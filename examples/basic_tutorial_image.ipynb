{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: image data\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run benchmarks\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "dl = TorchDataLoader(name=\"CIFAR10\")\n",
    "\n",
    "# use only 320 images from cifar10\n",
    "train_indices = list(range(32*10))\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32, sampler=SubsetRandomSampler(train_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "# wrap a sequential model in a torch nn.Module\n",
    "class model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model3, self).__init__()\n",
    "        self.seqmodel = nn.Sequential(models.resnet18(pretrained=True), nn.Linear(1000,10))\n",
    "    def forward(self, X):\n",
    "        return self.seqmodel(X)\n",
    "\n",
    "model = model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  3.093740075826645  \tBatch training accuracy:  18.75  \t[ 8 / 8 ]                                   \n",
      "Time taken for this epoch: 3.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 15.625000%,                 Avg loss: 2.850661 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  2.3813588470220566  \tBatch training accuracy:  32.03125  \t[ 8 / 8 ]                              \n",
      "Time taken for this epoch: 3.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 10.937500%,                 Avg loss: 3.679309 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  2.0986555367708206  \tBatch training accuracy:  39.453125  \t[ 8 / 8 ]                             \n",
      "Time taken for this epoch: 2.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 6.250000%,                 Avg loss: 3.852335 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.8523353338241577, 6.25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "# train the model\n",
    "pipe.train(SGD, 3, False, {\"lr\":0.01}, {\"batch_size\":32, \"sampler\":SubsetRandomSampler(train_indices)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simply use interpretability tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteocaorsi/opt/anaconda3/lib/python3.9/site-packages/captum/_utils/gradient.py:56: UserWarning:\n",
      "\n",
      "Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "\n",
      "/Users/matteocaorsi/opt/anaconda3/lib/python3.9/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:59: UserWarning:\n",
      "\n",
      "Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "\n",
      "/Users/matteocaorsi/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1025: UserWarning:\n",
      "\n",
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "inter = Interpreter(pipe.model, method=\"GuidedGradCam\")\n",
    "output = inter.interpret_image(next(iter(dl_tr))[0][0].reshape(1,3,32,32), \n",
    "                      1, pipe.model.seqmodel[0].layer2[0].conv1);\n",
    "\n",
    "# visualise the interpreter\n",
    "vs = Visualiser(pipe)\n",
    "vs.plot_interpreter_image(inter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract inner data from your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqmodel.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      "seqmodel.0.bn1.weight torch.Size([64])\n",
      "seqmodel.0.bn1.bias torch.Size([64])\n",
      "seqmodel.0.bn1.running_mean torch.Size([64])\n",
      "seqmodel.0.bn1.running_var torch.Size([64])\n",
      "seqmodel.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.0.bn1.weight torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.bias torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.0.bn2.weight torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.bias torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.1.bn1.weight torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.bias torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.1.bn2.weight torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.bias torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
      "seqmodel.0.layer2.0.bn1.weight torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.bias torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "seqmodel.0.layer2.0.bn2.weight torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.bias torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1])\n",
      "seqmodel.0.layer2.0.downsample.1.weight torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.bias torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "seqmodel.0.layer2.1.bn1.weight torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.bias torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "seqmodel.0.layer2.1.bn2.weight torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.bias torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
      "seqmodel.0.layer3.0.bn1.weight torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.bias torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "seqmodel.0.layer3.0.bn2.weight torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.bias torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1])\n",
      "seqmodel.0.layer3.0.downsample.1.weight torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.bias torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "seqmodel.0.layer3.1.bn1.weight torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.bias torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "seqmodel.0.layer3.1.bn2.weight torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.bias torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
      "seqmodel.0.layer4.0.bn1.weight torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.bias torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "seqmodel.0.layer4.0.bn2.weight torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.bias torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "seqmodel.0.layer4.0.downsample.1.weight torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.bias torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "seqmodel.0.layer4.1.bn1.weight torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.bias torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "seqmodel.0.layer4.1.bn2.weight torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.bias torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.fc.weight torch.Size([1000, 512])\n",
      "seqmodel.0.fc.bias torch.Size([1000])\n",
      "seqmodel.1.weight torch.Size([10, 1000])\n",
      "seqmodel.1.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "from gdeep.models import ModelExtractor\n",
    "\n",
    "me = ModelExtractor(pipe.model, loss_fn)\n",
    "\n",
    "lista = me.get_layers_param()\n",
    "\n",
    "for k, item in lista.items():\n",
    "    print(k,item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the decision boundary computations:\n",
      "Step: 0/1\r"
     ]
    }
   ],
   "source": [
    "x = next(iter(dl_tr))[0][0]\n",
    "if x.dtype is not torch.int64:\n",
    "    res = me.get_decision_boundary(x, n_epochs=1)\n",
    "    res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dl_tr))[0]\n",
    "list_activations = me.get_activations(x)\n",
    "len(list_activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([1000, 512])\n",
      "torch.Size([1000])\n",
      "torch.Size([10, 1000])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "x, target = next(iter(dl_tr))\n",
    "if x.dtype is torch.float:\n",
    "    for gradient in me.get_gradients(x, target=target)[1]:\n",
    "        print(gradient.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activations and other topological aspects of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vs.plot_data_model()\n",
    "# vs.plot_activations(x)\n",
    "vs.plot_persistence_diagrams(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "\n",
    "In the next section we compute the confusion matrix on the entire training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 12.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.0,\n",
       " 4.131547451019287,\n",
       " array([[ 0.,  3.,  6.,  0.,  0., 11.,  5.,  0.,  0.,  0.],\n",
       "        [ 0.,  6.,  7.,  2.,  0., 10., 16.,  0.,  3.,  3.],\n",
       "        [ 0.,  0., 18.,  0.,  0.,  5.,  5.,  0.,  1.,  0.],\n",
       "        [ 0.,  0., 17.,  1.,  0.,  4.,  7.,  0.,  3.,  0.],\n",
       "        [ 0.,  0., 10.,  0.,  0., 10.,  5.,  0.,  2.,  0.],\n",
       "        [ 0.,  0., 12.,  2.,  0.,  4.,  7.,  0.,  2.,  0.],\n",
       "        [ 0.,  0., 17.,  0.,  0.,  3., 14.,  0.,  3.,  0.],\n",
       "        [ 0.,  0., 14.,  0.,  0.,  3., 10.,  0.,  1.,  1.],\n",
       "        [ 0.,  0.,  9.,  0.,  0.,  8.,  9.,  0.,  1.,  0.],\n",
       "        [ 0.,  2., 11.,  1.,  0.,  7., 14.,  0.,  1.,  4.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.evaluate_classification(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
