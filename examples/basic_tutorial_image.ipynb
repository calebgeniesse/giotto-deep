{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: image data\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run benchmarks\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data.datasets import BuildDatasets, BuildDataLoaders\n",
    "\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.transforms import ToTensor  # for preprocessing\n",
    "\n",
    "db = BuildDatasets(name=\"CIFAR10\")\n",
    "ds_tr, ds_val, ds_ts = db.build_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "from gdeep.data.preprocessors import ToTensorImage\n",
    "\n",
    "transformation = ToTensorImage((32,32))\n",
    "transformation.fit_to_dataset(ds_tr)  # this is useless for this transformation\n",
    "\n",
    "transformed_ds_tr = transformation.attach_transform_to_dataset(ds_tr)\n",
    "transformed_ds_val = transformation.attach_transform_to_dataset(ds_val)\n",
    "transformed_ds_ts = transformation.attach_transform_to_dataset(ds_ts)\n",
    "\n",
    "# use only 320 images from cifar10\n",
    "train_indices = list(range(32*10))\n",
    "dl_tr, dl_val, dl_ts = BuildDataLoaders((transformed_ds_tr, transformed_ds_val, transformed_ds_ts)).build_dataloaders(\n",
    "    batch_size=32, sampler=SubsetRandomSampler(train_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "# wrap a sequential model in a torch nn.Module\n",
    "class model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model3, self).__init__()\n",
    "        self.seqmodel = nn.Sequential(models.resnet18(pretrained=True), nn.Linear(1000,10))\n",
    "    def forward(self, X):\n",
    "        return self.seqmodel(X)\n",
    "\n",
    "model = model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "# train the model\n",
    "pipe.train(SGD, 3, False, {\"lr\":0.01}, {\"batch_size\":32, \"sampler\":SubsetRandomSampler(train_indices)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simply use interpretability tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "inter = Interpreter(pipe.model, method=\"GuidedGradCam\")\n",
    "output = inter.interpret_image(next(iter(dl_tr))[0][0].reshape(1,3,32,32), \n",
    "                      1, pipe.model.seqmodel[0].layer2[0].conv1);\n",
    "\n",
    "# visualise the interpreter\n",
    "vs = Visualiser(pipe)\n",
    "try:\n",
    "    vs.plot_interpreter_image(inter);\n",
    "except AssertionError:\n",
    "    print(\"The heatmap is made of all zeros...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract inner data from your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.models import ModelExtractor\n",
    "\n",
    "me = ModelExtractor(pipe.model, loss_fn)\n",
    "\n",
    "lista = me.get_layers_param()\n",
    "\n",
    "for k, item in lista.items():\n",
    "    print(k,item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dl_tr))[0][0]\n",
    "if x.dtype is not torch.int64:\n",
    "    res = me.get_decision_boundary(x, n_epochs=1)\n",
    "    res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dl_tr))[0]\n",
    "list_activations = me.get_activations(x)\n",
    "len(list_activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, target = next(iter(dl_tr))\n",
    "if x.dtype is torch.float:\n",
    "    for gradient in me.get_gradients(x, target=target)[1]:\n",
    "        print(gradient.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activations and other topological aspects of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vs.plot_data_model()\n",
    "# vs.plot_activations(x)\n",
    "vs.plot_persistence_diagrams(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "\n",
    "In the next section we compute the confusion matrix on the entire training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.evaluate_classification(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
