{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: image data\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run benchmarks\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "dl = TorchDataLoader(name=\"CIFAR10\")\n",
    "\n",
    "# use only 320 images from cifar10\n",
    "train_indices = list(range(32*10))\n",
    "dl_tr, dl_ts = dl.build_dataloader(batch_size=32, sampler=SubsetRandomSampler(train_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "# wrap a sequential model in a torch nn.Module\n",
    "class model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model3, self).__init__()\n",
    "        self.seqmodel = nn.Sequential(models.resnet18(pretrained=True), nn.Linear(1000,10))\n",
    "    def forward(self, X):\n",
    "        return self.seqmodel(X)\n",
    "\n",
    "model = model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  3.2025386095046997  \tBatch training accuracy:  16.796875  \t[ 8 / 8 ]                              \n",
      "Time taken for this epoch: 3s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 9.375000%,                 Avg loss: 4.675710 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  2.905037134885788  \tBatch training accuracy:  26.953125  \t[ 8 / 8 ]                              \n",
      "Time taken for this epoch: 3s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 6.250000%,                 Avg loss: 3.128407 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  2.086886078119278  \tBatch training accuracy:  41.015625  \t[ 8 / 8 ]                               \n",
      "Time taken for this epoch: 3s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.187500%,                 Avg loss: 4.096832 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.096831679344177, 17.1875)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "# train the model\n",
    "pipe.train(SGD, 3, False, {\"lr\":0.01}, {\"batch_size\":32, \"sampler\":SubsetRandomSampler(train_indices)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simply use interpretability tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteocaorsi/anaconda3/lib/python3.6/site-packages/captum/_utils/gradient.py:59: UserWarning:\n",
      "\n",
      "Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "\n",
      "/Users/matteocaorsi/anaconda3/lib/python3.6/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:61: UserWarning:\n",
      "\n",
      "Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "\n",
      "/Users/matteocaorsi/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py:974: UserWarning:\n",
      "\n",
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "inter = Interpreter(pipe.model, method=\"GuidedGradCam\")\n",
    "output = inter.interpret_image(next(iter(dl_tr))[0][0].reshape(1,3,32,32), \n",
    "                      1, pipe.model.seqmodel[0].layer2[0].conv1);\n",
    "\n",
    "# visualise the interpreter\n",
    "vs = Visualiser(pipe)\n",
    "vs.plot_interpreter_image(inter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract inner data from your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqmodel.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      "seqmodel.0.bn1.weight torch.Size([64])\n",
      "seqmodel.0.bn1.bias torch.Size([64])\n",
      "seqmodel.0.bn1.running_mean torch.Size([64])\n",
      "seqmodel.0.bn1.running_var torch.Size([64])\n",
      "seqmodel.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.0.bn1.weight torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.bias torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.0.bn2.weight torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.bias torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.1.bn1.weight torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.bias torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "seqmodel.0.layer1.1.bn2.weight torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.bias torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.running_mean torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.running_var torch.Size([64])\n",
      "seqmodel.0.layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
      "seqmodel.0.layer2.0.bn1.weight torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.bias torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "seqmodel.0.layer2.0.bn2.weight torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.bias torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1])\n",
      "seqmodel.0.layer2.0.downsample.1.weight torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.bias torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
      "seqmodel.0.layer2.1.bn1.weight torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.bias torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "seqmodel.0.layer2.1.bn2.weight torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.bias torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.running_mean torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.running_var torch.Size([128])\n",
      "seqmodel.0.layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
      "seqmodel.0.layer3.0.bn1.weight torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.bias torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "seqmodel.0.layer3.0.bn2.weight torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.bias torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1])\n",
      "seqmodel.0.layer3.0.downsample.1.weight torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.bias torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "seqmodel.0.layer3.1.bn1.weight torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.bias torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "seqmodel.0.layer3.1.bn2.weight torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.bias torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.running_mean torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.running_var torch.Size([256])\n",
      "seqmodel.0.layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
      "seqmodel.0.layer4.0.bn1.weight torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.bias torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "seqmodel.0.layer4.0.bn2.weight torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.bias torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "seqmodel.0.layer4.0.downsample.1.weight torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.bias torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
      "seqmodel.0.layer4.1.bn1.weight torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.bias torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "seqmodel.0.layer4.1.bn2.weight torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.bias torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.running_mean torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.running_var torch.Size([512])\n",
      "seqmodel.0.layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "seqmodel.0.fc.weight torch.Size([1000, 512])\n",
      "seqmodel.0.fc.bias torch.Size([1000])\n",
      "seqmodel.1.weight torch.Size([10, 1000])\n",
      "seqmodel.1.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "from gdeep.models import ModelExtractor\n",
    "\n",
    "me = ModelExtractor(pipe.model, loss_fn)\n",
    "\n",
    "lista = me.get_layers_param()\n",
    "\n",
    "for k, item in lista.items():\n",
    "    print(k,item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the decision boundary computations:\n",
      "Step: 0/1\r"
     ]
    }
   ],
   "source": [
    "x = next(iter(dl_tr))[0][0]\n",
    "if x.dtype is not torch.int64:\n",
    "    res = me.get_decision_boundary(x, n_epochs=1)\n",
    "    res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dl_tr))[0]\n",
    "list_activations = me.get_activations(x)\n",
    "len(list_activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([1000, 512])\n",
      "torch.Size([1000])\n",
      "torch.Size([10, 1000])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "x, target = next(iter(dl_tr))\n",
    "if x.dtype is torch.float:\n",
    "    for gradient in me.get_gradients(x, target=target)[1]:\n",
    "        print(gradient.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activations and other topological aspects of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# vs.plot_data_model()\n",
    "# vs.plot_activations(x)\n",
    "vs.plot_persistence_diagrams(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "\n",
    "In the next section we compute the confusion matrix on the entire training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 14.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25.937500000000004,\n",
       " 3.6003201961517335,\n",
       " array([[ 0.,  2.,  0.,  0.,  0.,  1.,  0.,  0., 21.,  1.],\n",
       "        [ 0., 15.,  0.,  0.,  2.,  2.,  3.,  0., 12., 13.],\n",
       "        [ 0.,  3.,  2.,  0.,  0.,  6.,  1.,  0.,  9.,  8.],\n",
       "        [ 0.,  4.,  0.,  1.,  2.,  5.,  3.,  0.,  9.,  8.],\n",
       "        [ 0.,  1.,  0.,  0.,  5.,  9.,  0.,  1.,  2.,  9.],\n",
       "        [ 0.,  1.,  0.,  0.,  2., 16.,  1.,  0.,  0.,  7.],\n",
       "        [ 1.,  1.,  2.,  0.,  3.,  7.,  5.,  1.,  4., 13.],\n",
       "        [ 0.,  0.,  0.,  1.,  3.,  9.,  0.,  2.,  7.,  7.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., 25.,  1.],\n",
       "        [ 0.,  2.,  0.,  0.,  1.,  4.,  0.,  1., 20., 12.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.evaluate_classification(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
