{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa6ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xitorch in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.8.0)\n",
      "Requirement already satisfied: torch>=1.8 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from torch>=1.8->xitorch) (4.1.1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing GPU!\n"
     ]
    }
   ],
   "source": [
    "from gdeep.topactivation import TopactivationFC as TFC\n",
    "from gdeep.pipeline import Pipeline\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from torch import nn\n",
    "import torch\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "!pip3 install xitorch\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.topactivation.spectral_analysisTorch import LaplacianOperator\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using GPU!\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    \n",
    "writer = SummaryWriter()\n",
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c40b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=8,            \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=2,bias=False                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        \n",
    "        conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(8, 16, 3, 1, 2,bias=False),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )        # fully connected layer, output 10 classes\n",
    "        \n",
    "        conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 3, 1, 2,bias=False),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(7),                \n",
    "        )        #\n",
    "        \n",
    "        out = nn.Sequential(nn.Flatten(),nn.Linear(32 , 10,bias=False))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layers=nn.Sequential(conv1,conv2,conv3,out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)   # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        return x   # return x for visualization\n",
    "    \n",
    "    \n",
    "    \n",
    "model = CNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a595c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#List layers : \n",
    "layers = [module for module in model.modules() if isinstance(module, nn.Sequential)]\n",
    "print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4893d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for x in dl_tr:\n",
    "    print(model(x[0]).shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a997a",
   "metadata": {},
   "source": [
    "## Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9643c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 1.557888 \tEpoch training accuracy: 45.62%                                                                \n",
      "Time taken for this epoch: 10.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 89.06%,                 Avg loss: 0.377016 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.279159 \tEpoch training accuracy: 91.45%                                                                \n",
      "Time taken for this epoch: 10.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 92.75%,                 Avg loss: 0.235724 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.174080 \tEpoch training accuracy: 94.63%                                      500 ]                     \n",
      "Time taken for this epoch: 10.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 95.01%,                 Avg loss: 0.162477 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.129600 \tEpoch training accuracy: 96.02%                                      500 ]                     \n",
      "Time taken for this epoch: 10.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 95.93%,                 Avg loss: 0.125635 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.110366 \tEpoch training accuracy: 96.51%                                      500 ]                     \n",
      "Time taken for this epoch: 10.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 96.29%,                 Avg loss: 0.119488 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11948767622249822, 96.29166666666666)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD\n",
    "pipe.train(optimizer, 5, False, {\"lr\": 0.1}, n_accumulated_grads=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
