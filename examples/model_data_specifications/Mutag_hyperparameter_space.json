{
    "dataloaders_params": {
        "batch_size": [8, 32, 2]
    },
    "models_hyperparams": {
        "activation": ["gelu"],
        "bias_attention": [ "True", "False"],
        "dropout_dec": [0.0, 0.5, 0.05],
        "dropout_enc": [0.0, 0.5, 0.05],
        "hidden_dim": ["16", "32", "64", "96", "128"],
        "input_dim": [6],
        "layer_norm": ["True", "False"],
        "layer_norm_pooling": ["True", "False"],
        "n_layer_dec": [1, 5, 1],
        "n_layer_enc": [2, 5, 1],
        "num_heads": ["2", "4", "8", "16"],
        "attention_type": ["self_attention"],
        "dim_output": ["2"]
    },
    "optimizers_params": {
        "lr": [0.00001, 0.1, null, true],
        "weight_decay": [0.000001, 0.1, null, true]
    },
    "schedulers_params": {
        "num_cycles": [1],
        "num_training_steps": [150],
        "num_warmup_steps": [6]
    },
    "n_trials": 1,
    "cross_validation": true,
    "k_folds": 4
}
