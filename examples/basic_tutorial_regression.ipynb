{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: regression task\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run trainig\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader, DataLoaderFromArray\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(100,3)\n",
    "y_train = 0.3*np.array(list(map(sum,X_train)))  # a hyperplane\n",
    "\n",
    "X_val = np.random.rand(50,3)\n",
    "y_val = 0.3*np.array(list(map(sum,X_train)))\n",
    "\n",
    "dl = DataLoaderFromArray(X_train, y_train, X_val, y_val)\n",
    "dl_tr, dl_val, _ = dl.create(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model1, self).__init__()\n",
    "        self.seqmodel = FFNet(arch=[3, 5, 1])\n",
    "    def forward(self, x):\n",
    "        return self.seqmodel(x)\n",
    "\n",
    "model = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.13145961364110312  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.129149 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.11279423534870148  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.124128 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.11507629851500194  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.119186 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.10685953746239345  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.114306 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.10859703024228413  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.109547 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.09545312573512395  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.104830 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.10045224179824193  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.099992 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.09632833798726399  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.095214 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.08390144010384877  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.090490 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.08938403924306233  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.085839 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.07867801810304324  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.081184 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.07471382369597752  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.076696 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.06424044817686081  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.072182 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.06724616636832555  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.067792 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.061106073359648384  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.063549 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.06308828915158908  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.059488 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.05145731444160143  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.055528 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.057759907096624374  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.051834 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.04598352933923403  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.048275 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.043577307214339576  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.044986 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0364653275658687  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                       \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.041939 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03688178459803263  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.039177 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.036139930287996926  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.036580 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03272849569718043  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.034116 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03308704184989134  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.031849 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02866063949962457  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.029757 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.025236713389555614  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.027840 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023890164370338123  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.026157 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020853805045286816  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.024685 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021519899368286133  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.023422 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02109677344560623  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.022275 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.018847711384296417  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.021285 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.017693640974660713  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.020427 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.018395536579191685  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.019666 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.015347520976016918  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.019000 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.017784237240751583  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.018424 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01692234476407369  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.017898 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01686689754327138  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.017429 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01742868684232235, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_val), loss_fn, writer)\n",
    "\n",
    "# train the model with learning rate scheduler\n",
    "pipe.train(Adam, 38, False, #lr_scheduler=ExponentialLR, scheduler_params={\"gamma\": 0.9}, \n",
    "           profiling=False, store_grad_layer_hist=True, writer_tag=\"line\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6636]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model(torch.tensor([[1,1,1]]).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model with cross validation: we just have to set the parameter `cross_validation = True`.\n",
    "\n",
    "The `keep_training = True` flag allow us to restart from the same scheduler, optimiser and trained model obtained at thhe end of the last training in the instance of the class `pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.017375807277858257  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.014973631283889214  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.015134613960981369  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.015744556051989395  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.016849397060771782  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0167525801807642  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                       \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.016769645735621452  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.017840805153052013  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.012630 \n",
      "\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train the model with CV\n",
    "pipe.train(SGD, 8, cross_validation=False, keep_training=True)\n",
    "\n",
    "# since we used the keep training flag, the optimiser has not been modified compared to the previous training.\n",
    "print(pipe.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract inner data from your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqmodel.linears.0.weight torch.Size([5, 3])\n",
      "seqmodel.linears.0.bias torch.Size([5])\n",
      "seqmodel.linears.1.weight torch.Size([1, 5])\n",
      "seqmodel.linears.1.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "me = ModelExtractor(pipe.model, loss_fn)\n",
    "\n",
    "lista = me.get_layers_param()\n",
    "for k, item in lista.items():\n",
    "    print(k,item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dl_tr))[0]\n",
    "list_activations = me.get_activations(x)\n",
    "len(list_activations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activations and other topological aspects of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending the plots to tensorboard: \n",
      "Step 1/4\r",
      "Step 2/4\r",
      "Step 3/4\r",
      "Step 4/4\r"
     ]
    }
   ],
   "source": [
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "\n",
    "vs.plot_data_model()\n",
    "vs.plot_activations(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
