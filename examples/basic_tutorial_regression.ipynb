{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: regression task\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run trainig\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader, DataLoaderFromArray\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(100,3)\n",
    "y_train = 0.3*np.array(list(map(sum,X_train)))  # a hyperplane\n",
    "\n",
    "X_val = np.random.rand(50,3)\n",
    "y_val = 0.3*np.array(list(map(sum,X_train)))\n",
    "\n",
    "dl = DataLoaderFromArray(X_train, y_train, X_val, y_val)\n",
    "dl_tr, dl_val, _ = dl.build_dataloaders(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model1, self).__init__()\n",
    "        self.seqmodel = FFNet(arch=[3, 5, 1])\n",
    "    def forward(self, x):\n",
    "        return self.seqmodel(x)\n",
    "\n",
    "model = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.397744615872701  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                       \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.449160 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.37383710344632465  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.434420 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.37516359488169354  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.421401 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42140087485313416, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_val), loss_fn, writer)\n",
    "\n",
    "# train the model with learning rate scheduler\n",
    "pipe.train(Adam, 3, False, lr_scheduler=ExponentialLR, scheduler_params={\"gamma\": 0.9}, \n",
    "           profiling=False, store_grad_layer_hist=True, writer_tag=\"line\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3371]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model(torch.tensor([[1,1,1]]).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model with cross validation: we just have to set the parameter `cross_validation = True`.\n",
    "\n",
    "The `keep_training = True` flag allow us to restart from the same scheduler, optimiser and trained model obtained at thhe end of the last training in the instance of the class `pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Fold  1 **************\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3981989920139313  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.320279 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3738676905632019  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.310843 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3571678598721822  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.301584 \n",
      "\n",
      "\n",
      "\n",
      "********** Fold  2 **************\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.38710831602414447  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.336761 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3794979353745778  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.326374 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.37004295984903973  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.316179 \n",
      "\n",
      "\n",
      "\n",
      "********** Fold  3 **************\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3496404190858205  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.464583 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.35369110107421875  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.452125 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.34385624527931213  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.439658 \n",
      "\n",
      "\n",
      "\n",
      "********** Fold  4 **************\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.39277324080467224  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.379204 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.35480426748593646  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.367999 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3506798247496287  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.357050 \n",
      "\n",
      "\n",
      "\n",
      "********** Fold  5 **************\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.39312166968981427  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.359207 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.368520587682724  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.349204 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.3716677228609721  \tBatch training accuracy:  0.0  \t[ 3 / 3 ]                      \n",
      "Time taken for this epoch: 0.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 0.000000%,                 Avg loss: 0.339402 \n",
      "\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.000729\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train the model with CV\n",
    "pipe.train(SGD, 3, cross_validation=True, keep_training=True)\n",
    "\n",
    "# since we used the keep training flag, the optimiser has not been modified compared to the previous training.\n",
    "print(pipe.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract inner data from your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqmodel.linears.0.weight torch.Size([5, 3])\n",
      "seqmodel.linears.0.bias torch.Size([5])\n",
      "seqmodel.linears.1.weight torch.Size([1, 5])\n",
      "seqmodel.linears.1.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "me = ModelExtractor(pipe.model, loss_fn)\n",
    "\n",
    "lista = me.get_layers_param()\n",
    "for k, item in lista.items():\n",
    "    print(k,item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dl_tr))[0]\n",
    "list_activations = me.get_activations(x)\n",
    "len(list_activations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activations and other topological aspects of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending the plots to tensorboard: \n",
      "Step 4/4\r"
     ]
    }
   ],
   "source": [
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "\n",
    "vs.plot_data_model()\n",
    "vs.plot_activations(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
