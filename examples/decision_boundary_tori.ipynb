{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of decision boundary\n",
    "Analysing decison boundaries is not an easy task, especially given the fact that the feature space is non compact.\n",
    "\n",
    "On compact spaces it is easier to work, as they a re close and bounded (Heine-Borel). \n",
    "\n",
    "We propose here a method to compactifiy the feature space $\\mathbb R^n$ to the projective space $\\mathbb RP^n$.\n",
    "\n",
    "The decision boundary, gets therefore sampled in each chart of $\\mathbb RP^n$ uniformly. When charts are put together, the resulting point cloud (defined abstractly via a dissimilarity matrix `d_final`), can be used to compute the topology of the *compactified* decision boundary.\n",
    "\n",
    "We believe that the topology so obtained can furthe be exploited for regularisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.data.datasets import DatasetBuilder, DataLoaderBuilder\n",
    "from gdeep.trainer import Trainer\n",
    "from torch import autograd\n",
    "\n",
    "# plot\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# TDA\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.plotting import plot_diagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build datatset\n",
    "\n",
    "We want to test our method on a 3D dataset made of 2 separate blob. We expect that the neural network decision boundary looks like and hyperplane in $\\mathbb R^3$.\n",
    "\n",
    "After compactification, we would expect to find $\\mathbb RP^2$ as final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = DatasetBuilder(name=\"DoubleTori\")\n",
    "ds_tr, ds_val, _ = bd.build()\n",
    "# train_indices = list(range(160))\n",
    "dl = DataLoaderBuilder((ds_tr, ds_val))\n",
    "dl_tr, dl_val, dl_ts = dl.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NN\n",
    "model = FFNet(arch=[3, 10, 10, 2])\n",
    "print(model)\n",
    "pipe = Trainer(model, (dl_tr, dl_ts), nn.CrossEntropyLoss(), writer)\n",
    "pipe.train(SGD, 5, False, {\"lr\": 0.01}, {\"batch_size\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "vs.plot_data_model()\n",
    "db, _, _ = vs.plot_decision_boundary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology\n",
    "We chec with Giotto-tda that the topology of the decison boundary is indeed that one of $\\mathbb RP^2$, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check topology from d_final\n",
    "\n",
    "vr = VietorisRipsPersistence(\n",
    "    collapse_edges=True,\n",
    "    max_edge_length=1,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=-1,\n",
    "    homology_dimensions=(0, 1, 2),\n",
    ")\n",
    "diag = vr.fit_transform([db])\n",
    "\n",
    "plot_diagram(diag[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower level use of the modules\n",
    "\n",
    "In this short section,. we show how to directly use the functionalities of the decision boundary calculators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.analysis.decision_boundary import (\n",
    "    QuasihyperbolicDecisionBoundaryCalculator,\n",
    "    UniformlySampledPoint,\n",
    ")\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "point_sample_generator = UniformlySampledPoint(\n",
    "    [(-2, 4), (-2, 2), (-2, 2), (0, 2 * np.pi), (-1.0, 1.0)], n_samples=n_samples\n",
    ")\n",
    "point_sample_tensor = torch.from_numpy(point_sample_generator()).float()\n",
    "\n",
    "phi = point_sample_tensor[:, -2].reshape(-1, 1)\n",
    "theta = point_sample_tensor[:, -1].reshape(-1, 1)\n",
    "theta = torch.acos(theta)\n",
    "\n",
    "y0 = torch.cat(\n",
    "    (\n",
    "        torch.sin(theta) * torch.cos(phi),\n",
    "        torch.sin(theta) * torch.sin(phi),\n",
    "        torch.cos(theta),\n",
    "    ),\n",
    "    -1,\n",
    ")\n",
    "\n",
    "\n",
    "g = QuasihyperbolicDecisionBoundaryCalculator(\n",
    "    model=model,\n",
    "    initial_points=point_sample_tensor[\n",
    "        :, :3\n",
    "    ],  # torch.ones_like(y0).to(dev),#torch.distributions.uniform.Uniform(-10.,10.).sample((n_samples, 3)).to(dev),\n",
    "    initial_vectors=y0,\n",
    "    integrator=None,  # lambda params: torch.optim.Adam(params, )\n",
    ")\n",
    "g.step(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points_boundary = g.get_filtered_decision_boundary(0.01).detach().cpu().numpy()\n",
    "# sample_points_boundary = g.get_decision_boundary().detach().cpu().numpy()\n",
    "\n",
    "writer.add_embedding(sample_points_boundary, tag=\"Decision boundary of entangled tori\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}