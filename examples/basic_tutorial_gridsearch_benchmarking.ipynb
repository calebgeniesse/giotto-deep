{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: gridsearch and benchmarking\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API.\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. gridsearch on the initial model and dataset\n",
    " 4. benchmarking\n",
    " 5. gridsearching in each benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and notebook auto-reloader\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.optim import SGD, Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from gdeep.pipeline import Pipeline\n",
    "from gdeep.data.datasets import TorchDataLoader\n",
    "# today's protagonists\n",
    "from gdeep.search import Benchmark\n",
    "from gdeep.search import Gridsearch, GiottoSummaryWriter\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results.\n",
    "\n",
    "In this example, we use our modified version of the writer, as we believe it displays better results in the `hparams` dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = GiottoSummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset\n",
    "\n",
    "In the next cell we subsample the `CIFAR10` dataset and prepare the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TorchDataLoader(name=\"CIFAR10\")\n",
    "train_indices = list(range(32*10))\n",
    "\n",
    "print(len(train_indices))\n",
    "\n",
    "dl_tr, dl_temp = dl.build_dataloaders(batch_size=32, \n",
    "                                      sampler=SubsetRandomSampler(train_indices))\n",
    "\n",
    "print(len(dl_tr))\n",
    "\n",
    "test_indices = [32*10 + x for x in list(range(32*2))]\n",
    "\n",
    "dl_ts, dl_temp = dl.build_dataloaders(batch_size=25, sampler=SubsetRandomSampler(test_indices))\n",
    "\n",
    "dl_val = dl_ts\n",
    "\n",
    "print(len(dl_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your model\n",
    "\n",
    "In the next section we build a torchh model with a `str` parameter. The type of parameter can of course be changed to `int`: the example is to show the potential of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametric model with string value\n",
    "class model2(nn.Module):\n",
    "    def __init__(self, n_nodes = \"100\"):\n",
    "        super(model2, self).__init__()\n",
    "        self.md = nn.Sequential(nn.Sequential(models.resnet18(pretrained=True), \n",
    "                                                  nn.Linear(1000,eval(n_nodes))), \n",
    "                                    nn.Linear(eval(n_nodes),10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.md(x)\n",
    "    \n",
    "    \n",
    "model = model2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# initialise pipeline class\n",
    "pipe = Pipeline(model, [dl_tr, dl_val, dl_ts], loss_fn, writer, StratifiedKFold(2, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is a simple cross-validated training (no Gridsearch)\n",
    "\n",
    "# we also add the n_accumulated_grads=5, which is useful to avoid OOM results when training on the GPU\n",
    "pipe.train(SGD, 2, True, {\"lr\": 0.001}, n_accumulated_grads=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch\n",
    "\n",
    "We run a gridsearch over different hyperparametrs: \n",
    " - the learning rate `lr`\n",
    " - the batch size `batch_size`\n",
    " - the network parameter `arch`\n",
    " \n",
    "The scope of the gridsearch is to find the optimum set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialise gridsearch\n",
    "search = Gridsearch(pipe, \"accuracy\", 2, best_not_last=True)\n",
    "\n",
    "# if you want to store pickle files of the models instead of the state_dicts\n",
    "search.store_pickle = True\n",
    "\n",
    "# dictionaries of hyperparameters\n",
    "optimizers_params = {\"lr\": [0.001, 0.01]}\n",
    "dataloaders_params = {\"batch_size\": [32, 64, 16]}\n",
    "models_hyperparams = {\"n_nodes\": [\"200\"]}\n",
    "\n",
    "# starting the gridsearch\n",
    "search.start((SGD, Adam), 3, False, optimizers_params, dataloaders_params, models_hyperparams, n_accumulated_grads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_val_acc_gs, search.best_val_loss_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the results\n",
    "df_res = search._results()\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line in the dataframe with the top accuracy contains the optimum hyperparameters. You can visualise them interactively in the the `HPARAMS` of the tesorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the gridsearch, this time with a LR scheduler\n",
    "\n",
    "# here we wat to grid-search over the LR parameters as well!\n",
    "schedulers_params = {\"gamma\": [0.5, 0.9]}\n",
    "\n",
    "search.start((SGD, Adam), 2, False, \n",
    "             dataloaders_params=dataloaders_params, \n",
    "             models_hyperparams=models_hyperparams,\n",
    "             lr_scheduler=ExponentialLR, schedulers_params=schedulers_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "Benchmarking means fixing a set of models and a set of datasets and trying all possible pairs of *(model, dataset)*. \n",
    "\n",
    "Of course, only compatible models with compatiible datasets will be benchmarked.\n",
    "\n",
    "Just to clarify further: at this stage, there is no hyperparameter search involved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing multiple datasets\n",
    "\n",
    "Store your different dataloaders into a dictionary for benchmarking: `dataloaders_dicts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dicts = []\n",
    "dl = TorchDataLoader(name=\"CIFAR10\")\n",
    "\n",
    "train_indices = list(range(64*5))\n",
    "\n",
    "dl_tr, dl_temp = dl.build_dataloaders(batch_size=32, sampler=SubsetRandomSampler(train_indices))\n",
    "\n",
    "test_indices = [64*5 + x for x in list(range(64))]\n",
    "\n",
    "dl_ts, dl_temp = dl.build_dataloaders(batch_size=32, sampler=SubsetRandomSampler(test_indices))\n",
    "\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"CIFAR10_1000\"\n",
    "temp_dict[\"dataloaders\"] = (dl_tr, dl_ts)\n",
    "\n",
    "dataloaders_dicts.append(temp_dict)\n",
    "\n",
    "dl = TorchDataLoader(name=\"DoubleTori\")\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=48)\n",
    "\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"double_tori\"\n",
    "temp_dict[\"dataloaders\"] = (dl_tr, dl_ts)\n",
    "\n",
    "dataloaders_dicts.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing multiple models\n",
    "Store your different models into a dictionary for benchmarking: `models_dicts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dicts = []\n",
    "\n",
    "model = model2()\n",
    "\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"resnet18\"\n",
    "temp_dict[\"model\"] = model\n",
    "\n",
    "models_dicts.append(temp_dict)\n",
    "\n",
    "# avoid having exposed paramters that wll not be gridsearched on\n",
    "class model_no_param(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_no_param, self).__init__()\n",
    "        self.mod = FFNet([3,5,5,2])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mod(x)\n",
    "\n",
    "model5 = model_no_param()\n",
    "temp_dict = {}\n",
    "temp_dict[\"name\"] = \"ffnn\"\n",
    "temp_dict[\"model\"] = model5\n",
    "\n",
    "models_dicts.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the benchmarking!\n",
    "\n",
    "after initialising th class with the dictionaries of models and dataloaders, we can run the actual benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the benchmarking class. When we do not specify it, it will use KFold with 5 splits\n",
    "bench = Benchmark(models_dicts, dataloaders_dicts, loss_fn, writer)\n",
    "\n",
    "# start the benchmarking\n",
    "bench.start(SGD, 2, False, {\"lr\" : 0.01}, {\"batch_size\" : 32}, n_accumulated_grads=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking + Gridsearch + CV\n",
    "\n",
    "In this last section we consider the possibility of running a gridsearch within each pair *(model, dataset)*.\n",
    "\n",
    "This can be achieved by initialising a benchmark class and use the benchmark as input for the gridsearch class.\n",
    "\n",
    "With these commands, we are basically looking for the best set of hyperparamets for each pair of *(model, dataset)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard pytorch loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# initialise benchmark\n",
    "bench = Benchmark(models_dicts, dataloaders_dicts, loss_fn, writer, KFold(3))\n",
    "\n",
    "# initialise gridsearch with benchmark instance\n",
    "search2 = Gridsearch(bench, \"loss\", 2)\n",
    "\n",
    "# yperparameters\n",
    "optimizers_params = {\"lr\": [0.001, 0.01, None, True]}  # to have the log sampler\n",
    "dataloaders_params = {\"batch_size\": [32, 64, 16]}\n",
    "models_hyperparams = {\"n_nodes\": [\"500\", \"200\"]}\n",
    "search2.start((SGD, Adam), 2, True, optimizers_params, dataloaders_params, models_hyperparams)\n",
    "\n",
    "writer.close()  # let's recall to close the tensorboard writer once all is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best validation accuracy: \", \n",
    "      search2.best_val_acc_gs, \n",
    "      \"\\nBest validation loss value: \", \n",
    "      search2.best_val_loss_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom pruner and sampler\n",
    "\n",
    "It is possible to pass to the gridsearch class a customer `optuna.Pruners` and `optuna.Samplers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# initialise gridsearch\n",
    "gs = Gridsearch(pipe, \"accuracy\", 8, best_not_last=False, pruner=MedianPruner(n_startup_trials=2,\n",
    "                                                                              n_warmup_steps=0,\n",
    "                                                                              interval_steps=1,\n",
    "                                                                              n_min_trials=1), sampler=TPESampler())\n",
    "\n",
    "# dictionaries of hyperparameters\n",
    "optimizers_params = {\"lr\": [0.001, 0.01]}\n",
    "dataloaders_params = {\"batch_size\": [32, 64, 16]}\n",
    "models_hyperparams = {\"n_nodes\": [\"500\", \"200\"]}\n",
    "\n",
    "# starting the gridsearch\n",
    "gs.start((SGD, Adam), 3, False, optimizers_params, dataloaders_params, models_hyperparams, n_accumulated_grads=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
