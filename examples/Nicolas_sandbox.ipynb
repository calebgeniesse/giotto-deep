{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pressed-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compatible-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informal-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloader(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monetary-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(0, arch=[28*28, 200, 32, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "editorial-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): FFNet(\n",
      "    (layer0): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (layer1): Linear(in_features=200, out_features=32, bias=True)\n",
      "    (layer2): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 50  [57600/60000]\n",
      " Accuracy: 37.7%,                 Avg loss: 0.065192 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 86  [57600/60000]\n",
      " Accuracy: 51.3%,                 Avg loss: 0.060942 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: 99  [57600/60000]\n",
      " Accuracy: 54.2%,                 Avg loss: 0.060042 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "# train the model\n",
    "pipe.train(SGD, 3, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pending-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gdeep.models import ModelExtractor\n",
    "\n",
    "me = ModelExtractor(model, loss_fn)\n",
    "\n",
    "x = next(iter(dl_tr))[0]\n",
    "list_activations = me.get_activations(x)\n",
    "len(list_activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continental-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudhi import SimplexTree as ST\n",
    "import networkx as nx\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "extreme-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activations = list_activations\n",
    "arch = [28*28, 200, 32, 10]\n",
    "\n",
    "def get_activation_graph(activations,arch, index_batch = 1):\n",
    "    n_layer = len(arch)\n",
    "    current_node = 0\n",
    "    activation_graph = ST()\n",
    "    edge_list = []\n",
    "    for i in range(n_layer - 1):\n",
    "        f = lambda x: (x[0] + current_node, x[1] + current_node)\n",
    "        G = nx.complete_bipartite_graph(arch[i], arch[i+1])\n",
    "        l = list(G.edges())\n",
    "        l = map(f,l)\n",
    "        edge_list.extend(l)\n",
    "        current_node += arch[i]\n",
    "    for edge in edge_list:\n",
    "        activation_graph.insert(list(edge), 0.0)\n",
    "    activations_flatten = torch.empty(0)\n",
    "    for layer in range(n_layer):\n",
    "        activations_flatten = torch.cat((activations_flatten, activations[layer][index_batch]))\n",
    "    for neuron in range(activations_flatten.size()[0]):\n",
    "        activation_graph.insert([neuron], float(activations_flatten[neuron]))\n",
    "    return activation_graph\n",
    "    \n",
    "def gudhi_to_giotto(diagrams_gudhi):\n",
    "    diagrams_giotto = []\n",
    "    for diagram in diagrams_gudhi:\n",
    "        diagram_giotto = []\n",
    "        for dim, bar in diagram:\n",
    "            diagram_giotto.append([bar[0],bar[1],dim])\n",
    "        diagrams_giotto.append(diagram_giotto)\n",
    "    return np.asarray(diagrams_giotto)\n",
    "\n",
    "def reverse_diagrams(diagrams):\n",
    "    diagrams_reversed = []\n",
    "    for diagram in diagrams:\n",
    "        diagram_reversed = []\n",
    "        for b,d,q in diagram:\n",
    "            diagram_reversed.append([d,b,q])\n",
    "        diagrams_reversed.append(diagram_reversed)       \n",
    "    return np.asarray(diagrams_reversed)\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comfortable-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_activation_graph(activations,arch, index_batch = 1)\n",
    "L.extend_filtration()\n",
    "pers = L.extended_persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "injured-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gudhi_to_giotto(pers[3])\n",
    "\n",
    "from gtda.diagrams import PersistenceEntropy as PE\n",
    "entropy = PE(normalize = True)\n",
    "E = entropy.fit_transform(reverse_diagrams(d))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "therapeutic-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 62.0%,                 Avg loss: 0.057609 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 44  [57600/60000]\n",
      " Accuracy: 62.4%,                 Avg loss: 0.057471 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 28  [57600/60000]\n",
      " Accuracy: 64.3%,                 Avg loss: 0.056905 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 14  [57600/60000]\n",
      " Accuracy: 64.0%,                 Avg loss: 0.056997 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 17  [57600/60000]\n",
      " Accuracy: 64.8%,                 Avg loss: 0.056733 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 29  [57600/60000]\n",
      " Accuracy: 64.8%,                 Avg loss: 0.056734 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 79  [57600/60000]\n",
      " Accuracy: 65.1%,                 Avg loss: 0.056639 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 08  [57600/60000]\n",
      " Accuracy: 65.9%,                 Avg loss: 0.056387 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 83  [57600/60000]\n",
      " Accuracy: 65.6%,                 Avg loss: 0.056478 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 90  [57600/60000]\n",
      " Accuracy: 66.2%,                 Avg loss: 0.056291 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 49  [57600/60000]\n",
      " Accuracy: 65.8%,                 Avg loss: 0.056417 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 11  [57600/60000]\n",
      " Accuracy: 66.2%,                 Avg loss: 0.056295 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 66.4%,                 Avg loss: 0.056242 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 66.2%,                 Avg loss: 0.056292 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 02  [57600/60000]\n",
      " Accuracy: 66.7%,                 Avg loss: 0.056136 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 78  [57600/60000]\n",
      " Accuracy: 66.8%,                 Avg loss: 0.056123 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 01  [57600/60000]\n",
      " Accuracy: 67.0%,                 Avg loss: 0.056032 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 66.2%,                 Avg loss: 0.056301 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 93  [57600/60000]\n",
      " Accuracy: 66.5%,                 Avg loss: 0.056206 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 10  [57600/60000]\n",
      " Accuracy: 66.9%,                 Avg loss: 0.056081 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 24  [57600/60000]\n",
      " Accuracy: 67.2%,                 Avg loss: 0.056003 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 66.7%,                 Avg loss: 0.056150 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 66.5%,                 Avg loss: 0.056192 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 66.4%,                 Avg loss: 0.056242 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 50  [57600/60000]\n",
      " Accuracy: 67.1%,                 Avg loss: 0.056028 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.4%,                 Avg loss: 0.055921 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.2%,                 Avg loss: 0.055969 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.5%,                 Avg loss: 0.055892 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 01  [57600/60000]\n",
      " Accuracy: 67.0%,                 Avg loss: 0.056023 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.4%,                 Avg loss: 0.055929 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.5%,                 Avg loss: 0.055882 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 11  [57600/60000]\n",
      " Accuracy: 67.3%,                 Avg loss: 0.055950 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.2%,                 Avg loss: 0.056005 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 46  [57600/60000]\n",
      " Accuracy: 67.3%,                 Avg loss: 0.055950 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.6%,                 Avg loss: 0.055864 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 50  [57600/60000]\n",
      " Accuracy: 67.8%,                 Avg loss: 0.055790 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 50  [57600/60000]\n",
      " Accuracy: 67.8%,                 Avg loss: 0.055811 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 00  [57600/60000]\n",
      " Accuracy: 67.7%,                 Avg loss: 0.055853 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 08  [57600/60000]\n",
      " Accuracy: 67.6%,                 Avg loss: 0.055875 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 59  [57600/60000]\n",
      " Accuracy: 67.8%,                 Avg loss: 0.055810 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "diagrams = []\n",
    "for i in range(n_epochs):\n",
    "    me = ModelExtractor(model, loss_fn)\n",
    "    x = next(iter(dl_tr))[0]\n",
    "    activations = me.get_activations(x)\n",
    "    L = get_activation_graph(activations,arch, index_batch = 1)\n",
    "    L.extend_filtration()\n",
    "    pers = L.extended_persistence()\n",
    "    diagrams.append(pers[3])\n",
    "    pipe.train(SGD, 2, lr=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "arabic-crystal",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d5d6acd5c9c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiagrams_giotto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgudhi_to_giotto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdiagrams_giotto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgudhi_to_giotto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_diagrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagrams_giotto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "entropy = PE(normalize = True)\n",
    "diagrams_giotto = gudhi_to_giotto(diagrams[0])\n",
    "for i in range(1,len(diagrams)):\n",
    "    diagrams_giotto.append(gudhi_to_giotto(diagrams[1]))\n",
    "\n",
    "E = entropy.fit_transform(np.asarray(reverse_diagrams(diagrams_giotto)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "furnished-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams_giotto = gudhi_to_giotto(diagrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "stretch-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = entropy.fit_transform(np.asarray(reverse_diagrams(diagrams_giotto)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "alone-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagrams[0] == diagrams[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-healing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-blade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-entry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-pollution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
