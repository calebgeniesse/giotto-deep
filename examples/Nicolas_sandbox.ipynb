{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "\n",
    "from gdeep.visualisation import  persistence_diagrams_of_activations\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from gtda.plotting import plot_betti_surfaces\n",
    "\n",
    "from gtda.plotting import plot_diagram\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from gtda.diagrams import PersistenceEntropy as PE\n",
    "\n",
    "from gdeep.models import ModelExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloader(batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "arch = [28*28,  300, 100, 10]\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(0, arch= arch ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): FFNet(\n",
      "    (layer0): Linear(in_features=784, out_features=300, bias=True)\n",
      "    (layer1): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "# train the model\n",
    "#pipe.train(SGD, 3, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.models import ModelExtractor\n",
    "\n",
    "\n",
    "\n",
    "x = next(iter(dl_tr))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudhi import SimplexTree as ST\n",
    "import networkx as nx\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_activation_graph(activations,arch, index_batch = 1):\n",
    "    n_layer = len(arch)\n",
    "    current_node = 0\n",
    "    activation_graph = ST()\n",
    "    edge_list = []\n",
    "    for i in range(n_layer - 1):\n",
    "        f = lambda x: (x[0] + current_node, x[1] + current_node)\n",
    "        G = nx.complete_bipartite_graph(arch[i], arch[i+1])\n",
    "        l = list(G.edges())\n",
    "        l = map(f,l)\n",
    "        edge_list.extend(l)\n",
    "        current_node += arch[i]\n",
    "    for edge in edge_list:\n",
    "        activation_graph.insert(list(edge), 0.0)\n",
    "    activations_flatten = torch.empty(0)\n",
    "    for layer in range(n_layer):\n",
    "        activations_flatten = torch.cat((activations_flatten, activations[layer][index_batch]))\n",
    "    for neuron in range(activations_flatten.size()[0]):\n",
    "        activation_graph.insert([neuron], float(activations_flatten[neuron]))\n",
    "    return activation_graph\n",
    "    \n",
    "def gudhi_to_giotto(diagrams_gudhi):\n",
    "    diagrams_giotto = []\n",
    "    for diagram in diagrams_gudhi:\n",
    "        diagram_giotto = []\n",
    "        for dim, bar in diagram:\n",
    "            diagram_giotto.append([bar[0],bar[1],dim])\n",
    "        diagrams_giotto.append(np.array(diagram_giotto))\n",
    "    return diagrams_giotto\n",
    "\n",
    "\n",
    "def reverse_diagrams(diagrams):\n",
    "    diagrams_reversed = []\n",
    "    for diagram in diagrams:\n",
    "        diagram_reversed = []\n",
    "        for b,d,q in diagram:\n",
    "            diagram_reversed.append([d,b,q])\n",
    "        diagrams_reversed.append(diagram_reversed)       \n",
    "    return diagrams_reversed\n",
    "\n",
    "def get_extended_persistence(model, loss_fn, x):\n",
    "    me = ModelExtractor(model, loss_fn)\n",
    "    activations = me.get_activations(x)\n",
    "    diagrams = []\n",
    "    for i in range(len(x)):\n",
    "        L = get_activation_graph(activations, arch, index_batch = i)\n",
    "        L.extend_filtration()\n",
    "        pers = L.extended_persistence()\n",
    "        diagrams.append(pers[3])\n",
    "    return diagrams\n",
    "    \n",
    "def diagrams_accross_training(model, loss_fn, x, n_epochs):\n",
    "    diagrams = []\n",
    "    for i in range(n_epochs):\n",
    "        diagrams.append(get_extended_persistence(model,loss_fn,x))\n",
    "        pipe.train(SGD, 2, lr=0.01)\n",
    "    return diagrams\n",
    "\n",
    "def get_entropy_accross_training(diagrams_accross_training):\n",
    "    entropy = PE(normalize = True)\n",
    "    n_epochs = len(diagrams_accross_training)\n",
    "    n_batch = len(diagrams_accross_training[0])\n",
    "    E = np.empty([n_epochs,n_batch])\n",
    "    for epoch in range(n_epochs):\n",
    "        diagrams_giotto_reversed = reverse_diagrams(gudhi_to_giotto(diagrams_accross_training[epoch]))\n",
    "        for batch in range(n_batch):\n",
    "            e = entropy.fit_transform(np.array([diagrams_giotto_reversed[batch]]))[0][0]\n",
    "            E[epoch][batch] = e\n",
    "    return E\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation extended persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 97  [57600/60000]\n",
      " Accuracy: 14.7%,                 Avg loss: 0.072409 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 43  [57600/60000]\n",
      " Accuracy: 21.3%,                 Avg loss: 0.070347 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 98  [57600/60000]\n",
      " Accuracy: 25.4%,                 Avg loss: 0.069064 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 51  [57600/60000]\n",
      " Accuracy: 26.4%,                 Avg loss: 0.068764 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 01  [57600/60000]\n",
      " Accuracy: 26.8%,                 Avg loss: 0.068616 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 14  [57600/60000]\n",
      " Accuracy: 27.3%,                 Avg loss: 0.068473 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 48  [57600/60000]\n",
      " Accuracy: 27.5%,                 Avg loss: 0.068397 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 79  [57600/60000]\n",
      " Accuracy: 27.6%,                 Avg loss: 0.068368 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 58  [57600/60000]\n",
      " Accuracy: 27.8%,                 Avg loss: 0.068314 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 99  [57600/60000]\n",
      " Accuracy: 27.8%,                 Avg loss: 0.068302 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 87  [57600/60000]\n",
      " Accuracy: 28.1%,                 Avg loss: 0.068205 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 33  [57600/60000]\n",
      " Accuracy: 32.3%,                 Avg loss: 0.066902 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 69  [57600/60000]\n",
      " Accuracy: 34.9%,                 Avg loss: 0.066096 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 74  [57600/60000]\n",
      " Accuracy: 35.5%,                 Avg loss: 0.065883 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 21  [57600/60000]\n",
      " Accuracy: 36.2%,                 Avg loss: 0.065686 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 48  [57600/60000]\n",
      " Accuracy: 36.5%,                 Avg loss: 0.065588 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: 40  [57600/60000]\n",
      " Accuracy: 36.7%,                 Avg loss: 0.065528 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: 41  [57600/60000]\n",
      " Accuracy: 36.9%,                 Avg loss: 0.065479 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-27e5778c90e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiagrams_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiagrams_accross_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7966db48cdfd>\u001b[0m in \u001b[0;36mdiagrams_accross_training\u001b[0;34m(model, loss_fn, x, n_epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mdiagrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdiagrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_extended_persistence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdiagrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7966db48cdfd>\u001b[0m in \u001b[0;36mget_extended_persistence\u001b[0;34m(model, loss_fn, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activation_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_filtration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_persistence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mdiagrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdiagrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "diagrams_training = diagrams_accross_training(model, loss_fn, x, n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = get_entropy_accross_training(diagrams_training)\n",
    "df_e = pd.DataFrame(E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_e)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams import PairwiseDistance\n",
    "dist = PairwiseDistance(metric = 'bottleneck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams = gudhi_to_giotto(diagrams_training[9]) \n",
    "distance_matrix = dist.fit_transform(diagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of overfitting on one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "n_epochs = 1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    image , labels = next(iter(dl_tr))\n",
    "    optimizer.zero_grad()\n",
    "    output = model(image)\n",
    "    loss = loss_fn(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate video of barcodes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = []\n",
    "deaths = []\n",
    "epochs = []\n",
    "batchs = []\n",
    "\n",
    "n_batch = 32\n",
    "for epoch in range(n_epochs):\n",
    "    diagrams_training_giotto = gudhi_to_giotto(diagrams_training[epoch])\n",
    "    for batch in range(n_batch):\n",
    "        for b,d,q in diagrams_training_giotto[batch]:\n",
    "            births.append(b)\n",
    "            deaths.append(d)\n",
    "            epochs.append(epoch)\n",
    "            batchs.append(batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'birth' : births , 'death' : deaths, 'epoch': epochs, 'batch' : batchs}\n",
    "df = pd.DataFrame (data, columns = ['birth','death','epoch', 'batch'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    fig = px.scatter(df[df['epoch'] == epoch], x=\"birth\", y=\"death\",  color=\"batch\",\n",
    "          range_x=[-100, 0], range_y=[-100,0])\n",
    "    fig.write_image('barcode_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"video_barcodes.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['batch'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('barcodes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
