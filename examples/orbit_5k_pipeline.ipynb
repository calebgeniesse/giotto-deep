{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dataclasses import dataclass\n","import os\n","from typing import Tuple\n","\n","import torch\n","import torch.nn as nn\n","from gdeep.data import PreprocessingPipeline\n","from gdeep.data.datasets import PersistenceDiagramFromFiles\n","from gdeep.data.datasets.base_dataloaders import (DataLoaderBuilder,\n","                                                  DataLoaderParamsTuples)\n","from gdeep.data.datasets.persistence_diagrams_from_graphs_builder import \\\n","    PersistenceDiagramFromGraphBuilder\n","from gdeep.data.persistence_diagrams.one_hot_persistence_diagram import (\n","    OneHotEncodedPersistenceDiagram, collate_fn_persistence_diagrams)\n","from gdeep.data.preprocessors import (\n","    FilterPersistenceDiagramByHomologyDimension,\n","    FilterPersistenceDiagramByLifetime, NormalizationPersistenceDiagram)\n","from gdeep.search.hpo import GiottoSummaryWriter\n","from gdeep.topology_layers import Persformer, PersformerConfig, PersformerWrapper\n","from gdeep.topology_layers.persformer_config import PoolerType\n","from gdeep.trainer.trainer import Trainer\n","from gdeep.search import HyperParameterOptimization\n","from gdeep.utility import DEFAULT_GRAPH_DIR, PoolerType\n","from gdeep.utility.utils import autoreload_if_notebook\n","from sklearn.model_selection import train_test_split\n","from torch.optim import Adam\n","from torch.utils.data import Subset\n","from torch.utils.tensorboard.writer import SummaryWriter\n","from gdeep.data.datasets import OrbitsGenerator, DataLoaderKwargs\n","\n","autoreload_if_notebook()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@dataclass\n","class Orbit5kConfig():\n","    batch_size_train: int = 4\n","    num_orbits_per_class: int = 32\n","    validation_percentage: float = 0.0\n","    test_percentage: float = 0.0\n","    num_jobs: int = 8\n","    dynamical_system: str = \"classical_convention\"\n","    homology_dimensions: Tuple[int] = (0, 1)  # type: ignore\n","    dtype: str = \"float32\"\n","    arbitrary_precision: bool = False\n","\n","config_data = Orbit5kConfig()\n","    \n","\n","og = OrbitsGenerator(\n","    num_orbits_per_class=config_data.num_orbits_per_class,\n","    homology_dimensions=config_data.homology_dimensions,\n","    validation_percentage=config_data.validation_percentage,\n","    test_percentage=config_data.test_percentage,\n","    n_jobs=config_data.num_jobs,\n","    dynamical_system=config_data.dynamical_system,\n","    dtype=config_data.dtype,\n",")\n","\n","\n","# Define the data loader\n","\n","dataloaders_dicts = DataLoaderKwargs(\n","    train_kwargs={\"batch_size\": config_data.batch_size_train,},\n","    val_kwargs={\"batch_size\": 4},\n","    test_kwargs={\"batch_size\": 3},\n",")\n","\n","if len(config_data.homology_dimensions) == 0:\n","    dl_train, _, _ = og.get_dataloader_orbits(dataloaders_dicts)\n","else:\n","    dl_train, _, _ = og.get_dataloader_persistence_diagrams(dataloaders_dicts)\n","    \n","model_config = PersformerConfig(\n","    input_size=2 + 2, # there are 2 coordinates and 2 homology dimensions\n","    ouptut_size=5,  # there are 5 classes\n","    hidden_size=64,\n","    intermediate_size=128,\n","    num_attention_layers=2,\n","    num_attention_heads=8,\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# model = Persformer(model_config)\n","\n","# writer = SummaryWriter()\n","\n","# loss_function =  nn.CrossEntropyLoss()\n","\n","# trainer = Trainer(model, [dl_train], loss_function, writer)\n","\n","# trainer.train(Adam, 3, False, \n","#               {\"lr\":0.01}, \n","#               {\"batch_size\":16})\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the model by using a Wrapper for the Persformer model\n","\n","wrapped_model = PersformerWrapper(\n","    num_attention_layers=3,\n","    num_attention_heads=4,\n","    input_size= 2 + 2,\n","    ouptut_size=5,\n","    pooler_type=PoolerType.ATTENTION,\n",")\n","writer = GiottoSummaryWriter()\n","\n","loss_function =  nn.CrossEntropyLoss()\n","\n","trainer = Trainer(wrapped_model, [dl_train, dl_train], loss_function, writer)  # type: ignore\n","\n","# initialise hpo object\n","search = HyperParameterOptimization(trainer, \"accuracy\", 2, best_not_last=True)\n","\n","# if you want to store pickle files of the models instead of the state_dicts\n","search.store_pickle = True\n","\n","# dictionaries of hyperparameters\n","optimizers_params = {\"lr\": [0.001, 0.01]}\n","dataloaders_params = {\"batch_size\": [2, 4, 2]}\n","models_hyperparams = {\n","    \"input_size\": [4],\n","    \"output_size\": [5],\n","    \"num_attention_layers\": [1, 2, 1],\n","    \"num_attention_heads\": [8, 16, 8],\n","    \"hidden_size\": [16],\n","    \"intermediate_size\": [16],\n","}\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# starting the HPO\n","search.start(\n","    [Adam],\n","    3,\n","    False,\n","    optimizers_params,\n","    dataloaders_params,\n","    models_hyperparams,\n",")\n","\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}