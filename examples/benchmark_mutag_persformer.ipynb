{"cells":[{"cell_type":"markdown","metadata":{},"source":["  ## Benchmarking PersFormer on the graph datasets.\n","  We will compare the accuracy on the graph datasets of our SetTransformer\n","  based on PersFormer with the perslayer introduced in the paper:\n","  https://arxiv.org/abs/1904.09378"]},{"cell_type":"markdown","metadata":{},"source":["  ## Benchmarking MUTAG\n","  We will compare the test accuracies of PersLay and PersFormer on the MUTAG\n","  dataset. It consists of 188 graphs categorised into two classes.\n","  We will train the PersFormer on the same input features as PersFormer to\n","  get a fair comparison.\n","  The features PersLay is trained on are the extended persistence diagrams of\n","  the vertices of the graph filtered by the heat kernel signature (HKS)\n","  at time t=10.\n","  The maximum (wrt to the architecture and the hyperparameters) mean test\n","  accuracy of PersLay is 89.8(Â±0.9) and the train accuracy with the same\n","  model and the same hyperparameters is 92.3.\n","  They performed 10-fold evaluation, i.e. splitting the dataset into\n","  10 equally-sized folds and then record the test accuracy of the i-th\n","  fold and training the model on the 9 other folds."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython import get_ipython\n","get_ipython().magic('load_ext autoreload')\n","get_ipython().magic('autoreload 2')\n","\n","# Import libraries:\n","import os\n","import json\n","from dotmap import DotMap\n","\n","\n","\n","import numpy as np\n","\n","# Import the PyTorch modules\n","import torch  # type: ignore\n","from torch import nn  # type: ignore\n","from torch.optim import SGD, Adam, RMSprop, AdamW  # type: ignore\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Import Tensorflow writer\n","#from torch.utils.tensorboard import SummaryWriter  # type: ignore\n","from gdeep.search import GiottoSummaryWriter\n","\n","from transformers.optimization import get_cosine_with_hard_restarts_schedule_with_warmup, get_constant_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","# Import the giotto-deep modules\n","from gdeep.topology_layers import Persformer\n","from gdeep.pipeline import Pipeline\n","from gdeep.search import Gridsearch\n","from gdeep.topology_layers import load_data_as_tensor, balance_binary_dataset,\\\n","    print_class_balance\n","\n","from optuna.pruners import MedianPruner, NopPruner\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","#Configs\n","\n","model_data_file = 'model_data_specifications'\n","\n","with open(os.path.join(model_data_file, 'Mutag_data.json')) as config_data_file:\n","    config_data = DotMap(json.load(config_data_file))\n","\n","\n","with open(os.path.join(model_data_file, 'Mutag_model.json')) as config_data_file:\n","    config_model = DotMap(json.load(config_data_file))\n","    \n","\n","with open(os.path.join(model_data_file, 'Mutag_hyperparameter_space.json')) as config_data_file:\n","    hyperparameters_dicts = DotMap(json.load(config_data_file))\n","    dataloaders_params = hyperparameters_dicts.dataloaders_params\n","    models_hyperparams = hyperparameters_dicts.models_hyperparams\n","    optimizers_params = hyperparameters_dicts.optimizers_params\n","    schedulers_params = hyperparameters_dicts.schedulers_params\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_pds, _, y = load_data_as_tensor(config_data.dataset_name)\n","\n","# Balance labels in dataset\n","\n","if config_data.balance_dataset:\n","    x_pds, y = balance_binary_dataset(x_pds, y, verbose=True)\n","\n","print('class balance: {:.2f}'.format((y.sum() / y.shape[0]).item()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set up dataset and dataloader\n","\n","# create the datasets\n","graph_ds = TensorDataset(x_pds, y)\n","\n","# Either use fixed train and validation split or use cross validation\n","if hyperparameters_dicts.cross_validation:\n","    graph_dl = DataLoader(\n","                        graph_ds,\n","                        num_workers=config_data.num_jobs,\n","                        batch_size=config_data.batch_size_train,\n","                        shuffle=True\n","                        )\n","else:\n","    # Split the dataset into training and validation\n","    total_size = x_pds.shape[0]\n","    train_size = int(total_size * config_data.train_percentage)\n","    graph_ds_train, graph_ds_val = torch.utils.data.random_split(\n","                                                        graph_ds,\n","                                                        [train_size,\n","                                                        total_size - train_size],\n","                                                        generator=torch.Generator().manual_seed(config_data.data_split_seed))\n","\n","\n","    # Define data loaders\n","    graph_dl_train = DataLoader(\n","        graph_ds_train,\n","        num_workers=config_data.num_jobs,\n","        batch_size=config_data.batch_size_train,\n","        shuffle=True\n","        )\n","\n","    graph_dl_val = DataLoader(\n","        graph_ds_val,\n","        num_workers=config_data.num_jobs,\n","        batch_size=config_data.batch_size_val,\n","        shuffle=False\n","    )\n","\n","    # Compute balance of train and validation datasets\n","        \n","    print_class_balance(graph_dl_train, 'train')\n","    print_class_balance(graph_dl_val, 'validation')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define and initialize the model\n","model = Persformer.from_config(config_model, config_data)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Do training and validation\n","\n","# initialize loss\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Initialize the Tensorflow writer\n","writer = GiottoSummaryWriter(\n","            os.path.join(\"runs\",\n","                        config_model.implementation +\n","                        \"_\" + config_data.dataset_name +\n","                        \"_\" + models_hyperparams.attention_type[0] +\n","                        \"_\" + \"hyperparameter_search_giotto\")\n","            )\n","\n","# initialize pipeline object\n","if hyperparameters_dicts.cross_validation:\n","    pipe = Pipeline(model, [graph_dl, None], loss_fn, writer)\n","else:\n","    pipe = Pipeline(model, [graph_dl_train, graph_dl_val, None], loss_fn, writer)\n","\n","# Use gradient clipping\n","if config_model.gradient_clipping == None:\n","    pipe.clip = 1.0  # use default clipping value 1.0\n","else:\n","    pipe.clip = config_model.gradient_clipping"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train the model\n","\n","pipe.train(eval(config_model.optimizer),\n","           config_model.num_epochs,\n","           cross_validation=False,\n","           optimizers_param={\"lr\": config_model.learning_rate,\n","            \"weight_decay\": config_model.weight_decay},\n","           store_grad_layer_hist=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hyperparameter search\n","\n","pruner = NopPruner()\n","search = Gridsearch(pipe,\n","                    search_metric=\"accuracy\",\n","                    n_trials=hyperparameters_dicts.n_trials,\n","                    best_not_last=True,\n","                    pruner=pruner)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# starting the gridsearch\n","search.start((eval(config_model.optimizer),),\n","            n_epochs=schedulers_params.num_training_steps[0],\n","            cross_validation=hyperparameters_dicts.cross_validation,\n","            k_folds=hyperparameters_dicts.k_folds,\n","            optimizers_params=optimizers_params,\n","            dataloaders_params=dataloaders_params,\n","            models_hyperparams=models_hyperparams, lr_scheduler=get_cosine_with_hard_restarts_schedule_with_warmup,\n","            schedulers_params=schedulers_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
