{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddbfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n",
      "No TPUs...\n",
      "use float32 model\n",
      "DotMap(implementation='Old_SetTransformer', dim_input=4, num_outputs=1, num_classes=5, dim_hidden=64, num_heads=4, num_induced_points=64, layer_norm=False, pre_layer_norm=False, num_layers_encoder=2, num_layers_decoder=1, attention_type='self_attention', activation='nn.ReLU()', dropout_enc=0.0, dropout_dec=0.0, optimizer=<class 'torch.optim.adam.Adam'>, learning_rate=0.0001, num_epochs=500, pooling_type='attention', weight_decay=0.0, n_accumulated_grads=0, bias_attention=True)\n",
      "DotMap(batch_size_train=32, num_orbits_per_class=2000, validation_percentage=0.0, test_percentage=0.0, num_jobs=2, dynamical_system='classical_convention', homology_dimensions=(0, 1), dtype='float32', arbitrary_precision=False, dim_input=DotMap())\n",
      "SetTransformerOld(\n",
      "  (enc): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=4, out_features=64, bias=True)\n",
      "        (fc_k): Linear(in_features=4, out_features=64, bias=True)\n",
      "        (fc_v): Linear(in_features=4, out_features=64, bias=True)\n",
      "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): Dropout(p=0.0, inplace=False)\n",
      "    (1): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Dropout(p=0.0, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02405753954132991  \tBatch training accuracy:  19.760572139303484  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.246032%,                 Avg loss: 1.617300 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02399967677557646  \tBatch training accuracy:  20.04042288557214  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.005952%,                 Avg loss: 1.613224 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024052011432932383  \tBatch training accuracy:  20.024875621890548  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.246032%,                 Avg loss: 1.613296 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023994134433233914  \tBatch training accuracy:  19.41853233830846  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.005952%,                 Avg loss: 1.611249 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024021568583018744  \tBatch training accuracy:  20.475746268656717  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.005952%,                 Avg loss: 1.610967 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024061233250062857  \tBatch training accuracy:  20.75559701492537  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.494048%,                 Avg loss: 1.609467 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023953884988281857  \tBatch training accuracy:  20.522388059701495  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.569444%,                 Avg loss: 1.611366 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023946960767110188  \tBatch training accuracy:  19.853855721393035  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.494048%,                 Avg loss: 1.611593 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024089589047787796  \tBatch training accuracy:  19.760572139303484  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.825397%,                 Avg loss: 1.610095 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024027855835150724  \tBatch training accuracy:  19.900497512437813  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.246032%,                 Avg loss: 1.610642 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023950556024390075  \tBatch training accuracy:  20.537935323383085  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.246032%,                 Avg loss: 1.615069 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023939619609965615  \tBatch training accuracy:  20.724502487562187  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.494048%,                 Avg loss: 1.612271 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023991672553826327  \tBatch training accuracy:  20.64676616915423  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.246032%,                 Avg loss: 1.612424 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024048579866020242  \tBatch training accuracy:  20.911069651741293  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.005952%,                 Avg loss: 1.611182 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024073660077147223  \tBatch training accuracy:  20.631218905472636  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.005952%,                 Avg loss: 1.609839 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023962874317643653  \tBatch training accuracy:  20.149253731343283  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.005952%,                 Avg loss: 1.611211 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024111250146704528  \tBatch training accuracy:  20.677860696517413  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.924603%,                 Avg loss: 1.608735 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024007656681003856  \tBatch training accuracy:  20.97325870646766  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.287698%,                 Avg loss: 1.607731 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02410539762297673  \tBatch training accuracy:  20.817786069651742  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.394841%,                 Avg loss: 1.609519 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023979655545742357  \tBatch training accuracy:  21.0976368159204  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.948413%,                 Avg loss: 1.609777 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024063455524729258  \tBatch training accuracy:  21.361940298507463  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 28.273810%,                 Avg loss: 1.605673 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.023878907089802757  \tBatch training accuracy:  20.74004975124378  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.849206%,                 Avg loss: 1.606995 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023872753280905348  \tBatch training accuracy:  21.937189054726367  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.412698%,                 Avg loss: 1.602069 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023878260631466388  \tBatch training accuracy:  21.703980099502488  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.486111%,                 Avg loss: 1.599900 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023874928109088346  \tBatch training accuracy:  23.227611940298505  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.783730%,                 Avg loss: 1.601773 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023811250183712784  \tBatch training accuracy:  21.828358208955223  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.783730%,                 Avg loss: 1.598231 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.024301429886129957  \tBatch training accuracy:  22.046019900497512  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 31.250000%,                 Avg loss: 1.579652 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023575243072130193  \tBatch training accuracy:  22.730099502487562  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.882937%,                 Avg loss: 1.584402 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023393172529799427  \tBatch training accuracy:  25.48196517412935  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 28.670635%,                 Avg loss: 1.558601 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.022750557358585187  \tBatch training accuracy:  27.81405472636816  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 26.240079%,                 Avg loss: 1.543407 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.022861317615603925  \tBatch training accuracy:  29.46206467661692  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.386905%,                 Avg loss: 1.617249 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02274756170623931  \tBatch training accuracy:  29.41542288557214  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 25.396825%,                 Avg loss: 1.540239 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02233461716874915  \tBatch training accuracy:  30.721393034825873  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 32.341270%,                 Avg loss: 1.491865 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02240769246324378  \tBatch training accuracy:  28.187189054726367  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.978175%,                 Avg loss: 1.478304 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02198376347176471  \tBatch training accuracy:  30.970149253731343  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.283730%,                 Avg loss: 1.459637 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.022325191331740043  \tBatch training accuracy:  31.949626865671643  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.134921%,                 Avg loss: 1.445636 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.023668337224134757  \tBatch training accuracy:  32.431592039801  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 31.597222%,                 Avg loss: 1.449349 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.022013801247326294  \tBatch training accuracy:  31.949626865671643  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.275794%,                 Avg loss: 1.434117 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020966226188697624  \tBatch training accuracy:  32.44713930348259  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.573413%,                 Avg loss: 1.431337 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02216809602519173  \tBatch training accuracy:  32.944651741293534  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 28.968254%,                 Avg loss: 1.489797 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02073893736844039  \tBatch training accuracy:  32.60261194029851  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 32.787698%,                 Avg loss: 1.428831 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020614367812427124  \tBatch training accuracy:  32.40049751243781  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 31.150794%,                 Avg loss: 1.459399 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02166282241024188  \tBatch training accuracy:  33.02238805970149  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.375000%,                 Avg loss: 1.417892 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020754755432926007  \tBatch training accuracy:  33.72201492537313  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.077381%,                 Avg loss: 1.417201 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021074463478961393  \tBatch training accuracy:  33.41106965174129  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.367063%,                 Avg loss: 1.397529 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021473353181905415  \tBatch training accuracy:  34.483830845771145  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 29.910714%,                 Avg loss: 1.473373 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020965247604977432  \tBatch training accuracy:  32.633706467661696  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.168651%,                 Avg loss: 1.408486 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02139643946690346  \tBatch training accuracy:  33.100124378109456  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.630952%,                 Avg loss: 1.416312 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02170079857555788  \tBatch training accuracy:  34.74813432835821  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 32.291667%,                 Avg loss: 1.433653 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021623866475043604  \tBatch training accuracy:  34.34390547263681  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.573413%,                 Avg loss: 1.413515 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020689794080174385  \tBatch training accuracy:  33.95522388059701  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.771825%,                 Avg loss: 1.400479 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020522773562379144  \tBatch training accuracy:  34.74813432835821  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.011905%,                 Avg loss: 1.386060 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021723349889119465  \tBatch training accuracy:  33.22450248756219  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 32.440476%,                 Avg loss: 1.447517 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02129011130451563  \tBatch training accuracy:  34.81032338308458  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.160714%,                 Avg loss: 1.383365 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02017669594703029  \tBatch training accuracy:  34.17288557213931  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.706349%,                 Avg loss: 1.380571 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02062973335607728  \tBatch training accuracy:  35.46330845771145  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.904762%,                 Avg loss: 1.378751 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021181148083055792  \tBatch training accuracy:  35.9297263681592  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.152778%,                 Avg loss: 1.380099 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.022149776937949717  \tBatch training accuracy:  34.483830845771145  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.035714%,                 Avg loss: 1.426863 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020748139020815418  \tBatch training accuracy:  34.85696517412935  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.855159%,                 Avg loss: 1.389508 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020837569118139162  \tBatch training accuracy:  34.965796019900495  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 29.910714%,                 Avg loss: 1.471774 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.019917399729069193  \tBatch training accuracy:  35.04353233830846  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.805556%,                 Avg loss: 1.369834 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021834061513492715  \tBatch training accuracy:  35.30783582089552  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.095238%,                 Avg loss: 1.366876 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020860583627994974  \tBatch training accuracy:  36.240671641791046  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.500000%,                 Avg loss: 1.373063 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02102470872414053  \tBatch training accuracy:  35.758706467661696  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.343254%,                 Avg loss: 1.363459 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02014234825153256  \tBatch training accuracy:  36.76927860696517  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.450397%,                 Avg loss: 1.373912 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020188399215242757  \tBatch training accuracy:  35.58768656716418  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.730159%,                 Avg loss: 1.441009 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021036394199921718  \tBatch training accuracy:  36.17848258706468  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.730159%,                 Avg loss: 1.411463 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02104474774640591  \tBatch training accuracy:  34.51492537313433  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.656746%,                 Avg loss: 1.369639 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.02064948473403703  \tBatch training accuracy:  36.66044776119403  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.382937%,                 Avg loss: 1.429931 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.021509072673854542  \tBatch training accuracy:  35.883084577114424  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.037698%,                 Avg loss: 1.334843 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01988642666470352  \tBatch training accuracy:  35.9452736318408  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.541667%,                 Avg loss: 1.330349 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020302104712718753  \tBatch training accuracy:  36.80037313432835  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.996032%,                 Avg loss: 1.353718 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.020113467577084973  \tBatch training accuracy:  35.851990049751244  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.476190%,                 Avg loss: 1.322194 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.019564552093619732  \tBatch training accuracy:  38.40174129353234  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.492063%,                 Avg loss: 1.328019 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.019929025303665086  \tBatch training accuracy:  37.79539800995025  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.277778%,                 Avg loss: 1.297465 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.018072471096741025  \tBatch training accuracy:  38.24626865671642  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.152778%,                 Avg loss: 1.337652 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01963332161974551  \tBatch training accuracy:  38.914800995024876  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.698413%,                 Avg loss: 1.310714 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01995223434410285  \tBatch training accuracy:  39.381218905472636  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.392857%,                 Avg loss: 1.318306 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01882915710335347  \tBatch training accuracy:  41.55783582089552  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.972222%,                 Avg loss: 1.238808 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0180469051522402  \tBatch training accuracy:  44.931592039801  \t[ 201 / 250 ]                         \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.603175%,                 Avg loss: 1.117105 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.015956287953391005  \tBatch training accuracy:  49.36256218905473  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.430556%,                 Avg loss: 1.045013 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01492157622949401  \tBatch training accuracy:  56.374378109452735  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 61.259921%,                 Avg loss: 0.994326 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01415634985586897  \tBatch training accuracy:  61.80037313432835  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 63.343254%,                 Avg loss: 0.930189 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.019021464817559543  \tBatch training accuracy:  66.386815920398  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 65.674603%,                 Avg loss: 0.863356 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01186096638589356  \tBatch training accuracy:  70.18034825870647  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 70.287698%,                 Avg loss: 0.816756 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.01220606482444118  \tBatch training accuracy:  72.6523631840796  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 69.444444%,                 Avg loss: 0.783914 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009454824438142538  \tBatch training accuracy:  72.94776119402985  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 70.982143%,                 Avg loss: 0.756592 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009868283473437106  \tBatch training accuracy:  74.16044776119402  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 71.825397%,                 Avg loss: 0.732327 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007993352946950428  \tBatch training accuracy:  75.40422885572139  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 69.940476%,                 Avg loss: 0.735309 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.011312383324352663  \tBatch training accuracy:  75.45087064676616  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 73.561508%,                 Avg loss: 0.702875 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.011084215557990383  \tBatch training accuracy:  75.48196517412936  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 73.958333%,                 Avg loss: 0.674807 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009375308580066435  \tBatch training accuracy:  76.41480099502488  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 75.595238%,                 Avg loss: 0.655020 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008853256405882574  \tBatch training accuracy:  76.85012437810946  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 75.545635%,                 Avg loss: 0.648301 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009009578334751413  \tBatch training accuracy:  77.06778606965175  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 76.041667%,                 Avg loss: 0.636195 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008550587874739918  \tBatch training accuracy:  77.67412935323384  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 76.537698%,                 Avg loss: 0.617239 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006831786080972472  \tBatch training accuracy:  77.23880597014924  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 76.686508%,                 Avg loss: 0.608067 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008620328126262077  \tBatch training accuracy:  78.01616915422885  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 76.835317%,                 Avg loss: 0.608681 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008172088298038463  \tBatch training accuracy:  78.68470149253731  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 77.033730%,                 Avg loss: 0.596734 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008562359643812797  \tBatch training accuracy:  78.80907960199005  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 76.339286%,                 Avg loss: 0.609613 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009002481526996366  \tBatch training accuracy:  78.20273631840796  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 77.926587%,                 Avg loss: 0.583482 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008335118270038966  \tBatch training accuracy:  78.66915422885572  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 78.075397%,                 Avg loss: 0.570536 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008046274457997944  \tBatch training accuracy:  79.21330845771143  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 77.777778%,                 Avg loss: 0.565860 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007233655126533698  \tBatch training accuracy:  79.64863184079603  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 77.728175%,                 Avg loss: 0.577238 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008282844403489906  \tBatch training accuracy:  79.33768656716418  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: \n",
      " Accuracy: 77.777778%,                 Avg loss: 0.563212 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009467899502806403  \tBatch training accuracy:  79.15111940298507  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 79.365079%,                 Avg loss: 0.540683 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00807797463972177  \tBatch training accuracy:  80.03731343283582  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 78.273810%,                 Avg loss: 0.564624 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007707584853196025  \tBatch training accuracy:  80.06840796019901  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 79.811508%,                 Avg loss: 0.525085 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006058006440822165  \tBatch training accuracy:  80.16169154228857  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.208333%,                 Avg loss: 0.526443 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005877064383445095  \tBatch training accuracy:  80.78358208955224  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 79.117063%,                 Avg loss: 0.532577 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005222797393798828  \tBatch training accuracy:  80.70584577114428  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 78.819444%,                 Avg loss: 0.557721 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009401467457339538  \tBatch training accuracy:  80.59701492537313  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.902778%,                 Avg loss: 0.504349 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008667274049265468  \tBatch training accuracy:  81.2655472636816  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.257937%,                 Avg loss: 0.507599 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008827612174684136  \tBatch training accuracy:  81.0478855721393  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.505952%,                 Avg loss: 0.495242 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006887436950977762  \tBatch training accuracy:  80.89241293532339  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.101190%,                 Avg loss: 0.496239 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006287677074546244  \tBatch training accuracy:  81.40547263681593  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 79.960317%,                 Avg loss: 0.520480 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00823440628858348  \tBatch training accuracy:  81.66977611940298  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.200397%,                 Avg loss: 0.489851 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005271468293014451  \tBatch training accuracy:  81.51430348258707  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.406746%,                 Avg loss: 0.490190 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.010774747945776033  \tBatch training accuracy:  81.74751243781094  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.498016%,                 Avg loss: 0.467323 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006599005626801827  \tBatch training accuracy:  81.28109452736318  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.605159%,                 Avg loss: 0.500253 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007407321117410612  \tBatch training accuracy:  81.66977611940298  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.349206%,                 Avg loss: 0.469533 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007876625701562683  \tBatch training accuracy:  81.46766169154229  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.349206%,                 Avg loss: 0.481883 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00664967431950925  \tBatch training accuracy:  82.0429104477612  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.654762%,                 Avg loss: 0.463697 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006392199156889275  \tBatch training accuracy:  82.96019900497512  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.250000%,                 Avg loss: 0.476860 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006895484319373743  \tBatch training accuracy:  82.26057213930348  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.009921%,                 Avg loss: 0.480731 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007287750938045445  \tBatch training accuracy:  82.46268656716418  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.200397%,                 Avg loss: 0.472141 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005184439284291433  \tBatch training accuracy:  82.13619402985076  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.093254%,                 Avg loss: 0.449278 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00633255388606247  \tBatch training accuracy:  82.1983830845771  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.944444%,                 Avg loss: 0.454150 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00871623452030011  \tBatch training accuracy:  82.4160447761194  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.200397%,                 Avg loss: 0.491616 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006401752506322528  \tBatch training accuracy:  82.94465174129353  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.291667%,                 Avg loss: 0.448192 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007032017506177153  \tBatch training accuracy:  82.50932835820896  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.589286%,                 Avg loss: 0.452180 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006832143857111385  \tBatch training accuracy:  82.54042288557214  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.894841%,                 Avg loss: 0.448142 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.006714753843658599  \tBatch training accuracy:  82.47823383084577  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.853175%,                 Avg loss: 0.468071 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005875577677541704  \tBatch training accuracy:  82.86691542288557  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.994048%,                 Avg loss: 0.440097 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00802842182899589  \tBatch training accuracy:  82.75808457711443  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.738095%,                 Avg loss: 0.432929 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005697743957908593  \tBatch training accuracy:  82.9912935323383  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.894841%,                 Avg loss: 0.451650 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008985020034941869  \tBatch training accuracy:  82.07400497512438  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.192460%,                 Avg loss: 0.441203 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007980098030460415  \tBatch training accuracy:  82.75808457711443  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.299603%,                 Avg loss: 0.446311 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.009748733458827385  \tBatch training accuracy:  82.4160447761194  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.845238%,                 Avg loss: 0.443567 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00604560541276315  \tBatch training accuracy:  82.13619402985076  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.150794%,                 Avg loss: 0.444627 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007432396139078473  \tBatch training accuracy:  82.77363184079603  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.250000%,                 Avg loss: 0.451965 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005579392708356108  \tBatch training accuracy:  82.9757462686567  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.539683%,                 Avg loss: 0.428121 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008325201658467155  \tBatch training accuracy:  82.80472636815921  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.696429%,                 Avg loss: 0.441122 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006878239746710554  \tBatch training accuracy:  83.30223880597015  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.638889%,                 Avg loss: 0.430728 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005727541683918208  \tBatch training accuracy:  82.78917910447761  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.795635%,                 Avg loss: 0.436654 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006717689150008396  \tBatch training accuracy:  82.29166666666666  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.688492%,                 Avg loss: 0.427327 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005106205667429303  \tBatch training accuracy:  83.25559701492537  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.498016%,                 Avg loss: 0.445384 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006519781268058132  \tBatch training accuracy:  83.08457711442786  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.539683%,                 Avg loss: 0.423541 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005013519777587397  \tBatch training accuracy:  83.2089552238806  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.093254%,                 Avg loss: 0.431010 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0073154015624108  \tBatch training accuracy:  83.02238805970148  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.704365%,                 Avg loss: 0.464930 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006577191809516641  \tBatch training accuracy:  82.89800995024875  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.192460%,                 Avg loss: 0.421901 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00714374819205175  \tBatch training accuracy:  82.9912935323383  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.192460%,                 Avg loss: 0.424986 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006758670456966951  \tBatch training accuracy:  83.33333333333334  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.390873%,                 Avg loss: 0.414346 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008135417504097098  \tBatch training accuracy:  83.45771144278606  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.142857%,                 Avg loss: 0.420360 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005723193139579166  \tBatch training accuracy:  83.51990049751244  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.597222%,                 Avg loss: 0.440132 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00552071167610178  \tBatch training accuracy:  82.85136815920397  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.357143%,                 Avg loss: 0.469064 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0071448869076534294  \tBatch training accuracy:  83.53544776119402  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.142857%,                 Avg loss: 0.419339 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006332142287818946  \tBatch training accuracy:  82.9912935323383  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.390873%,                 Avg loss: 0.416612 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00773400053456055  \tBatch training accuracy:  82.77363184079603  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.142857%,                 Avg loss: 0.425846 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006290244818919927  \tBatch training accuracy:  83.30223880597015  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.894841%,                 Avg loss: 0.417391 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006450724171761849  \tBatch training accuracy:  83.3955223880597  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.192460%,                 Avg loss: 0.409760 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00638538065241344  \tBatch training accuracy:  83.17786069651741  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.746032%,                 Avg loss: 0.429780 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005093209186003576  \tBatch training accuracy:  83.16231343283582  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.101190%,                 Avg loss: 0.461322 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008347181538444253  \tBatch training accuracy:  83.24004975124379  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.242063%,                 Avg loss: 0.407020 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0046410922387346105  \tBatch training accuracy:  83.16231343283582  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.349206%,                 Avg loss: 0.436904 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005924640232650795  \tBatch training accuracy:  83.03793532338308  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.291667%,                 Avg loss: 0.414117 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005641754142087491  \tBatch training accuracy:  83.02238805970148  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.291667%,                 Avg loss: 0.409809 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007785202110584696  \tBatch training accuracy:  83.48880597014924  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.192460%,                 Avg loss: 0.415273 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006744101272886665  \tBatch training accuracy:  83.70646766169155  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.837302%,                 Avg loss: 0.412687 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00681142486743073  \tBatch training accuracy:  83.62873134328358  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.093254%,                 Avg loss: 0.403854 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007222278497705412  \tBatch training accuracy:  83.47325870646766  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.688492%,                 Avg loss: 0.404596 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007235226939566693  \tBatch training accuracy:  82.78917910447761  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.589286%,                 Avg loss: 0.404092 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006323982382295143  \tBatch training accuracy:  83.50435323383084  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.986111%,                 Avg loss: 0.399123 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004990015901736359  \tBatch training accuracy:  83.0068407960199  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.894841%,                 Avg loss: 0.423125 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005996385023961613  \tBatch training accuracy:  83.37997512437812  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.886905%,                 Avg loss: 0.397756 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004870329330216592  \tBatch training accuracy:  83.56654228855722  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.886905%,                 Avg loss: 0.406964 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006736834250872408  \tBatch training accuracy:  83.3955223880597  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.605159%,                 Avg loss: 0.465631 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0043082350670401726  \tBatch training accuracy:  83.53544776119402  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 80.654762%,                 Avg loss: 0.452717 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006697978991181103  \tBatch training accuracy:  83.79975124378109  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.837302%,                 Avg loss: 0.403549 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0052235374848047895  \tBatch training accuracy:  83.86194029850746  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.192460%,                 Avg loss: 0.403705 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005763774784050177  \tBatch training accuracy:  83.50435323383084  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.638889%,                 Avg loss: 0.411936 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007565766721222531  \tBatch training accuracy:  83.50435323383084  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.837302%,                 Avg loss: 0.391540 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006249698536906077  \tBatch training accuracy:  83.44216417910447  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.738095%,                 Avg loss: 0.403007 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005476918386582711  \tBatch training accuracy:  83.86194029850746  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.936508%,                 Avg loss: 0.398630 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005110465694422746  \tBatch training accuracy:  84.0018656716418  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 81.299603%,                 Avg loss: 0.425476 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006509316649603013  \tBatch training accuracy:  83.36442786069652  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.787698%,                 Avg loss: 0.400449 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.006219647861831817  \tBatch training accuracy:  83.34888059701493  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.142857%,                 Avg loss: 0.400171 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00620284231741037  \tBatch training accuracy:  84.1728855721393  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.142857%,                 Avg loss: 0.400715 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004471692798742608  \tBatch training accuracy:  84.31281094527363  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.638889%,                 Avg loss: 0.393313 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005507935635486052  \tBatch training accuracy:  83.90858208955224  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.531746%,                 Avg loss: 0.392947 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005045798139192571  \tBatch training accuracy:  84.15733830845771  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.234127%,                 Avg loss: 0.401051 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007927709254459361  \tBatch training accuracy:  84.15733830845771  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.382937%,                 Avg loss: 0.399154 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00474648926388565  \tBatch training accuracy:  84.375  \t[ 201 / 250 ]                                 \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.730159%,                 Avg loss: 0.375505 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.008482951281675652  \tBatch training accuracy:  84.15733830845771  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.482143%,                 Avg loss: 0.397375 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003510394573804751  \tBatch training accuracy:  84.28171641791045  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.531746%,                 Avg loss: 0.398213 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004441152016321818  \tBatch training accuracy:  84.43718905472637  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.722222%,                 Avg loss: 0.369905 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006009422872790057  \tBatch training accuracy:  84.62375621890547  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 82.936508%,                 Avg loss: 0.403383 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005656561299936095  \tBatch training accuracy:  85.01243781094527  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.474206%,                 Avg loss: 0.362348 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005394443202374586  \tBatch training accuracy:  85.07462686567165  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.027778%,                 Avg loss: 0.363127 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0069634798006038764  \tBatch training accuracy:  85.3389303482587  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.829365%,                 Avg loss: 0.362843 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006715983152389526  \tBatch training accuracy:  85.55659203980099  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.970238%,                 Avg loss: 0.362004 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0041750689495855305  \tBatch training accuracy:  85.66542288557214  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.672619%,                 Avg loss: 0.353036 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004809676118157989  \tBatch training accuracy:  86.14738805970148  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.375000%,                 Avg loss: 0.351204 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005212117857600919  \tBatch training accuracy:  85.55659203980099  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.531746%,                 Avg loss: 0.380420 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006250250547086422  \tBatch training accuracy:  85.49440298507463  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 84.821429%,                 Avg loss: 0.346616 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0033381232871345025  \tBatch training accuracy:  86.20957711442786  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.267857%,                 Avg loss: 0.348430 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006127718891670454  \tBatch training accuracy:  86.1162935323383  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.813492%,                 Avg loss: 0.346994 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0070599212278774125  \tBatch training accuracy:  85.92972636815921  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 83.035714%,                 Avg loss: 0.382172 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005152003978615377  \tBatch training accuracy:  86.00746268656717  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.714286%,                 Avg loss: 0.335925 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004647801616298619  \tBatch training accuracy:  86.44278606965175  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.061508%,                 Avg loss: 0.324210 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005037331610769775  \tBatch training accuracy:  86.5205223880597  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.863095%,                 Avg loss: 0.326080 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0048482576709481615  \tBatch training accuracy:  86.24067164179104  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.912698%,                 Avg loss: 0.322875 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004600170462285702  \tBatch training accuracy:  86.76927860696517  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.011905%,                 Avg loss: 0.324238 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00521574477058145  \tBatch training accuracy:  86.7070895522388  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.664683%,                 Avg loss: 0.327243 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005802650875713101  \tBatch training accuracy:  86.3339552238806  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.607143%,                 Avg loss: 0.317563 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004738399193654606  \tBatch training accuracy:  86.87810945273633  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.218254%,                 Avg loss: 0.345552 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004495347687854103  \tBatch training accuracy:  86.08519900497512  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.565476%,                 Avg loss: 0.353791 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004742048198903971  \tBatch training accuracy:  86.5360696517413  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.359127%,                 Avg loss: 0.320703 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005245060692379131  \tBatch training accuracy:  86.67599502487562  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.160714%,                 Avg loss: 0.311269 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004094655389216409  \tBatch training accuracy:  86.95584577114428  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.318103 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004894016171569255  \tBatch training accuracy:  87.22014925373134  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.359127%,                 Avg loss: 0.317196 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005534269026855924  \tBatch training accuracy:  87.28233830845771  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.557540%,                 Avg loss: 0.309186 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005606199526668188  \tBatch training accuracy:  86.48942786069652  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.160714%,                 Avg loss: 0.304272 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0049187380134762815  \tBatch training accuracy:  87.43781094527363  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.912698%,                 Avg loss: 0.326124 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0045836300992254005  \tBatch training accuracy:  87.23569651741293  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.119048%,                 Avg loss: 0.333552 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0037839543908389645  \tBatch training accuracy:  87.22014925373134  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.557540%,                 Avg loss: 0.312917 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004535107247865022  \tBatch training accuracy:  86.92475124378109  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.515873%,                 Avg loss: 0.332510 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004917410623967944  \tBatch training accuracy:  86.76927860696517  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.416667%,                 Avg loss: 0.335328 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005309876221329418  \tBatch training accuracy:  87.26679104477611  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.408730%,                 Avg loss: 0.303029 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0035162847581787487  \tBatch training accuracy:  87.67101990049751  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.053571%,                 Avg loss: 0.303555 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00426685743367494  \tBatch training accuracy:  86.61380597014924  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.218254%,                 Avg loss: 0.320820 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005647327398779381  \tBatch training accuracy:  87.46890547263682  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.954365%,                 Avg loss: 0.306425 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0042230880527354  \tBatch training accuracy:  87.56218905472637  \t[ 201 / 250 ]                        \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.210317%,                 Avg loss: 0.300287 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007215408543449136  \tBatch training accuracy:  87.40671641791045  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.408730%,                 Avg loss: 0.314900 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005548595418384419  \tBatch training accuracy:  87.17350746268657  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.954365%,                 Avg loss: 0.293595 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004272737313265824  \tBatch training accuracy:  87.20460199004975  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.160714%,                 Avg loss: 0.310952 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004710577539543607  \tBatch training accuracy:  87.79539800995025  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.297341 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004744149336767434  \tBatch training accuracy:  87.53109452736318  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.210317%,                 Avg loss: 0.308707 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006876655034164884  \tBatch training accuracy:  87.77985074626866  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.294389 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0051067450746374934  \tBatch training accuracy:  88.0907960199005  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.259921%,                 Avg loss: 0.304342 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.005142904780990449  \tBatch training accuracy:  87.90422885572139  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.904762%,                 Avg loss: 0.293575 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.002849645653174291  \tBatch training accuracy:  87.8886815920398  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.557540%,                 Avg loss: 0.301185 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005620245761539212  \tBatch training accuracy:  87.54664179104478  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.656746%,                 Avg loss: 0.285683 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005029142051193845  \tBatch training accuracy:  88.13743781094527  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.283573 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00306179578328014  \tBatch training accuracy:  88.02860696517413  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.294413 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006189508372871437  \tBatch training accuracy:  87.95087064676616  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.416667%,                 Avg loss: 0.329057 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0026643534946204418  \tBatch training accuracy:  87.06467661691542  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.656746%,                 Avg loss: 0.287850 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005373422630983798  \tBatch training accuracy:  87.71766169154229  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.962302%,                 Avg loss: 0.311238 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0048946128852331815  \tBatch training accuracy:  87.59328358208955  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.003968%,                 Avg loss: 0.292630 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003505716424676316  \tBatch training accuracy:  87.74875621890547  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.912698%,                 Avg loss: 0.312835 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005793439882311655  \tBatch training accuracy:  88.15298507462687  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.656746%,                 Avg loss: 0.309317 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005063687390949002  \tBatch training accuracy:  87.67101990049751  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.296343 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00427836802468371  \tBatch training accuracy:  87.98196517412936  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.292025 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0051732089240752645  \tBatch training accuracy:  88.05970149253731  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.301587%,                 Avg loss: 0.281125 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003933529207362465  \tBatch training accuracy:  87.76430348258707  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.284878 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007344408266579927  \tBatch training accuracy:  88.24626865671642  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.281586 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003515203052492284  \tBatch training accuracy:  87.28233830845771  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.103175%,                 Avg loss: 0.288000 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00554100835501258  \tBatch training accuracy:  87.7021144278607  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.003968%,                 Avg loss: 0.279031 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.002878488148029764  \tBatch training accuracy:  87.90422885572139  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.507937%,                 Avg loss: 0.303327 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004511427968295652  \tBatch training accuracy:  88.07524875621891  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.954365%,                 Avg loss: 0.285733 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0031869473742015325  \tBatch training accuracy:  88.35509950248756  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.288687 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005121538332149164  \tBatch training accuracy:  88.35509950248756  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.904762%,                 Avg loss: 0.292920 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006021707805234994  \tBatch training accuracy:  88.02860696517413  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.309524%,                 Avg loss: 0.308194 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005919793500236018  \tBatch training accuracy:  88.05970149253731  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.607143%,                 Avg loss: 0.280540 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005502307222257206  \tBatch training accuracy:  88.41728855721394  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.656746%,                 Avg loss: 0.279170 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003756157497861492  \tBatch training accuracy:  87.62437810945273  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.515873%,                 Avg loss: 0.316889 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003396118903041479  \tBatch training accuracy:  88.69713930348259  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.152778%,                 Avg loss: 0.290201 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004329858431175573  \tBatch training accuracy:  88.40174129353234  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.912698%,                 Avg loss: 0.299950 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004781385114536949  \tBatch training accuracy:  88.2929104477612  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.656746%,                 Avg loss: 0.295171 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004881003158009468  \tBatch training accuracy:  88.38619402985076  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.301587%,                 Avg loss: 0.272851 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004156643997377424  \tBatch training accuracy:  88.0907960199005  \t[ 201 / 250 ]                       \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.152778%,                 Avg loss: 0.283632 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003886885236744857  \tBatch training accuracy:  88.52611940298507  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.805556%,                 Avg loss: 0.291129 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004928866725655931  \tBatch training accuracy:  87.65547263681593  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.954365%,                 Avg loss: 0.275140 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0058271168772854025  \tBatch training accuracy:  88.40174129353234  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.359127%,                 Avg loss: 0.298786 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0034959389647441124  \tBatch training accuracy:  88.04415422885572  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.904762%,                 Avg loss: 0.283893 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004382817009788247  \tBatch training accuracy:  87.84203980099502  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.202381%,                 Avg loss: 0.283497 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.007113659411520507  \tBatch training accuracy:  88.68159203980099  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.400794%,                 Avg loss: 0.286789 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00497766313564718  \tBatch training accuracy:  87.99751243781094  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.202381%,                 Avg loss: 0.271348 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0032095283418152464  \tBatch training accuracy:  88.49502487562188  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.297761 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00401875161709477  \tBatch training accuracy:  88.23072139303483  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 85.267857%,                 Avg loss: 0.336567 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004336316342377544  \tBatch training accuracy:  88.71268656716418  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.202381%,                 Avg loss: 0.288243 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0028259658546590095  \tBatch training accuracy:  88.40174129353234  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.351190%,                 Avg loss: 0.277008 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0031939687123939174  \tBatch training accuracy:  88.61940298507463  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.300249 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006107778543263526  \tBatch training accuracy:  88.8681592039801  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.954365%,                 Avg loss: 0.293893 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006151255535249093  \tBatch training accuracy:  88.4794776119403  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.251984%,                 Avg loss: 0.286312 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003495101237771523  \tBatch training accuracy:  88.19962686567165  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.557540%,                 Avg loss: 0.301773 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003101454519513828  \tBatch training accuracy:  88.40174129353234  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.698413%,                 Avg loss: 0.281881 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004591151256466386  \tBatch training accuracy:  88.33955223880598  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.103175%,                 Avg loss: 0.285943 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0030187739809947227  \tBatch training accuracy:  88.4794776119403  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.400794%,                 Avg loss: 0.269438 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0047990988143047884  \tBatch training accuracy:  88.41728855721394  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.351190%,                 Avg loss: 0.269683 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005053993926119448  \tBatch training accuracy:  88.33955223880598  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 20.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.202381%,                 Avg loss: 0.283370 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004458200130889665  \tBatch training accuracy:  88.2929104477612  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.847222%,                 Avg loss: 0.268063 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004593146084552973  \tBatch training accuracy:  89.10136815920397  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 19.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.400794%,                 Avg loss: 0.288330 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.00513883935871409  \tBatch training accuracy:  88.99253731343283  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.251984%,                 Avg loss: 0.279456 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.004507592513193538  \tBatch training accuracy:  88.43283582089553  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 19.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.301587%,                 Avg loss: 0.288901 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004763592238449931  \tBatch training accuracy:  88.40174129353234  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 19.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.251984%,                 Avg loss: 0.278040 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005606961339267332  \tBatch training accuracy:  88.91480099502488  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.152778%,                 Avg loss: 0.280340 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.004873148503884747  \tBatch training accuracy:  88.51057213930348  \t[ 201 / 250 ]                      \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 87.251984%,                 Avg loss: 0.279481 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.006119419389696263  \tBatch training accuracy:  88.19962686567165  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.607143%,                 Avg loss: 0.294660 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.005484721405589165  \tBatch training accuracy:  88.54166666666666  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 86.755952%,                 Avg loss: 0.286203 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.003685801405811784  \tBatch training accuracy:  88.60385572139303  \t[ 201 / 250 ]                     \n",
      "Time taken for this epoch: 18.00s\n",
      "No TPUs\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# for gridsearch\n",
    "\n",
    "#!pip install pyyaml==5.4.1\n",
    "\n",
    "# %%\n",
    "from IPython import get_ipython  # type: ignore\n",
    "\n",
    "# %% \n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "from dotmap import DotMap\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import the PyTorch modules\n",
    "import torch  # type: ignore\n",
    "from torch import nn  # type: ignore\n",
    "from torch.optim import SGD, Adam, RMSprop, AdamW  # type: ignore\n",
    "\n",
    "# Import Tensorflow writer\n",
    "from torch.utils.tensorboard import SummaryWriter  # type: ignore\n",
    "\n",
    "# Import modules from XTransformers\n",
    "#from x_transformers.x_transformers import AttentionLayers, Encoder, ContinuousTransformerWrapper\n",
    "from transformers.optimization import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "# Import the giotto-deep modules\n",
    "from gdeep.data import OrbitsGenerator, DataLoaderKwargs\n",
    "from gdeep.topology_layers import SetTransformer, PersFormer\n",
    "#from gdeep.topology_layers import AttentionPooling\n",
    "from gdeep.topology_layers import ISAB, PMA, SAB\n",
    "from gdeep.pipeline import Pipeline\n",
    "from gdeep.search import Gridsearch\n",
    "import json\n",
    "#from gdeep.search import Gridsearch\n",
    "\n",
    "from optuna.pruners import MedianPruner, NopPruner\n",
    "\n",
    "# %%\n",
    "\n",
    "#Configs\n",
    "config_data = DotMap({\n",
    "    'batch_size_train': 32,\n",
    "    'num_orbits_per_class': 2_000,\n",
    "    'validation_percentage': 0.0,\n",
    "    'test_percentage': 0.0,\n",
    "    'num_jobs': 2,\n",
    "    'dynamical_system': 'classical_convention',\n",
    "    'homology_dimensions': (0, 1),\n",
    "    'dtype': 'float32',\n",
    "    'arbitrary_precision': False\n",
    "})\n",
    "\n",
    "\n",
    "config_model = DotMap({\n",
    "    'implementation': 'Old_SetTransformer', # SetTransformer, PersFormer,\n",
    "    # PytorchTransformer, DeepSet, X-Transformer\n",
    "    'dim_input': 4,\n",
    "    'num_outputs': 1,  # for classification tasks this should be 1\n",
    "    'num_classes': 5,  # number of classes\n",
    "    'dim_hidden': 64,\n",
    "    'num_heads': 4,\n",
    "    'num_induced_points': 64,\n",
    "    'layer_norm': False,  # use layer norm\n",
    "    'pre_layer_norm': False,\n",
    "    'num_layers_encoder': 2,\n",
    "    'num_layers_decoder': 1,\n",
    "    'attention_type': \"self_attention\",\n",
    "    'activation': \"nn.ReLU()\",\n",
    "    'dropout_enc': 0.0,\n",
    "    'dropout_dec': 0.0,\n",
    "    'optimizer': torch.optim.AdamW,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs': 1_000,\n",
    "    'pooling_type': \"attention\",\n",
    "    'weight_decay': 0.0,\n",
    "    'n_accumulated_grads': 0,\n",
    "    'bias_attention': True\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# Define the data loader\n",
    "\n",
    "\n",
    "dataloaders_dicts = DataLoaderKwargs(train_kwargs = {\"batch_size\":\n",
    "                                                        config_data.batch_size_train,},\n",
    "                                     val_kwargs = {\"batch_size\": 4},\n",
    "                                     test_kwargs = {\"batch_size\": 3})\n",
    "\n",
    "og = OrbitsGenerator(num_orbits_per_class=config_data.num_orbits_per_class,\n",
    "                     homology_dimensions = config_data.homology_dimensions,\n",
    "                     validation_percentage=config_data.validation_percentage,\n",
    "                     test_percentage=config_data.test_percentage,\n",
    "                     n_jobs=config_data.num_jobs,\n",
    "                     dynamical_system = config_data.dynamical_system,\n",
    "                     dtype=config_data.dtype,\n",
    "                     arbitrary_precision=config_data.arbitrary_precision,\n",
    "                     )\n",
    "\n",
    "if config_data.arbitrary_precision:\n",
    "    orbits = np.load(os.path.join('data', 'orbit5k_arbitrary_precision.npy'))\n",
    "    og.orbits_from_array(orbits)\n",
    "\n",
    "if config_data.dim_input == 2:\n",
    "    dl_train, _, _ = og.get_dataloader_orbits(dataloaders_dicts)\n",
    "else:\n",
    "    dl_train, _, _ = og.get_dataloader_persistence_diagrams(dataloaders_dicts)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "if config_model.implementation == 'SetTransformer':\n",
    "    model = SetTransformer(\n",
    "            dim_input=config_model.dim_input,\n",
    "            num_outputs=1,  # for classification tasks this should be 1\n",
    "            dim_output=config_model.num_classes,  # number of classes\n",
    "            dim_hidden=config_model.dim_hidden,\n",
    "            num_heads=config_model.num_heads,\n",
    "            num_inds=config_model.num_induced_points,\n",
    "            ln=config_model.layer_norm,  # use layer norm\n",
    "            n_layers_encoder=config_model.num_layers_encoder,\n",
    "            n_layers_decoder=config_model.num_layers_decoder,\n",
    "            attention_type=config_model.attention_type,\n",
    "            dropout=config_model.dropout\n",
    "    )\n",
    "\n",
    "elif config_model.implementation == 'PersFormer':\n",
    "    model = PersFormer(\n",
    "            dim_input=2,\n",
    "            dim_output=5,\n",
    "            n_layers=5,\n",
    "            hidden_size=32,\n",
    "            n_heads=4,\n",
    "            dropout=0.1,\n",
    "            layer_norm=True,\n",
    "            pre_layer_norm=False,\n",
    "            activation=nn.GELU,\n",
    "            attention_layer_type=\"self_attention\")\n",
    "\n",
    "elif config_model.implementation == 'PytorchTransformer':\n",
    "    model = PytorchTransformer(\n",
    "            dim_input=2,\n",
    "            dim_output=5,\n",
    "            hidden_size=64,\n",
    "            nhead=8,\n",
    "            activation='gelu',\n",
    "            norm_first=True,\n",
    "            num_layers=3,\n",
    "            dropout=0.0,\n",
    "    )\n",
    "elif config_model.implementation == 'DeepSet':\n",
    "    model = DeepSet(dim_input=2,\n",
    "                    dim_output=config_model.num_classes,\n",
    "                    dim_hidden=config_model.dim_hidden,\n",
    "                    n_layers_encoder=config_model.num_layers_encoder,\n",
    "                    n_layers_decoder=config_model.num_layers_decoder,\n",
    "                    pool=config_model.pooling_type).double()\n",
    "\n",
    "elif config_model.implementation == \"X-Transformer\":\n",
    "    model = \\\n",
    "    nn.Sequential(\n",
    "        ContinuousTransformerWrapper(\n",
    "            dim_in = 2,\n",
    "            use_pos_emb = True,\n",
    "            max_seq_len = None,\n",
    "            attn_layers = Encoder(\n",
    "                dim = config_model.dim_hidden,\n",
    "                depth = config_model.num_layers_encoder,\n",
    "                heads = config_model.num_heads,\n",
    "            ),\n",
    "        ),\n",
    "        AttentionPooling(hidden_dim = config_model.dim_hidden, q_length=1),\n",
    "        nn.Sequential(*[nn.Sequential(nn.Linear(config_model.dim_hidden,\n",
    "                            config_model.dim_hidden),\n",
    "                            nn.ReLU())\n",
    "                for _ in range(config_model.num_layers_decoder)]),\n",
    "        nn.Linear(config_model.dim_hidden, config_model.num_classes)\n",
    "    )\n",
    "    \n",
    "elif config_model.implementation == \"Old_SetTransformer\":\n",
    "    # initialize SetTransformer model\n",
    "    class SetTransformerOld(nn.Module):\n",
    "        \"\"\" Vanilla SetTransformer from\n",
    "        https://github.com/juho-lee/set_transformer/blob/master/main_pointcloud.py\n",
    "        \"\"\"\n",
    "        def __init__(\n",
    "            self,\n",
    "            dim_input=4,  # dimension of input data for each element in the set\n",
    "            num_outputs=1,\n",
    "            dim_output=5,  # number of classes\n",
    "            num_inds=32,  # number of induced points, see  Set Transformer paper\n",
    "            dim_hidden=128,\n",
    "            num_heads=\"4\",\n",
    "            layer_norm=\"False\",  # use layer norm\n",
    "            dropout=0.0,\n",
    "            num_layer_enc=2,\n",
    "            num_layer_dec=2,\n",
    "            activation=\"nn.Relu()\",\n",
    "            bias_attention=True,\n",
    "            attention_type=\"induced_attention\"\n",
    "        ):\n",
    "            super().__init__()\n",
    "            if attention_type==\"induced_attention\":\n",
    "                self.enc = nn.Sequential(\n",
    "                    ISAB(dim_input, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm), bias_attention=bias_attention),\n",
    "                    *[ISAB(dim_hidden, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm), bias_attention=bias_attention)\n",
    "                      for _ in range(num_layer_enc-1)],\n",
    "                )\n",
    "            else:\n",
    "                self.enc = nn.Sequential(\n",
    "                    SAB(dim_input, dim_hidden, eval(num_heads), ln=eval(layer_norm), bias_attention=bias_attention),\n",
    "                    *[SAB(dim_hidden, dim_hidden, eval(num_heads), ln=eval(layer_norm), bias_attention=bias_attention)\n",
    "                      for _ in range(num_layer_enc-1)],\n",
    "                )\n",
    "            self.dec = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                PMA(dim_hidden, eval(num_heads), num_outputs, ln=eval(layer_norm), bias_attention=bias_attention),\n",
    "                nn.Dropout(dropout),\n",
    "                *[nn.Sequential(nn.Linear(dim_hidden, dim_hidden),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(dropout)) for _ in range(num_layer_dec-1)],\n",
    "                nn.Linear(dim_hidden, dim_output),\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.dec(self.enc(input)).squeeze(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    model = SetTransformerOld(dim_input=4, dim_output=5,\n",
    "                           num_inds=config_model.num_induced_points,\n",
    "                           dim_hidden=config_model.dim_hidden,\n",
    "                           num_heads=str(config_model.num_heads),\n",
    "                           layer_norm=str(config_model.layer_norm),  # use layer norm\n",
    "                           dropout=config_model.dropout_dec,\n",
    "                           num_layer_enc=config_model.num_layers_encoder,\n",
    "                           num_layer_dec=config_model.num_layers_decoder,\n",
    "                           activation=config_model.activation,\n",
    "                           bias_attention=config_model.bias_attention,\n",
    "                           attention_type=config_model.attention_type)\n",
    "else:\n",
    "    raise Exception(\"Unknown Implementation\")\n",
    "# %%\n",
    "\n",
    "if config_data.dtype == \"float64\":\n",
    "    print(\"Use float64 model\")\n",
    "    model = model.double()\n",
    "else:\n",
    "    print(\"use float32 model\")\n",
    "    print(config_model)\n",
    "    print(config_data)\n",
    "    print(model)\n",
    "\n",
    "# %%\n",
    "# Do training and validation\n",
    "\n",
    "# initialise loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the Tensorflow writer\n",
    "#writer = SummaryWriter(comment=json.dumps(config_model.toDict())\\\n",
    "#                                + json.dumps(config_data.toDict()))\n",
    "writer = SummaryWriter(comment=config_model.implementation)\n",
    "\n",
    "# initialise pipeline class\n",
    "pipe = Pipeline(model, [dl_train, None], loss_fn, writer)\n",
    "# %%\n",
    "\n",
    "\n",
    "# train the model\n",
    "pipe.train(config_model.optimizer,\n",
    "           config_model.num_epochs,\n",
    "           cross_validation=False,\n",
    "           optimizers_param={\"lr\": config_model.learning_rate,\n",
    "                             \"weight_decay\": config_model.weight_decay},\n",
    "           n_accumulated_grads=config_model.n_accumulated_grads)\n",
    "\n",
    "# %%\n",
    "# keep training\n",
    "#pipe.train(Adam, 300, False, keep_training=True)\n",
    "\n",
    "# %%\n",
    "# %%\n",
    "# Gridsearch\n",
    "\n",
    "# initialise gridsearch\n",
    "# pruner = NopPruner()\n",
    "# search = Gridsearch(pipe, search_metric=\"accuracy\", n_trials=50, best_not_last=True, pruner=pruner)\n",
    "\n",
    "# dictionaries of hyperparameters\n",
    "optimizers_params = {\"lr\": [1e-3, 1e-0, None, True],\n",
    "                      \"weight_decay\": [0.0, 0.2, None, True] }\n",
    "dataloaders_params = {\"batch_size\": [8, 16, 2]}\n",
    "models_hyperparams = {\"n_layer_enc\": [2, 4],\n",
    "                      \"n_layer_dec\": [1, 5],\n",
    "                      \"num_heads\": [\"2\", \"4\", \"8\"],\n",
    "                      \"hidden_dim\": [\"16\", \"32\", \"64\"],\n",
    "                      \"dropout\": [0.0, 0.5, 0.05],\n",
    "                      \"layer_norm\": [\"True\", \"False\"],\n",
    "                      \"bias_attention\": [True, False]}#,\n",
    "                      #'pre_layer_norm': [\"True\", \"False\"]}\n",
    "    \n",
    "scheduler_params = {\"num_warmup_steps\": int(0.1 * config_model.num_epochs),  #(int) – The number of steps for the warmup phase.\n",
    "                    \"num_training_steps\": config_model.num_epochs, #(int) – The total number of training steps.\n",
    "                    \"num_cycle\": [1, 3, 1]}\n",
    "\n",
    "# starting the gridsearch\n",
    "search.start((AdamW,), n_epochs=config_model.num_epochs, cross_validation=False,\n",
    "            optimizers_params=optimizers_params,\n",
    "            dataloaders_params=dataloaders_params,\n",
    "            models_hyperparams=models_hyperparams, lr_scheduler=get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "            scheduler_params=scheduler_params)\n",
    "\n",
    "\n",
    "# %%\n",
    "#print(search.best_val_acc_gs, search.best_val_loss_gs)\n",
    "# %%\n",
    "#df_res = search._results()\n",
    "#df_res\n",
    "#df_res.to_csv('set_transformer_grid_search.csv')\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b19bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-30 22:31:52,685]\u001b[0m A new study created in memory with name: no-name-d7b40beb-47f0-46e2-8df0-1d7df3078751\u001b[0m\n",
      "\u001b[32m[I 2021-11-30 23:54:58,183]\u001b[0m Trial 0 finished with value: 36.7 and parameters: {'optimizer': 'Adam', 'lr': 9.625930908215547e-07, 'batch_size': 16, 'dropout': 0.0, 'n_layer_enc': 2, 'n_layer_dec': 5, 'num_heads': '4', 'hidden_dim': '64', 'layer_norm': 'False', 'bias_attention': 'False'}. Best is trial 0 with value: 36.7.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python Set_transformer_benchmark_orbit5k_persistence.py > self_attention_gridsearch.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f87a95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd7cd87130>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0d0lEQVR4nO2dd3hc5ZX/P+/MaNS7NKNuSS5Ili0XZIMbxTIYg4kJsATSaAnZ3WSTbPI8m2SzG7b8dpPdZNM2hA2bwKZCCD0EMOCCabEtY+PeNLblrlGxrJFs1ff3x8zIg5BsSTN3bns/z6PHmtFYc+69o+8957znPUdIKVEoFAqF+XDobYBCoVAoJoYScIVCoTApSsAVCoXCpCgBVygUCpOiBFyhUChMiiueb5aXlyfLy8vj+ZYKhUJherZs2dIipcwf/nxcBby8vJyGhoZ4vqVCoVCYHiHEkZGeVykUhUKhMClKwBUKhcKkKAFXKBQKk6IEXKFQKEyKEnCFQqEwKZcUcCHEo0KIZiHEzojncoQQrwkhDoT+zdbWTIVCoVAMZywe+P8BNwx77uvAGinlVGBN6LFCoVAo4sgl68CllBuEEOXDnl4FXBP6/pfAeuBrsTTMCPT2D/LLdw6T4BRU5qcxrzyHZLdTb7Msy1sHWth5ooPCzCTqynMozkrW2yTL4u/s4aktx0hPclFdmMGskkxcTpVRNRsT3cjjlVKeDH1/CvCO9kIhxAPAAwBlZWUTfDt9ePtgC//20p6hx26Xg4/MKuJzV1Uy1Zuuo2XW5J//uIsDzYGhxzOLM/nMkgpuri3C4RA6WmY9Xtx+gv94Ze/Q48zkBO6aX8Z9i8vxpCfpaJliPER9y5XBiRCjToWQUj4ipayTUtbl539oJ6ihafQHxeT1r1zN/907j7+4vIQ/bT/JDT96k39/aQ/negd0ttBaDEjJddO9vPTFJXzzxmq6evv50hPbuPXhd9hz8qze5lmKgcHgn+xrf3sVD318Lgsn5/LIhkbqv/cGv3znMIODatCLGZiogJ8WQhQChP5tjp1JxqHR30V2SgJTPGlcc5mHf/voTN75+lLuqCvhkQ0+bnv4HY62dettpnWQkOhyML0og89eVcnrf3s1P/jYLI61d3PLQ2/z9JZjeltoOQoyk7iptpCHP3k5a756DbPLsnjwhV385W+20Hm+T2/zFJdgogL+AnB36Pu7gedjY46xaPQHmJyf9oHnslPdfPvWWh67Z96QsOw+obxDLXA4BB+dU8LqL1/F3LJsvvqH9/nR6wdQYwC1oSIvlV/dN59/XDmdNXubueNnf6Y10KO3WYqLMJYywseBd4HLhBDHhBD3A98BrhNCHACWhR5bDp+/i8r81BF/dm2Vh2c/vwi3y8Fd//tndp3oiLN11kSID+e6c9MS+fX987ltbgk/eH0///Xqfh0ssybDz7cQgvsXV/DoPfM41BLgY48oETcylxRwKeVdUspCKWWClLJESvkLKWWrlLJeSjlVSrlMStkWD2PjSce5PloCPR/ywCOZnJ/Gk59bQKrbyb2PbebEmXNxtNB6XMyvdjkdfPf2Wu6aX8pP1h3k138esTmbYoxcKoi5elo+j90zn6Nt3XzmVw2c71PrPUZE1Q2Ngi+0gFl5EQEHKM1J4dF753Gud4B7H9tMoKc/HubZEodD8K+rZlBf5eHB53eybq8ll14Mw4LJufzwY7PZdvQMX3lym0pdGRAl4KPQ6O8CYPIoKZRIqgoyePiTl3OguZNvPrtDfdAniJSSSxULupwOfnzXHKoKMvjy77dxXEU9E0KG4p1Lne8VMwv5xooqXtpxil+8dUh7wxTjQgn4KPj8AVwOQWlOyphev3hqHl+5bhrPbzvBHxpUtYSWpCa6+Okn5jIwKPni41vpGxjU2yRL89kllSyv8fIfr+xl29EzepujiEAJ+Cg0+gOU5aaQMI7daX91zRQWT8njWy/s5HBLl4bWWZcR1jBHpDwvlX+/dSZbjrTz32sPamuUhRnL+RZC8J+3zcKTnsQXH99Kd69KExoFJeCj4PN3XXQBcyScDsF/3TGLBKeDrz29XW2GGCfjPVsfmVXELbOL+Om6g2qjzzgZb5YvMyWB798xi6a2br6vqoAMgxLwEegfGORIa/eoJYQXw5uRxDdvrGbjoTae2HxUA+sUkXzr5hoykxP42tPb6VepFE25ojKXT1xRxqNvH2JrU7ve5ihQAj4ix9rP0TswOG4PPMzH5pWyoDKXb7+8R9XQjgMpL72oNpycVDcPfqSG7cc6+N2mJk3ssiJhB1yM84x/fUUVnvQkvvnszqHt+Ar9UAI+Ar6WYAnhWCpQRkIIwb+sqqG7d4Dvv6bCTa25ubaQBZW5fP+1/Zzp7tXbHEuTnpTA399Uze6TZ/lDg4ow9UYJ+Ag0NgcXICvzJuaBA0z1pvOpKyfx+KYm9p5S+dmxMtJOzLH8n2/dPJ2z5/r40ZoDGlhlXSZwurm5tpC6Sdl879V9ql+KzigBHwFfS4CcVDfZqe6ofs+Xl00lPSmBf31xt6oNHwNy3MuYF6guzODO+WX8+t0jHIxoSasYmWg+juEbZkugl5+sUxVAeqIEfAQam7smnD6JJCvFzZeXTeXtg628dbAlBpYpLsZXr5tGUoKT77+2T29TLE9tSRa3zS3hsbcPc6rjvN7m2BYl4CPgawlElT6J5ONXlFGUmcR/vbpfeeGXYCKLmJHkpiVy36JyXtpxSjUXuwTRRDthvrxsKoODkoeUF64bSsCH0dHdR0ugl8me6D1wgESXk7+pn8q2o2dYt0/17tCa+5dUkpHk4gevqVy41pTmpHDHvFKe2NzEsXbVF18PlIAPozFUgRIrDxzg9stLKMtJ4fuvKS/8kkQ5OS0zOYHPLqnk9T2neV9t+74kE1nEjOQL105BIPiJ2g2rC0rAh9HYHO5CGBsPHCDB6eCL9VPZefys8sIvQqzubfcuriArJUFtsb8IsTrXRVnJfPyKMp7ackw1FtMBJeDD8LV0keAcexOrsbJqdhFFmUn8zxu+mP5exYdJS3Rx94JyXt9zmoPNnXqbY3k+e1UlEnhUdSuMO0rAh+HzByjLGV8Tq7GQ4HRw/5JKNh1q4z21DXlUxrszcDQ+vWASSQkOHtmgbpgXIxbnuzgrmY/MKuLxTU10dKu68HiiBHwYjRNoYjVW7pxXSmZyAo8oL1xzctMSuaOulGe3Huf0WVXmpjUPXFVJd+8Av9moJiXFEyXgEQSbWHVdcgrPRElNdPHpBZNYvfsUjX612WQkol1Ui+SzSyoZGJQqtI8D1YUZXHNZPo+9fUiNX4sjSsAjONp+jr4BGZNNPKNx98Jy3E6Hmm4yArGu0CnNSeGm2iJ+u7FJjbobRvhcx/KG+bmrJtMS6OXZrcdj90sVF0UJeARjnYMZDXlpiayaXcSz7x2n45zKF2rNfYvKCfT08+x7akqS1lxZmUN1YQa/fOewKpeNE0rAIwinNbT0wAE+vaCcc30DPLVFiUokkqjLwD/E7NIsaksy+eW7R5SoRBA+FbE830II7l4wib2nOtl8WC3UxwMl4BH4/F3kprrJSomuidWlmFGcyeWTsvnNn4+oqT0aI4Tg0wvKOdgc4N3GVr3NsTyrZheTkeTiV+8e1tsUW6AEPIJGf0CzCpThfHrBJA61dPGmanL1AWKZkw2zsraQ7JQEfqlERXOS3U7uqCvllZ2nVPVPHFACHoHP3xXTHZgXY8WMQvLSEvnVO4fj8n5mQKsMR1KCkzvnl/Ha7tNqt2CIoYk8GtwxP3nlJAak5Hcb1YQkrVECHuJMdy+tXb1xE3C3y8Fd80tZu69ZNQKKA5+4ogwJPKHGrmlOeV4qV0/L5/FNTWpOqcYoAQ/R6A9O4YlXCgXgjrpSALWYGUGsdmIOpyQ7haum5vPUlmNqlmME2pxtuHNeGc2dPbyx36/ROyhACfgQjXEoIRxOaU4Kiybn8YeGY2oxk9j0qL4YH5tXysmO82w4oERF64Kc+moPeWlufr9Zzc3UEiXgIXz+UBOr7OS4vu8d80o5fuYcbzeqxUzQZhEzzLJqLzmpbp5UoqI5CU4Ht84tYe3eZvydPXqbY1mUgIfw+QNMyk3FFeMmVpfi+uleMpMTlKeC9l6h2+Xgo3OKeX3PaVoD9haVcLSj5Q3zjrpS+gclz6hNVJqhBDxEsIQwPguYkSQlOPnonGJe3XWa9q7euL+/3fjYvFL6BqTa7h0HpnjSqJuUze8bjqpNVBoRlYALIf5WCLFLCLFTCPG4ECIpVobFk76BQZrauuOa/47kY/NK6R0Y5LltSlS09AgBpnnTmVOWxe83K1EBbcoII7ljXik+fxdbjqidmVowYQEXQhQDXwTqpJQzACdwZ6wMiydH27pDTaz0EfDqwgxqSzJ5ssHeoWa85PRjdaUcaA6wzcYj1+J177ppZiGpbidPNqgUoRZEm0JxAclCCBeQApyI3qT44wuVEMarBnwkbp1TzJ6TZ9l3yu4TZDR2wYEbawtxuxw8v82UH1dTkZro4oYZhby845RqM6sBExZwKeVx4HtAE3AS6JBSvjr8dUKIB4QQDUKIBr/fmOVbQ02sYjjIeLysnFWE0yFsnUaJl1eYkZTAddVe/vj+CfpsutEknsmjj84pprOnn7V71TzYWBNNCiUbWAVUAEVAqhDik8NfJ6V8REpZJ6Wsy8/Pn7ilGuLzd5GX5iYzJUE3G/LSErlqah7Pbz2uasLjwKrZRbR29fLWAVW+qTULJufiSU9UC8caEE0KZRlwSErpl1L2Ac8AC2NjVnxp9Aeo1NH7DnPLnGJOdJxn8+E2vU3RDa0XMcNcc5mHrJQEW0c88TrXTodg1ewi1u9rVpVWMSYaAW8CrhRCpIjgUnY9sCc2ZsUXX0sXkz365b/DXD+9gFS308aiEr/Iw+1ycNPMQlbvOmXPaT1xrsC5ZU4xfQOSP+04Gdf3tTrR5MA3Ak8B7wE7Qr/rkRjZFTfau3pp6+o1hAee7HayvKaAF7eftO2CT5ycQiCYmz3fN8iru07F8V3tyfTCDKZ60nhOpVFiSlRVKFLKB6WUVVLKGVLKT0kpTbe9zdcSWsA0gAcOQU+l83w/6/fZb8En3mXZl0/KpiQ72Za5WS2mH10MIQS3zCmm4Ug7Ta2q+2assP1OzHAXQiN44AALJ+eSrxZ84oIQgltmF/P2wRaa1fABzVk1uwiA522bIow9SsD9AdxOByVxbmI1Gi6ng5W1hazb56fzvP2GHsdrYS3MqtlFDEp4eadKo2hNSXYK88qzeXG7yoPHCtsLuM/fxaTclLg3sboYK2sL6e0fZM0ee6VR9CienOpNZ5o3jT/ZTFSk1H4b/UjcNLOQfac7Odhs9w1rscE4qqUT8ZyDOVbmlGZTmJmkPJU4cdPMIjYfaVMzHOPAipmFCAF/2q4inlhgawHvGxikqbVb1y30I+FwCG6cWciG/X7O2iiNIqXUbCLPxbiptgAp4WUblbhJpA5nGrwZScwrz+FPO1Qbg1hgawFvauumf1C/JlYX48aZhfQODLJmz2m9TbE8UzzpVBWkqxrlOLGytpD9pwPsP63SKNFiawE3QhOr0ZhTmkVRZpLtcrM6pGWBYG528+F2TnWoNIrW3DCjIJRGsddnWwtsLeB6zMEcKxfSKC10nLNHGkXPDjA31hYC8JJNvPDgIqY+7+1JT2J+eY6KeGKArQXc5w+Ql5ZIZrJ+Tawuxo21wTTK67tVGkVrJuenUVWQbhsB15uVtYUcbFZplGixtYA3+rsMmT4JM6c0i+KsZNt4KlLGd3fgcFbWFtJwpJ2THed0tCI+BHdi6ne2l88owCFQlVZRYmsB9xmwhDASIQQ3zizgzQN+OrrtkUbRkxtnhtMoqsRNazzpSVxRkcuftqtqlGiwrYC3dfXS3t2nyyDj8bBiZiF9A5K1++yRRtFjc0mYylAaZbXalRkXbpxZQKO/S23qiQLbCrgvPIXHwB44wOySLDzpiazeaX0BN8KQ4eU1BWw+0kZLwHR92caFjHc3qxG4bnoBAKt3Wf+zrRU2FnDjlhBG4nAIrq/x8sZ+v21bzMaT5TXBTT1q4Vh7CjKTmF2axWrVznfC2FbALzSxStHblEuyvKaAc30DbNhvzJmisUJ//xuqC9MpzUm2vKjotRNzOMtrCth+rIMTZ6y/cKwFNhbwLsrzUnA6jPAxvjhXVuaSkeRSoWYcEEKwfHoBbx9stWU3yHizvMYLoIZqTBDbCrjRK1AiSXA6qK/2smbvafotPkVdxzXMIZbPKKB3YJD1+6wd8RiByvw0pnrSlHMyQWwp4H0DgzS1Ga+J1cVYXuPlTHcfmw5ZeOCxEXIowNyybHJT3dZOo+i4E3M419d42XS4TQ08ngC2FPAjrcEmVkaZwjMWrpqWT6LLYW1RMQhOh+C66V7W7/PT068WjrVmeU0BA4OS11XjtnFjSwEfKiH0mEfAU9wurpqWz6u7Txui3E4L9N4dGMnymgICPf28c7BVb1M0wUjnemZxJkWZSbyqKn/GjS0FvNEkJYTDWV5TwMmO8+w43qG3KZZn4ZRc0hJdKuKJA0IIrq8pYMN+P929/XqbYypsKeA+f4D89EQykozZxGo0llV7cDqEpUXFKHnZRJeTay7L57XdpxkYtGbEYySur/HS0z9o+VLZWGNLAW/0B6jMM5f3DZCV4uaKihzLrtgbLTW0vKaA1q5ethxp19uUmCOlNMzNEmB+eQ7ZKQmW/WxrhS0F3NfSZar8dyTLawo42BwY6mWu0I5rqzy4nQ5VoxwHXOFS2T2n6bN4qWwssZ2At3X1cqa7z5QeOEB9tQfAkqPWDNCe4wOkJbq4cnIur++x3sKxEQ9nWbWXs+f72XzYwqWyMcZ2At5owgqUSEqyU6gqSOf1Pc16m2ILrqv2cLi1e2jh20oY6WYJsGRqHm6ngzXqsz1mbCfgQyWEJqoBH851071sOdLOmW7rbXwwUl4WYGl1cKu3FSMeo5Ga6GLhlFzWWDDi0QrbCXijvwu3y0FxdrLepkyY+movA4PSclu9jfg3W5yVTHVhhuW8Qom+vddHo77aa9mIRwtsJ+A+f4CK3FRTNLEajdriTPLTE3lNeYVxYVm1h4Yjaqt3PKivCq7xqF2ZY8N2Am70OZhjweEQLL3Mw4Z9fnr7rbNiL5GG9AqXVXsZlLB+v3W8cCNGOwBFWclML8xQKasxEpWACyGyhBBPCSH2CiH2CCEWxMowLejtDzaxMksXwotRX+2hs0et2MeDmaGI5/Xd1hFwMN4iZphl1R62HGlXEc8YiNYD/xHwipSyCpgF7IneJO1oautiYFCa3gMHWDw1j0SXw3KhphFFxeEQ1Fd5eGO/tSIeo7JsejDiWbfPWjdMLZiwgAshMoGrgF8ASCl7pZRnYmSXJoQXRqzggae4XSyakmepGmUjH0Z9tZdAT79l2vlKpDHvlsCMokw86YmWc060IBoPvALwA48JIbYKIX4uhPiQayuEeEAI0SCEaPD79a2aCNeAW8EDh2Aa5WjbOQ40q12ZWrN4ijUjHiPicAjqqz1s2N+iIp5LEI2Au4C5wMNSyjlAF/D14S+SUj4ipayTUtbl5+dH8XbR4/N34UlPJN1kTaxGo74qWKNsFVGRYFivMNntZPGUPNbstUbEY/RDqK8KRjwbD1mznW+siEbAjwHHpJQbQ4+fIijohqXRH7CM9w3Bqd4ziq1Xo2xU6qu9HG07x/7T1oh4DHqvBGBRKOJRn+2LM2EBl1KeAo4KIS4LPVUP7I6JVRogpcTn77JE/juSZdVe3mtqpyXQo7cpMcEoQwZGItyHxioRj5FJdjtZMjWP1yw8wCQWRFuF8jfAb4UQ24HZwL9HbZFGtHX10nGuj0oLCriUsG6vBTwVg/+dejOSqC3JtEyNshFr7iOpr/Zy/Mw59p3u1NsUwxKVgEspt4Xy27VSyluklIZtnHyhAsU6KRSAmqIMCjKSVKgZJ+qrvGw9esYyEY+RCe/KVJ/t0bHNTsyhJlYW88CFECyt9rDhgJ/zfeYfwGtwp5D6ag9SwlorRDwGxxOKeFTKanRsI+CN/gBul4OiLPM2sRqNZdUeunsH+LPP3Cv20ug5FIIRT2FmkunTKEabyDMa9VVeth09g79TRTwjYRsB9/m7qMwzdxOr0Vg4OY+kBIclvEKjXx0hBEurPLx5oIWefvNHPEYnHPGoXZkjYxsBt1oJYSRJCU4WT8lnzZ5mU6/Ym8X0ZdXeUMRj3l2ZRpt+NBoX1njMHfFohS0EvKd/gKPt5yyX/46kvtqjVuzjxILJucGIR4mK5oTXeFTEMzK2EPCm1m7LNLEajaUWWbE3Q142HPG8bvKIxyxcWOMxb8SjFbYQcCs1sRoNb0YSM4vNXaNsJikMRzxm3ZUppfHrwMMMrfGY+LOtFTYR8OAfWYVJJ9GPlfpqj+lrlI28EzOSpWpyTNwIRjx5KuIZAVsIuM/fhTfDOk2sRqO+Krgr06yzMs30xxmOeMxa+WOGks1IllZ5TR3xaIU9BLwlQKWJp9CPlRnFGXgzEk2dRjET9dUe3mtqp9WkEY85Yp0gqg/NyFhewKWUNDYHmOyxdvoEwjXKXjaYeHKMSdKywIU+NGaNeMyE2SMerbC8gLd29XL2fL8tPHAI9o/o6h0wZR9lcwX1wRplb0Yia/aazysMLmLqbcX4WFpl7ohHCywv4I3N1prCcynM3kfZTJpyIeJRk2PigYp4PozlBdzXYv0SwkiS3U4WmXRyjMnMBYIRjxlnZZrwVFNTlIEn3ZwRj1ZYXsAbmwMkuhwUW7CJ1WiEZ2UeVLMyNWeRqWdlmineUbMyR8LyAu5r6aIiLxWHBZtYjcaFGmUTplFMlpg1c8RjRpaGZmWaLeLRCssLeKM/YJv0SZjCzGRqijJYq0LNuGDGiMeMi5gAi8NrPOqzDVhcwHv6Bzja1m25KTxjob7Kw5Yj7bR39eptiuUZ6kOjStw0J9ntZOHkXNN33owVlhbwI63dDEosNwdzLNRXexmUsH6/OUQl/MdoQqdwKOIx1wYq84pffbWXprbuoRYZdsbSAm7VMWpjYWZxJvnpiebMg5sQM0Y8ZrxZgsnXeGKMpQU83IWwwoYpFIdDsPQyDxv2+ekbMM+KvRnzsmC+iMfMFGUlM70wg7VKwK0u4AEKMpJIS3TpbYouLK320NnTz2YTrNibPZ0ZjnjMsoHKrIuYYeqrPTQcaTNVxKMFlhZwn7/LNjswR2LxlDzcLodaXIsD4Yjnjf3minjMSjjieWO/vXdlWlbApZSWnoM5FlITXSyozGXNHuPXKIetM0s/8JFYWu2h83w/mw+riEdraoszyUtLNOkGqthhWQFvCfTSeb7flguYkSyr9nC4tXuopYBCO4YiHpOkUcx8s3Q4BEur8m0f8VhWwMMlRnYsIYzk2qFZmebwVMyclw1HPKrlaXxYWuU1TcSjFZYVcN/QHEz7plAASrJTqCpIN7xXaPQUz1hZVu3hUEuX4WuUJdLUN0uAJVPzcDsdtq5GsayAN/oDJCU4KMq0TxOr0Qiu2LfT0d2ntymWx2wRj5lJTXRx5eRcWy/SW1bAff4AFXlptmpiNRr11V4GBqWha5QvLGKaG/NEPHpbEBvCEY/P4BGPVlhWwBttXkIYyaySLHJT3YYXFatglojH7DdLiOhDY9PPtiUF/HzfAMfau21fgRLG6RBcW+Vh/b5mw6/Ymz0vC+aIeKxCOOKxazlh1AIuhHAKIbYKIV6MhUGxINzEyu4LmJHUV3k4e76fLUfa9TZlRKwS0oM5Ih4LnW6WVpkj4tGCWHjgXwL2xOD3xAw7N7EajSXT8klwCrW4FgciI55+A0c8wgrhDvaOeKIScCFECXAT8PPYmBMbwptWKvKUBx4mLdHFlZXGXbGXIZ/QMqISingaVMSjObNLs8hJdduy/j5aD/yHwN8Bo7oZQogHhBANQogGvz8+fQsam4NNrFJt2sRqNOqrPPj8XRxSuzI1Jxzx2FFU4o3TIbj2Mg/r9/kNHfFowYQFXAixEmiWUm652OuklI9IKeuklHX5+fkTfbtx0djSxWSP8r6HU1/tBVSNcjwIRzx2XVyLN/XVHjrO9Rl2jUcrovHAFwEfEUIcBp4AlgohfhMTq6JASomvOUBlnsp/D6c0J4Vp3jRDLq5ZKaQPY+SIR1pqGTO4KzPBKQybItSKCQu4lPIbUsoSKWU5cCewVkr5yZhZNkH8gR46e/pVBcoo1Fd72Xy4jY5z9luxjzdGj3gsstwAQHpSQnCNx6DnWissVwfe2Bz0duzexGo06qs89A9KNhi0j7KVRCUc8RgyD24tBxwIlhM2+rs4bMCIRytiIuBSyvVSypWx+F3R4msJlRB6lICPxJyybLJTEowpKhakvtrLpkNtnD1vvIjHSjdLgPqqUMRjo8+2JT3wpAQHhRlJeptiSMIr9usMWqNs5h7VIxGOeN7YZ8yIx0qU5aYw1ZNmqzSK5QTc1xJcwFRNrEanvtrLme4+th49o7cpQ1hxEROMG/FY9HQbOuLRAssJuN3HqI2FJdPycDmEKnGLA0aOeKwW7UCwnNDIazyxxlICHmxidU5tob8EGUkJXFGZY6hG+Bd2YupsiAYYM+Kxpg8+tyybrJQEQ322tcRSAn6ktRspUR74GFha5eVAc4Cm1m69TbE8Ro14rHizjIx4BgateZOKxFIC3qiaWI2ZZdWhPsp7DSYqehugAUaMeKxMfbWH9u4+tjZZf1empQQ83IVQNbG6NJNyU5mcn2qYXZkWjeiHMFrEY+XTfdW0/FDEY4zPtpZYSsAb/V0UZqomVmNlWbWXjYdabbNiryfhiOc1A6VRrBjtQDDimV+RY7iUlRZYSsB9/oBKn4yD62sK6BuQhgjth2ZiWlRVJuWmUlWQzupdp/Q2BbB+xLO8poCDzQEONlt7VqZlBFxKqeZgjpM5pVl40hN5ZacxRMXqLK8pYPPhNvydPXqbAlin9/pIXF8T3JVplBumVlhGwP2dPQR6+pUHPg4cDsHymgLW72/mXO+A3uYA1qxNDnPDjAKkhNd2Wz+015vCzGRml2ZZ3jmxjIAfDC1gKg98fKyYUcD5vkHe0HkclVXrkiOpKkinPDeFVwzgFVr/bAc/2zuOd3C0zRgLx1pgGQH3+YMdyJQHPj7mV+SQlZJgeU/FCAghWD6jgHcOthhiAK91Y50gy2sKAGunUSwj4I3+AMkJTgpUE6tx4XI6uK7ay5o9zfT267/V28JpWQBuqCmgf1Aarv7eipTnGWvhWAssI+C+0AKmamI1flbMLKCzp5+3G1t0s8EOIT3ArJIsCjOTdI947JCyAlgxo5CGI+00d57X2xRNsIyAB5tYqfTJRFg4OY+0RBerVRpFc8ILx2/s99PV06+vMTbwdcILx6/usmbEYwkBP983wPEz59QYtQmSlODk2ioPr+4+rVvHPJs4hEAwN9vTP8gbOnbMs8vpnuZNoyIvVfeIRyssIeCHW7tCTayUBz5RVswooK2rl82Hrd8/Qm/mV+SQm+rWXVRs4IAjhOCGGQW862vlTHev3ubEHEsI+NAcTNUDZcJcPS2fRJdD9wUfK28uCeN0CK6b7mXt3mZ6+o1Rf29lbqgpYGBQWrI3iiUE3KdqwKMmNdHFVdPyeWXnKQb1aMNpl5g+xPIZBQR6+nnrgE4LxzY637UlmRRlJvHyjpN6mxJzLCHgjf4ARZlJpLhVE6touGlmIafOnmeLjm04re9/B1k0OY/M5AT+tF0/UbFDtAPB41wxs5ANB/yGqL+PJZYQcF9Ll5pCHwOWTfeS6HLwx/dPxP29pZ1cQsDtcnBDTQGv7j7N+b74p1Hsdr5vnlVE34Bk9W5rLWaaXsCllDQ2B1T+OwakJbqor/bw0o6ThpvfaEVunlVEoKef9fv0yc3aw/8OMqskk9KcZF7UMeLRAtMLeHNnD129A8oDjxE31xbREuhl46E2Xd7fJlE9AFdW5pCX5uaPFhMVIyKE4ObaIt4+2EJrwBjdIGOB6QW8MdTvtzJPCXgsuLbKQ6rbGfc0ip3qwMO4nA5WzChkzZ7Tcd/UY8fzffOsIgYGJS9bqCbc/ALeEmpi5VEplFiQlODk+poCXt55SpfeKDZywIGgqJzvG9Rleoydoh0IdoOc4knTZY1HK8wv4M0BUtyqiVUsuXlWIR3n+njrYPx2CtrQIQSgblI2BRlJ/PH9+KZR7OiBh9Momw63cfqsNXqjmF7AfS3BJlZ2KYmKB4un5JOZnMCLcRYVO+JwCFbWFvLG/ua4l7hZeXjGaKycVYiU6Fq+GUvML+D+gMp/xxi3y8GKGfqUuNnxRmzVEjcjMjk/jZqiDP643RppFFMLeLiJldqBGXtW1gZL3NbujU+Jm13am45EbUkmZTkpvLAtfqJitzrwSFbWFrG16QxNreaf1DNhARdClAoh1gkhdgshdgkhvhRLw8bCoZZgEys1hSf2LJicizcjkWfeO6a3KZZHCMEts4t4u7GFkx3n4vi+cXsrQ7FqdhFCwDNbzf/ZjsYD7we+KqWcDlwJfF4IMT02Zo2NRtUDRTOcDsEtc4pZv89PSxzqZsP+oF1F5da5JUgJz22Njxdu44CHoqxkFk7O5Zn3jps+8puwgEspT0op3wt93wnsAYpjZdhYCM/BVDlwbbhtbgn9gzKuob1dKc9LpW5SNk+/d8z0omIGbp1TQlNbNw1HzN0+OSY5cCFEOTAH2DjCzx4QQjQIIRr8/tiWpTX6AxRnJZPsdsb09yqCTPOmM7M4k6fjmEaxqQMOBL3wg80Bdhzv0NsUy3PDjAJS3E6e3mLuNErUAi6ESAOeBr4spTw7/OdSykeklHVSyrr8/Pxo3+4DhOdgKrTjtrnF7Dpxlr2nPnRpY4pyOuGm2kLcLkdcRMXupzs10cWKGYX8aftJXZqJxYqoBFwIkUBQvH8rpXwmNiaNDSklPn9ALWBqzM2zinA5BM+8d1xvUyxPZnIC10/38sL7J+KyC9aOJZuR3Da3mM6efl7dbd55mdFUoQjgF8AeKeX3Y2fS2Dh9NtTESnngmpKblsi1VR6e3Xpc0w6FQ2VttheVEtq7+1incYdCFfHAlZW5FGUmmTqNEo0Hvgj4FLBUCLEt9HVjjOy6JBcqUJQHrjW3zS3G39nDm3pNj7ERS6bmkZ+eyFMmFhWz4HAIPjq3mDcP+E27tT6aKpS3pJRCSlkrpZwd+noplsZdjPAYNZVC0Z6lVV5yU908vqlJ8/eyt/8d7FB469xi1u5t1lxU7H6uAf7i8lIGJTy5+ajepkwI0+7EbPR3kep24s1I1NsUy+N2Obi9roQ1WoqKCumHuGteGQODUmNRUSccguWbi6bk8sTmowzoMQs2Skws4AEqVBOruBEfUVFA/ERF/ekE+fj8SRw/c44NB+LXfTNWmFbAff4ulT6JI1qLit13Yg5nSFT2ayMqahHzAtdN95KX5uZ3G7VPEcYaUwr4ud5QEyu1AzOuaC0qiguEReW3JhQVs+F2OfiLulLW7m3mVIe5FjNNKeCH1BQeXYiHqNixR/VIXBCV05o1uFLRzgXCKcLfmyxFaEoBHyohVB54XIkUleNnYisqKqT/MHfNK0MCj2+Kvaio0/1BynJTWDI1jyc2N9Gn4X6HWGNKAff5uxACKvKUBx5vPnFFGQC/evewvobYgLLcFK69zMPvNh7RZLu3inY+yN0LyjnZcZ7Vu8wzWMOUAt7oD1CUqZpY6UFJdgorZhTy+MammE5SD+/EVGH9B7l/cQUtgV5eiPEgXtXx8MMsrfJQnpvCL946pLcpY8aUAu5rCTDZo9InenHf4nLOnu+Pa5dCu7Jwci5VBek8+tYhJboa43AI7l1UwdamM7zXZI42s6YT8GATqy4qVfpEN+aWZTOrNIvH3j7MYIxLCpUD/kGEENy3qIK9pzp5t7E1xr87pr/OEtx+eQnpSS7TeOGmE/BTZ8/T3TugPHAdEUJw/+IKDrV0xWxmpnIuR+cjs4vITXXHVFTU6R6Z1EQXd80v45Wdp2K+UK8FphPwxuZQCaHywHVlxYwCijKTePiNRhXaa0xSgpNPLZjEmr3NMe3Lrhzwkbl7YTkC+N8NPr1NuSSmE3Bfi+pCaAQSnA7+8prJbDnSzru+6EN7tRPz4tyzsJxUt5OH1jXG5Pepe+7oFGcl89E5xTy+qYnmTmNv7DGfgKsmVobhjrpS8tMT+cnag3qbYnmyUtx8akE5L24/MbQPQqEdf33tFPoGBvnFm8bOhZtOwBv9ASrz01QTKwOQlODkc1dV8k5jK1uOtMXkd6ra5NH5zJIKEl0OHloXoxum+hsalYq8VG6eVcSv/3yEtq5evc0ZFdMJeLCJlcp/G4WPX1FGTqqbH6+JTlRUHv3S5KUl8vH5k3h+2wmOtHZF9bvU2b40X7h2Cuf6BnjUwBUpphLw7t7+YBMrlf82DCluF59dUskb+/1sOhQbL1wxOp+7uhKXQ/DD1w/obYrlmepN58YZhTz29iH8nT16mzMiphLwoSZWSsANxT0LyynISOLbL++ZsCc99N9UVH9RvBlJ3Le4gme3Hmfn8Y4J/x4ppTrVY+Cr10/jfP8gP15jzBumqQS80R8U8EqVQjEUyW4nX7luGlubzvDKTvP0kTArf3n1ZLJSEviPV/bqbYrlqcxP4+Pzy3h8U9PQGEcjYSoB9/kDqomVQbnt8hKmedP4z9X76O2feDc35RVemszkBP5m6VTePNASVW92tYY5Nr5YP5VEl4P/fGWf3qZ8CFMJeKO/i+KsZJISVBMro+F0CL6xoppDLV2m2YZsZj55ZRmTclP4pz/uoqc/9p0KFRfIT0/kc1dP5pVdpww3zMRUAu7zB1T+28BcW+VheY2XH63Zz9G2br3NsTSJLif//JEafP4uHnnD+DsGzc4DV1VSkZfKPz6/U5PWvhPFNAI+OBhqYqXy34bmwZtrcAjBgy/sGteCZvilqr5/7FxzmYebagv573UHOdwyvrJCKVW6ajwkJTj511UzONLazU/Xx2Y3bCwwjYCfOnuec30DqoTQ4BRlJfOV66axdm9zzHtYKz7Mt1ZOx+108I1ndsS8M6Tigyyemseq2UX8z/pG9pyMXU+aaDCNgPv84RJC5YEbnXsWlnP5pGz+4bmdHGsfXypFeYXjw5uRxD+urOZdXys/f2t8qRQV7Yyfb62cTmZKAl9+YpshUimmEfBw/weVAzc+LqeDH9wxGynhK0++T/8YZgxKtTdwwtxRV8ryGi/fXb1vzLXh6nxPjNy0RL57ey37TnfynZf1L+M0jYD7/AHSEl140lUTKzNQlpvCv6yqYdOhNr5tgA+6lRFC8J1ba8lNTeRzv95CS8CYuwatwjWXebh3UTn/985hnt2q71Qq0wh4Y2gBU4V95uHWuSXcs7CcX7x1iCcbxjZZXV3eiZGd6uaRT19OS6CHv/7Ne2OqxVeneuL8/Y3VXFmZw9ee3sG2o2d0s8M0Aq5KCM3JP9xUzeIpefz9MzsuOu1b9bKKntqSLP7z9lo2HW7ji49vpe8iqSt1vqMjwengp5+4HG9GIvc+timmgzbGgykEvLu3nxMd59UcTBPicjp4+JNzmVmSyRd+995FRRyUBx4tq2YX8+DN03ll1ym+9MTWi3ri6lxHR06qm1/fdwWJLief+N+Nuoi4KQR8qAJFzcE0JelJCfzyvvlML8rkr36zhf/d4PtQjbhyCGPHvYsq+Iebqnlpxyk++fONI+bElQceG8rzUvndZ6/A5RTc/vC7rNlzOq7vH5WACyFuEELsE0IcFEJ8PVZGDSdcgaI28ZiXjKQEHv/sFSyvKeDfXtrDPY9tHneJoWLsfGZJJT+6czbvHzvDDT/cwEs7Tqqe6xpRmZ/Gc59fRHleCvf/soF/eG4Hnef74vLeExZwIYQTeAhYAUwH7hJCTI+VYZH4/F0IAeW5SsDNTIrbxUMfn8s/3TydzYfbuPZ76/n609vZ6GtlYDAY6quJPLFj1exinvv8Igoyk/jr377Hqofe5uktx2gPTZhR5zp2FGYm84fPLeT+xRX8dmMTi76zlu+u3svuE2c1vXG6ovi/84GDUkofgBDiCWAVsDsWhkXS6A9Qkq2aWFkBh0Nwz6IKrqsp4OH1B3my4RhPbD6KQ2mJJlQXZvDcXy/iqS3HePiNRr76h/eBYP573qQcna2zFsluJ/+4cjofnVPMf689wEPrGnloXSNJCQ5KslP42acuj3khRjQCXgxE1oYdA64Y/iIhxAPAAwBlZWUTeqPqwgxKslMm9H8VxqQ4K5n/d8tMvnZDFW8eaGHH8Q7au3pZMDlXb9Msh8vp4M75ZdxRV8qO4x283djC0bZulkzN19s0SzKjOJOffaqO5s7zrN/rZ//pTo61nyM7xR3z9xITde+FELcDN0gpPxN6/CngCinlF0b7P3V1dbKhoWFC76dQKBR2RQixRUpZN/z5aBYxjwOlEY9LQs8pFAqFIg5EI+CbgalCiAohhBu4E3ghNmYpFAqF4lJMOAcupewXQnwBWA04gUellLtiZplCoVAoLko0i5hIKV8CXoqRLQqFQqEYB6bYialQKBSKD6MEXKFQKEyKEnCFQqEwKUrAFQqFwqRMeCPPhN5MCD9wZIL/PQ9oiaE5ZkAdsz1Qx2wPojnmSVLKD22djauAR4MQomGknUhWRh2zPVDHbA+0OGaVQlEoFAqTogRcoVAoTIqZBPwRvQ3QAXXM9kAdsz2I+TGbJgeuUCgUig9iJg9coVAoFBEoAVcoFAqTYgoBj9fw5HgihCgVQqwTQuwWQuwSQnwp9HyOEOI1IcSB0L/ZoeeFEOLHoXOwXQgxV98jmDhCCKcQYqsQ4sXQ4wohxMbQsf0+1J4YIURi6PHB0M/LdTV8ggghsoQQTwkh9goh9gghFlj9Ogsh/jb0ud4phHhcCJFktesshHhUCNEshNgZ8dy4r6sQ4u7Q6w8IIe4ejw2GF/B4Dk+OM/3AV6WU04Ergc+HjuvrwBop5VRgTegxBI9/aujrAeDh+JscM74E7Il4/B/AD6SUU4B24P7Q8/cD7aHnfxB6nRn5EfCKlLIKmEXw2C17nYUQxcAXgTop5QyC7abvxHrX+f+AG4Y9N67rKoTIAR4kOI5yPvBgWPTHhJTS0F/AAmB1xONvAN/Q2y4NjvN54DpgH1AYeq4Q2Bf6/mfAXRGvH3qdmb4ITm5aAywFXgQEwd1pruHXm2Cv+QWh712h1wm9j2Gcx5sJHBput5WvMxfm5eaErtuLwHIrXmegHNg50esK3AX8LOL5D7zuUl+G98AZeXhysU62aEIoZJwDbAS8UsqToR+dAryh761yHn4I/B0wGHqcC5yRUvaHHkce19Axh37eEXq9magA/MBjobTRz4UQqVj4OkspjwPfA5qAkwSv2xasfZ3DjPe6RnW9zSDglkYIkQY8DXxZSnk28mcyeEu2TJ2nEGIl0Cyl3KK3LXHEBcwFHpZSzgG6uBBWA5a8ztnAKoI3ryIglQ+nGixPPK6rGQTcssOThRAJBMX7t1LKZ0JPnxZCFIZ+Xgg0h563wnlYBHxECHEYeIJgGuVHQJYQIjwdKvK4ho459PNMoDWeBseAY8AxKeXG0OOnCAq6la/zMuCQlNIvpewDniF47a18ncOM97pGdb3NIOCWHJ4shBDAL4A9UsrvR/zoBSC8En03wdx4+PlPh1azrwQ6IkI1UyCl/IaUskRKWU7wOq6VUn4CWAfcHnrZ8GMOn4vbQ683lacqpTwFHBVCXBZ6qh7YjYWvM8HUyZVCiJTQ5zx8zJa9zhGM97quBq4XQmSHIpfrQ8+NDb0XAca4UHAjsB9oBL6ptz0xOqbFBMOr7cC20NeNBHN/a4ADwOtATuj1gmA1TiOwg+AKv+7HEcXxXwO8GPq+EtgEHAT+ACSGnk8KPT4Y+nml3nZP8FhnAw2ha/0ckG316wz8M7AX2An8Gki02nUGHieY4+8jGGndP5HrCtwXOvaDwL3jsUFtpVcoFAqTYoYUikKhUChGQAm4QqFQmBQl4AqFQmFSlIArFAqFSVECrlAoFCZFCbhCoVCYFCXgCoVCYVL+P991bXCuuJBkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "model = torch.nn.Linear(2, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=10)\n",
    "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, 100, 1_000, 3)\n",
    "lrs = []\n",
    "\n",
    "for i in range(1_000):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "#     print(\"Factor = \",0.1 if i!=0 and i%2!=0 else 1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(range(1_000),lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d5b8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_optimizer as optim\n",
    "\n",
    "# model = ...\n",
    "optimizer = optim.Shampoo(\n",
    "    m.parameters(),\n",
    "    lr=1e-1,\n",
    "    momentum=0.0,\n",
    "    weight_decay=0.0,\n",
    "    epsilon=1e-4,\n",
    "    update_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbca5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dicts = DataLoaderKwargs(train_kwargs = {\"batch_size\":\n",
    "                                                        config_data.batch_size_train,\n",
    "                                                    \"shuffle\":True},\n",
    "                                     val_kwargs = {\"batch_size\": 16},\n",
    "                                     test_kwargs = {\"batch_size\": 3})\n",
    "\n",
    "og = OrbitsGenerator(num_orbits_per_class=1_000,\n",
    "                     homology_dimensions = config_data.homology_dimensions,\n",
    "                     validation_percentage=0.2,\n",
    "                     test_percentage=config_data.test_percentage,\n",
    "                     n_jobs=config_data.num_jobs,\n",
    "                     dynamical_system = config_data.dynamical_system,\n",
    "                     dtype=config_data.dtype,\n",
    "                     arbitrary_precision=False,\n",
    "                     )\n",
    "dl_train, dl_val, _ = og.get_dataloader_persistence_diagrams(dataloaders_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d5ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | enc     | Sequential       | 249 K \n",
      "1 | dec     | Sequential       | 83.3 K\n",
      "2 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "332 K     Trainable params\n",
      "0         Non-trainable params\n",
      "332 K     Total params\n",
      "1.331     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930c55805f504eaca24488e676d3a601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SetTransformerOld(pl.LightningModule):\n",
    "    \"\"\" Vanilla SetTransformer from\n",
    "    https://github.com/juho-lee/set_transformer/blob/master/main_pointcloud.py\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_input=4,  # dimension of input data for each element in the set\n",
    "        num_outputs=1,\n",
    "        dim_output=5,  # number of classes\n",
    "        num_inds=32,  # number of induced points, see  Set Transformer paper\n",
    "        dim_hidden=128,\n",
    "        num_heads=\"4\",\n",
    "        layer_norm=\"False\",  # use layer norm\n",
    "        dropout=0.0,\n",
    "        num_layer_enc=2,\n",
    "        num_layer_dec=2,\n",
    "        activation=\"nn.Relu()\",\n",
    "        bias_attention=True,\n",
    "        attention_type=\"induced_attention\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if attention_type==\"induced_attention\":\n",
    "            self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm), bias_attention=bias_attention),\n",
    "                *[ISAB(dim_hidden, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm), bias_attention=bias_attention)\n",
    "                  for _ in range(num_layer_enc-1)],\n",
    "            )\n",
    "        else:\n",
    "            self.enc = nn.Sequential(\n",
    "                SAB(dim_input, dim_hidden, eval(num_heads), ln=eval(layer_norm), bias_attention=bias_attention),\n",
    "                *[SAB(dim_hidden, dim_hidden, eval(num_heads), ln=eval(layer_norm), bias_attention=bias_attention)\n",
    "                  for _ in range(num_layer_enc-1)],\n",
    "            )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            PMA(dim_hidden, eval(num_heads), num_outputs, ln=eval(layer_norm), bias_attention=bias_attention),\n",
    "            nn.Dropout(dropout),\n",
    "            *[nn.Sequential(nn.Linear(dim_hidden, dim_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(dropout)) for _ in range(num_layer_dec-1)],\n",
    "            nn.Linear(dim_hidden, dim_output),\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.dec(self.enc(input)).squeeze(dim=1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        x_hat = self.forward(x)\n",
    "        loss = self.loss_fn(x_hat, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def val_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        x_hat = self.forward(x)\n",
    "        acc = accuracy_score(x_hat, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        print(\"acc\", acc)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "model = SetTransformerOld(dim_input=4, dim_output=5,\n",
    "                       num_inds=config_model.num_induced_points,\n",
    "                       dim_hidden=config_model.dim_hidden,\n",
    "                       num_heads=str(config_model.num_heads),\n",
    "                       layer_norm=str(config_model.layer_norm),  # use layer norm\n",
    "                       dropout=config_model.dropout_dec,\n",
    "                       num_layer_enc=config_model.num_layers_encoder,\n",
    "                       num_layer_dec=config_model.num_layers_decoder,\n",
    "                       activation=config_model.activation,\n",
    "                       bias_attention=config_model.bias_attention,\n",
    "                       attention_type=config_model.attention_type)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, log_every_n_steps=1, gpus=1)\n",
    "trainer.fit(model, dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7df5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:giottodeep]",
   "language": "python",
   "name": "conda-env-giottodeep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
