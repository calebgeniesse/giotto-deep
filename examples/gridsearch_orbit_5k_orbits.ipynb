{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddbfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.4.1 in /home/jovyan/conda-envs/giottodeep/lib/python3.8/site-packages (5.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/jovyan/conda-envs/giottodeep/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "use float32 model\n",
      "SetTransformerOld(\n",
      "  (enc): Sequential(\n",
      "    (0): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=4, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=4, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=4, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (ln0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (6): Linear(in_features=32, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.032001428084798375  \tBatch training accuracy:  19.74009900990099  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.676587%,                 Avg loss: 1.608815 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185076288657614  \tBatch training accuracy:  20.276402640264028  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.608940 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03189474167210041  \tBatch training accuracy:  19.16254125412541  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609081 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031875957356821194  \tBatch training accuracy:  19.471947194719473  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609171 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186254218073174  \tBatch training accuracy:  19.843234323432345  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 9.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609351 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031934577639740294  \tBatch training accuracy:  19.822607260726073  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609423 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03196156851135858  \tBatch training accuracy:  20.317656765676567  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609521 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188049911272408  \tBatch training accuracy:  20.627062706270628  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609509 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188807657449552  \tBatch training accuracy:  20.152640264026402  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609531 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187050205646175  \tBatch training accuracy:  19.822607260726073  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609567 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188611493252291  \tBatch training accuracy:  19.76072607260726  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609587 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318707546385208  \tBatch training accuracy:  19.71947194719472  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609658 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187246605901435  \tBatch training accuracy:  19.245049504950494  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609604 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188412378330042  \tBatch training accuracy:  20.13201320132013  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609635 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.03185298655292775  \tBatch training accuracy:  19.966996699669966  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609644 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031896754066542826  \tBatch training accuracy:  19.966996699669966  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609651 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031861776172524635  \tBatch training accuracy:  20.42079207920792  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609678 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188085438001274  \tBatch training accuracy:  20.09075907590759  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609703 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031855217301019347  \tBatch training accuracy:  19.822607260726073  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.692460%,                 Avg loss: 1.609710 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185583695326701  \tBatch training accuracy:  20.13201320132013  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609755 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187862481221114  \tBatch training accuracy:  19.636963696369637  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609718 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031857566078110494  \tBatch training accuracy:  20.13201320132013  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609754 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186303436165989  \tBatch training accuracy:  20.565181518151814  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609776 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031868218195320354  \tBatch training accuracy:  20.255775577557756  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609793 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031896756427122815  \tBatch training accuracy:  20.173267326732674  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609782 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185869325505625  \tBatch training accuracy:  20.317656765676567  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609805 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318533725077563  \tBatch training accuracy:  19.801980198019802  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609790 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318656062135602  \tBatch training accuracy:  20.6476897689769  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609808 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031881736056639416  \tBatch training accuracy:  19.16254125412541  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609782 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186216684851316  \tBatch training accuracy:  19.471947194719473  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609790 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186964280534499  \tBatch training accuracy:  20.585808580858085  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609794 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031840200471405934  \tBatch training accuracy:  20.358910891089106  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609797 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031883397904953155  \tBatch training accuracy:  20.606435643564357  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609790 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031893272211055944  \tBatch training accuracy:  21.10148514851485  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609831 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318726112346838  \tBatch training accuracy:  20.317656765676567  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609820 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185193609483171  \tBatch training accuracy:  20.462046204620464  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609823 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031841731307530166  \tBatch training accuracy:  20.358910891089106  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609816 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185324621672678  \tBatch training accuracy:  20.152640264026402  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609787 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031874347441267256  \tBatch training accuracy:  20.111386138613863  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609801 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031843138213204863  \tBatch training accuracy:  20.42079207920792  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609799 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185233503285021  \tBatch training accuracy:  20.09075907590759  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609843 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031893117593066525  \tBatch training accuracy:  20.40016501650165  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609818 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.031855852297036955  \tBatch training accuracy:  20.33828382838284  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609826 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187735009901595  \tBatch training accuracy:  20.09075907590759  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609817 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031876848475767834  \tBatch training accuracy:  20.008250825082506  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609819 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03190385941231605  \tBatch training accuracy:  19.4513201320132  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609840 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318418564182697  \tBatch training accuracy:  20.379537953795378  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609821 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186425832238528  \tBatch training accuracy:  20.585808580858085  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609826 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185605530691619  \tBatch training accuracy:  19.884488448844884  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609855 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031856545127264345  \tBatch training accuracy:  20.9983498349835  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609828 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031862549262471715  \tBatch training accuracy:  20.07013201320132  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609839 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185620638403562  \tBatch training accuracy:  20.606435643564357  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609823 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186831615938999  \tBatch training accuracy:  20.379537953795378  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609842 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031883681174552085  \tBatch training accuracy:  20.42079207920792  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609829 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031866725128475985  \tBatch training accuracy:  20.75082508250825  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609848 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186147047741578  \tBatch training accuracy:  20.152640264026402  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609835 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185645306464469  \tBatch training accuracy:  20.977722772277225  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609830 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186132648203632  \tBatch training accuracy:  19.78135313531353  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609808 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185970948474242  \tBatch training accuracy:  20.379537953795378  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609822 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187979093872675  \tBatch training accuracy:  20.833333333333336  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609837 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03183959734321821  \tBatch training accuracy:  20.13201320132013  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609845 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188986353354879  \tBatch training accuracy:  20.6476897689769  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609832 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03184788297898698  \tBatch training accuracy:  21.06023102310231  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609826 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031840070639506425  \tBatch training accuracy:  20.214521452145213  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609810 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187554189474276  \tBatch training accuracy:  20.565181518151814  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609831 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031861547196265494  \tBatch training accuracy:  20.23514851485149  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609802 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318705150396517  \tBatch training accuracy:  20.812706270627064  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609815 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185811373266843  \tBatch training accuracy:  21.142739273927393  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609804 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031841894187549555  \tBatch training accuracy:  20.441419141914192  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609816 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03191454693822578  \tBatch training accuracy:  20.42079207920792  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609839 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.03185523854623927  \tBatch training accuracy:  20.42079207920792  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609829 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031858284874717785  \tBatch training accuracy:  19.698844884488448  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609836 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185758496275042  \tBatch training accuracy:  20.627062706270628  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609814 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031870551628641566  \tBatch training accuracy:  20.23514851485149  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609825 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188071864666325  \tBatch training accuracy:  20.6476897689769  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609826 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185845011531716  \tBatch training accuracy:  20.13201320132013  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609814 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187472041290585  \tBatch training accuracy:  21.555280528052805  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609825 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186696118647509  \tBatch training accuracy:  19.76072607260726  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609794 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186788653383161  \tBatch training accuracy:  19.884488448844884  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609817 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186784640397176  \tBatch training accuracy:  20.40016501650165  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609831 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188716421032896  \tBatch training accuracy:  20.441419141914192  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609821 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188503732775698  \tBatch training accuracy:  20.70957095709571  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609839 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318828561518452  \tBatch training accuracy:  20.23514851485149  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609819 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186190128326416  \tBatch training accuracy:  20.33828382838284  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609818 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187032147209243  \tBatch training accuracy:  20.668316831683168  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609837 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03183881481095116  \tBatch training accuracy:  20.668316831683168  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609845 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188617984847267  \tBatch training accuracy:  20.668316831683168  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609819 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188663898128094  \tBatch training accuracy:  20.75082508250825  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609842 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186625891392774  \tBatch training accuracy:  20.833333333333336  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609824 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186655752729661  \tBatch training accuracy:  20.19389438943894  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609826 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188015682862537  \tBatch training accuracy:  19.905115511551156  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609826 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031867781488022  \tBatch training accuracy:  20.19389438943894  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609812 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031867452187113246  \tBatch training accuracy:  19.843234323432345  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609801 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031880032898175835  \tBatch training accuracy:  20.40016501650165  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609825 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03185962922502272  \tBatch training accuracy:  20.585808580858085  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609822 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031864081278885945  \tBatch training accuracy:  20.585808580858085  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609822 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.0318696935578148  \tBatch training accuracy:  19.987623762376238  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609845 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03189252036632878  \tBatch training accuracy:  20.833333333333336  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609810 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  0.03186564044197007  \tBatch training accuracy:  20.606435643564357  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609831 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03188209368450807  \tBatch training accuracy:  20.48267326732673  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609814 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031860588800789104  \tBatch training accuracy:  20.462046204620464  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609821 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.031884034081260754  \tBatch training accuracy:  20.544554455445542  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609832 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03186756077379283  \tBatch training accuracy:  20.523927392739274  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609811 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  0.03187875110324066  \tBatch training accuracy:  20.09075907590759  \t[ 101 / 167 ]                     \n",
      "Time taken for this epoch: 8.00s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.353175%,                 Avg loss: 1.609827 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6087368726730347  \tBatch training accuracy:  20.833333333333336  \t[ 1 / 167 ]                     \r"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# for gridsearch\n",
    "\n",
    "!pip install pyyaml==5.4.1\n",
    "\n",
    "# %%\n",
    "from IPython import get_ipython  # type: ignore\n",
    "\n",
    "# %% \n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "from dotmap import DotMap\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import the PyTorch modules\n",
    "import torch  # type: ignore\n",
    "from torch import nn  # type: ignore\n",
    "from torch.optim import SGD, Adam, RMSprop  # type: ignore\n",
    "\n",
    "# Import Tensorflow writer\n",
    "from torch.utils.tensorboard import SummaryWriter  # type: ignore\n",
    "\n",
    "# Import modules from XTransformers\n",
    "from x_transformers.x_transformers import AttentionLayers, Encoder, ContinuousTransformerWrapper\n",
    "\n",
    "\n",
    "# Import the giotto-deep modules\n",
    "from gdeep.data import OrbitsGenerator, DataLoaderKwargs\n",
    "from gdeep.topology_layers import SetTransformer, PersFormer\n",
    "#from gdeep.topology_layers import AttentionPooling\n",
    "from gdeep.topology_layers import ISAB, PMA, SAB\n",
    "from gdeep.pipeline import Pipeline\n",
    "from gdeep.search import Gridsearch\n",
    "import json\n",
    "#from gdeep.search import Gridsearch\n",
    "\n",
    "from optuna.pruners import MedianPruner, NopPruner\n",
    "\n",
    "# %%\n",
    "\n",
    "#Configs\n",
    "config_data = DotMap({\n",
    "    'batch_size_train': 48,\n",
    "    'num_orbits_per_class': 2_000,\n",
    "    'validation_percentage': 0.0,\n",
    "    'test_percentage': 0.0,\n",
    "    'num_jobs': 2,\n",
    "    'dynamical_system': 'classical_convention',\n",
    "    'homology_dimensions': (0, 1),\n",
    "    'dtype': 'float32',\n",
    "    'arbitrary_precision': False\n",
    "})\n",
    "\n",
    "\n",
    "config_model = DotMap({\n",
    "    'implementation': 'Old_SetTransformer', # SetTransformer, PersFormer,\n",
    "    # PytorchTransformer, DeepSet, X-Transformer\n",
    "    'dim_input': 4,\n",
    "    'num_outputs': 1,  # for classification tasks this should be 1\n",
    "    'num_classes': 5,  # number of classes\n",
    "    'dim_hidden': 32,\n",
    "    'num_heads': 8,\n",
    "    'num_induced_points': 64,\n",
    "    'layer_norm': False,  # use layer norm\n",
    "    'pre_layer_norm': False,\n",
    "    'num_layers_encoder': 4,\n",
    "    'num_layers_decoder': 4,\n",
    "    'attention_type': \"induced_attention\",\n",
    "    'activation': nn.GELU,\n",
    "    'dropout': 0.2,\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs': 2000,\n",
    "    'pooling_type': \"max\",\n",
    "    'weight_decay': 0.2,\n",
    "    'n_accumulated_grads': 0,\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# Define the data loader\n",
    "\n",
    "\n",
    "# dataloaders_dicts = DataLoaderKwargs(train_kwargs = {\"batch_size\":\n",
    "#                                                         config_data.batch_size_train,},\n",
    "#                                      val_kwargs = {\"batch_size\": 4},\n",
    "#                                      test_kwargs = {\"batch_size\": 3})\n",
    "\n",
    "# og = OrbitsGenerator(num_orbits_per_class=config_data.num_orbits_per_class,\n",
    "#                      homology_dimensions = config_data.homology_dimensions,\n",
    "#                      validation_percentage=config_data.validation_percentage,\n",
    "#                      test_percentage=config_data.test_percentage,\n",
    "#                      n_jobs=config_data.num_jobs,\n",
    "#                      dynamical_system = config_data.dynamical_system,\n",
    "#                      dtype=config_data.dtype,\n",
    "#                      arbitrary_precision=config_data.arbitrary_precision,\n",
    "#                      )\n",
    "\n",
    "# if config_data.arbitrary_precision:\n",
    "#     orbits = np.load(os.path.join('data', 'orbit5k_arbitrary_precision.npy'))\n",
    "#     og.orbits_from_array(orbits)\n",
    "\n",
    "# if config_data.dim_input == 2:\n",
    "#     dl_train, _, _ = og.get_dataloader_orbits(dataloaders_dicts)\n",
    "# else:\n",
    "#     dl_train, _, _ = og.get_dataloader_persistence_diagrams(dataloaders_dicts)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "if config_model.implementation == 'SetTransformer':\n",
    "    model = SetTransformer(\n",
    "            dim_input=config_model.dim_input,\n",
    "            num_outputs=1,  # for classification tasks this should be 1\n",
    "            dim_output=config_model.num_classes,  # number of classes\n",
    "            dim_hidden=config_model.dim_hidden,\n",
    "            num_heads=config_model.num_heads,\n",
    "            num_inds=config_model.num_induced_points,\n",
    "            ln=config_model.layer_norm,  # use layer norm\n",
    "            n_layers_encoder=config_model.num_layers_encoder,\n",
    "            n_layers_decoder=config_model.num_layers_decoder,\n",
    "            attention_type=config_model.attention_type,\n",
    "            dropout=config_model.dropout\n",
    "    )\n",
    "\n",
    "elif config_model.implementation == 'PersFormer':\n",
    "    model = PersFormer(\n",
    "            dim_input=2,\n",
    "            dim_output=5,\n",
    "            n_layers=5,\n",
    "            hidden_size=32,\n",
    "            n_heads=4,\n",
    "            dropout=0.1,\n",
    "            layer_norm=True,\n",
    "            pre_layer_norm=False,\n",
    "            activation=nn.GELU,\n",
    "            attention_layer_type=\"self_attention\")\n",
    "\n",
    "elif config_model.implementation == 'PytorchTransformer':\n",
    "    model = PytorchTransformer(\n",
    "            dim_input=2,\n",
    "            dim_output=5,\n",
    "            hidden_size=64,\n",
    "            nhead=8,\n",
    "            activation='gelu',\n",
    "            norm_first=True,\n",
    "            num_layers=3,\n",
    "            dropout=0.0,\n",
    "    )\n",
    "elif config_model.implementation == 'DeepSet':\n",
    "    model = DeepSet(dim_input=2,\n",
    "                    dim_output=config_model.num_classes,\n",
    "                    dim_hidden=config_model.dim_hidden,\n",
    "                    n_layers_encoder=config_model.num_layers_encoder,\n",
    "                    n_layers_decoder=config_model.num_layers_decoder,\n",
    "                    pool=config_model.pooling_type).double()\n",
    "\n",
    "elif config_model.implementation == \"X-Transformer\":\n",
    "    model = \\\n",
    "    nn.Sequential(\n",
    "        ContinuousTransformerWrapper(\n",
    "            dim_in = 2,\n",
    "            use_pos_emb = True,\n",
    "            max_seq_len = None,\n",
    "            attn_layers = Encoder(\n",
    "                dim = config_model.dim_hidden,\n",
    "                depth = config_model.num_layers_encoder,\n",
    "                heads = config_model.num_heads,\n",
    "            ),\n",
    "        ),\n",
    "        AttentionPooling(hidden_dim = config_model.dim_hidden, q_length=1),\n",
    "        nn.Sequential(*[nn.Sequential(nn.Linear(config_model.dim_hidden,\n",
    "                            config_model.dim_hidden),\n",
    "                            nn.ReLU())\n",
    "                for _ in range(config_model.num_layers_decoder)]),\n",
    "        nn.Linear(config_model.dim_hidden, config_model.num_classes)\n",
    "    )\n",
    "    \n",
    "elif config_model.implementation == \"Old_SetTransformer\":\n",
    "    # initialize SetTransformer model\n",
    "    class SetTransformerOld(nn.Module):\n",
    "        \"\"\" Vanilla SetTransformer from\n",
    "        https://github.com/juho-lee/set_transformer/blob/master/main_pointcloud.py\n",
    "        \"\"\"\n",
    "        def __init__(\n",
    "            self,\n",
    "            dim_input=4,  # dimension of input data for each element in the set\n",
    "            num_outputs=1,\n",
    "            dim_output=5,  # number of classes\n",
    "            num_inds=32,  # number of induced points, see  Set Transformer paper\n",
    "            dim_hidden=128,\n",
    "            num_heads=\"4\",\n",
    "            layer_norm=\"False\",  # use layer norm\n",
    "            dropout=0.0,\n",
    "            num_layer_enc=2,\n",
    "            num_layer_dec=2,\n",
    "        ):\n",
    "            super().__init__()\n",
    "            self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm)),\n",
    "                *[ISAB(dim_hidden, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm))\n",
    "                  for _ in range(num_layer_enc-1)],\n",
    "            )\n",
    "            self.dec = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                PMA(dim_hidden, eval(num_heads), num_outputs, ln=layer_norm),\n",
    "                nn.Dropout(dropout),\n",
    "                *[nn.Sequential(nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.Dropout(dropout)) for _ in range(num_layer_dec-1)],\n",
    "                nn.Linear(dim_hidden, dim_output),\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.dec(self.enc(input)).squeeze(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    model = SetTransformerOld(dim_input=4, dim_output=5,\n",
    "                           num_inds=config_model.num_induced_points,\n",
    "                           dim_hidden=config_model.dim_hidden,\n",
    "                           num_heads=str(config_model.num_heads),\n",
    "                           layer_norm=str(config_model.layer_norm),  # use layer norm\n",
    "                           dropout=config_model.dropout,\n",
    "                           num_layer_enc=config_model.num_layers_encoder,\n",
    "                           num_layer_dec=config_model.num_layers_decoder)\n",
    "else:\n",
    "    raise Exception(\"Unknown Implementation\")\n",
    "# %%\n",
    "\n",
    "if config_data.dtype == \"float64\":\n",
    "    print(\"Use float64 model\")\n",
    "    model = model.double()\n",
    "else:\n",
    "    print(\"use float32 model\")\n",
    "    print(model)\n",
    "\n",
    "# %%\n",
    "# Do training and validation\n",
    "\n",
    "# initialise loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the Tensorflow writer\n",
    "#writer = SummaryWriter(comment=json.dumps(config_model.toDict())\\\n",
    "#                                + json.dumps(config_data.toDict()))\n",
    "writer = SummaryWriter(comment=config_model.implementation)\n",
    "\n",
    "# initialise pipeline class\n",
    "pipe = Pipeline(model, [dl_train, None], loss_fn, writer)\n",
    "# %%\n",
    "\n",
    "\n",
    "# train the model\n",
    "pipe.train(config_model.optimizer,\n",
    "           config_model.num_epochs,\n",
    "           cross_validation=False,\n",
    "           optimizers_param={\"lr\": config_model.learning_rate,\n",
    "                             \"weight_decay\": config_model.weight_decay},\n",
    "           n_accumulated_grads=config_model.n_accumulated_grads)\n",
    "\n",
    "# %%\n",
    "# keep training\n",
    "#pipe.train(Adam, 300, False, keep_training=True)\n",
    "\n",
    "# %%\n",
    "# %%\n",
    "# Gridsearch\n",
    "\n",
    "# initialise gridsearch\n",
    "# pruner = NopPruner()\n",
    "# search = Gridsearch(pipe, search_metric=\"accuracy\", n_trials=50, best_not_last=True, pruner=pruner)\n",
    "\n",
    "# dictionaries of hyperparameters\n",
    "# optimizers_params = {\"lr\": [1e-7, 1e-3, None, True],\n",
    "#                       \"weight_decay\": [0.0, 0.2] }\n",
    "# dataloaders_params = {\"batch_size\": [32, 64, 16]}\n",
    "# models_hyperparams = {\"n_layer_enc\": [2, 5],\n",
    "#                       \"n_layer_dec\": [1, 5],\n",
    "#                       \"num_heads\": [\"2\", \"4\", \"8\"],\n",
    "#                       \"hidden_dim\": [\"16\", \"32\", \"64\"],\n",
    "#                       \"dropout\": [0.0, 0.2],\n",
    "#                       \"layer_norm\": [\"True\", \"False\"],\n",
    "#                       'pre_layer_norm': [\"True\", \"False\"]}\n",
    "\n",
    "# starting the gridsearch\n",
    "#search.start((Adam,), n_epochs=500, cross_validation=False,\n",
    "#             optimizers_params=optimizers_params,\n",
    "#             dataloaders_params=dataloaders_params,\n",
    "#             models_hyperparams=models_hyperparams, lr_scheduler=None,\n",
    "#             scheduler_params=None)\n",
    "\n",
    "\n",
    "# %%\n",
    "#print(search.best_val_acc_gs, search.best_val_loss_gs)\n",
    "# %%\n",
    "#df_res = search._results()\n",
    "#df_res\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d377ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DotMap(implementation='Old_SetTransformer', dim_input=4, num_outputs=1, num_classes=5, dim_hidden=32, num_heads=8, num_induced_points=64, layer_norm=False, pre_layer_norm=False, num_layers_encoder=4, num_layers_decoder=4, attention_type='induced_attention', activation=<class 'torch.nn.modules.activation.GELU'>, dropout=0.2, optimizer=<class 'torch.optim.adam.Adam'>, learning_rate=0.0001, num_epochs=2000, pooling_type='max', weight_decay=0.2, n_accumulated_grads=0, num_layer_encoder=DotMap(), num_layer_decoder=DotMap(), _ipython_display_=DotMap(), _repr_mimebundle_=DotMap())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b19bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DotMap(_ipython_display_=DotMap(), _repr_mimebundle_=DotMap())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! python Set_transformer_benchmark_orbit5k_persistence.py > out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c85e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand((2, 1000, 4)).double()\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9e6bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "Number of pruned trials:  0\n",
      "Number of complete trials:  50\n",
      "Best trial:\n",
      "Metric Value for best trial:  99.10714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/giottodeep/lib/python3.8/site-packages/numpy/lib/function_base.py:2474: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in subtract\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Parameters: %{x}<br>Parameters: %{y}<br>Correlation: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "lr",
          "batch_size",
          "dropout",
          "n_layer_enc",
          "n_layer_dec",
          "loss",
          "accuracy"
         ],
         "xaxis": "x",
         "y": [
          "lr",
          "batch_size",
          "dropout",
          "n_layer_enc",
          "n_layer_dec",
          "loss",
          "accuracy"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           0.3321793461835531,
           0.0904440217666608,
           0.08792457464781951,
           -0.1781623815223595,
           null,
           0.24389148551474943
          ],
          [
           0.33217934618355316,
           0.9999999999999998,
           0.11206889636935947,
           -0.02436777204559112,
           0.02155217086890601,
           null,
           -0.019212603122426414
          ],
          [
           0.0904440217666608,
           0.11206889636935947,
           0.9999999999999999,
           0.26285826902480613,
           0.1766546131963994,
           null,
           -0.05580527297616502
          ],
          [
           0.0879245746478195,
           -0.02436777204559112,
           0.26285826902480613,
           1,
           0.02517799662955688,
           null,
           0.09026802690199691
          ],
          [
           -0.17816238152235953,
           0.02155217086890601,
           0.1766546131963994,
           0.025177996629556883,
           0.9999999999999998,
           null,
           -0.07963620883241891
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           0.24389148551474943,
           -0.019212603122426414,
           -0.05580527297616503,
           0.09026802690199691,
           -0.07963620883241893,
           null,
           1
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Correlation"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "side": "top",
         "title": {
          "text": "Parameters"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Parameters"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"711b72fc-9d3b-44bf-b6a1-b3b8e17b6c56\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"711b72fc-9d3b-44bf-b6a1-b3b8e17b6c56\")) {                    Plotly.newPlot(                        \"711b72fc-9d3b-44bf-b6a1-b3b8e17b6c56\",                        [{\"coloraxis\": \"coloraxis\", \"hovertemplate\": \"Parameters: %{x}<br>Parameters: %{y}<br>Correlation: %{z}<extra></extra>\", \"name\": \"0\", \"type\": \"heatmap\", \"x\": [\"lr\", \"batch_size\", \"dropout\", \"n_layer_enc\", \"n_layer_dec\", \"loss\", \"accuracy\"], \"xaxis\": \"x\", \"y\": [\"lr\", \"batch_size\", \"dropout\", \"n_layer_enc\", \"n_layer_dec\", \"loss\", \"accuracy\"], \"yaxis\": \"y\", \"z\": [[1.0, 0.3321793461835531, 0.0904440217666608, 0.08792457464781951, -0.1781623815223595, null, 0.24389148551474943], [0.33217934618355316, 0.9999999999999998, 0.11206889636935947, -0.02436777204559112, 0.02155217086890601, null, -0.019212603122426414], [0.0904440217666608, 0.11206889636935947, 0.9999999999999999, 0.26285826902480613, 0.1766546131963994, null, -0.05580527297616502], [0.0879245746478195, -0.02436777204559112, 0.26285826902480613, 1.0, 0.02517799662955688, null, 0.09026802690199691], [-0.17816238152235953, 0.02155217086890601, 0.1766546131963994, 0.025177996629556883, 0.9999999999999998, null, -0.07963620883241891], [null, null, null, null, null, null, null], [0.24389148551474943, -0.019212603122426414, -0.05580527297616503, 0.09026802690199691, -0.07963620883241893, null, 1.0]]}],                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"Correlation\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"constrain\": \"domain\", \"domain\": [0.0, 1.0], \"scaleanchor\": \"y\", \"side\": \"top\", \"title\": {\"text\": \"Parameters\"}}, \"yaxis\": {\"anchor\": \"x\", \"autorange\": \"reversed\", \"constrain\": \"domain\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Parameters\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('711b72fc-9d3b-44bf-b6a1-b3b8e17b6c56');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>n_layer_enc</th>\n",
       "      <th>n_layer_dec</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>layer_norm</th>\n",
       "      <th>pre_layer_norm</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>32</td>\n",
       "      <td>0.158746</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>48</td>\n",
       "      <td>0.130351</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.710317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>32</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>32</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>63.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>64</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>32</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>89.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>32</td>\n",
       "      <td>0.126969</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>64</td>\n",
       "      <td>0.154917</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.582031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>32</td>\n",
       "      <td>0.125399</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>32</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>48</td>\n",
       "      <td>0.078869</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.511905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>48</td>\n",
       "      <td>0.081688</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>48</td>\n",
       "      <td>0.091360</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>48</td>\n",
       "      <td>0.068706</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>48</td>\n",
       "      <td>0.118253</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>64</td>\n",
       "      <td>0.131878</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>95.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>48</td>\n",
       "      <td>0.198995</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>48</td>\n",
       "      <td>0.111423</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>99.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>64</td>\n",
       "      <td>0.107427</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>95.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>48</td>\n",
       "      <td>0.145682</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.246032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>48</td>\n",
       "      <td>0.188350</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>48</td>\n",
       "      <td>0.194394</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>48</td>\n",
       "      <td>0.109942</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>48</td>\n",
       "      <td>0.103142</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>48</td>\n",
       "      <td>0.177623</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>64</td>\n",
       "      <td>0.144937</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.363281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>48</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>48</td>\n",
       "      <td>0.106832</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>64</td>\n",
       "      <td>0.138439</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>48</td>\n",
       "      <td>0.119270</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>48</td>\n",
       "      <td>0.166125</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>48</td>\n",
       "      <td>0.092712</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>48</td>\n",
       "      <td>0.186484</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.115079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>48</td>\n",
       "      <td>0.160658</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>65.773810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>48</td>\n",
       "      <td>0.054597</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.329365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>48</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.130952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>32</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>95.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>32</td>\n",
       "      <td>0.115180</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>64</td>\n",
       "      <td>0.135858</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>65.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>32</td>\n",
       "      <td>0.152652</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.363281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>48</td>\n",
       "      <td>0.109732</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>48.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>48</td>\n",
       "      <td>0.127127</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>48</td>\n",
       "      <td>0.096609</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>48</td>\n",
       "      <td>0.096068</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>48</td>\n",
       "      <td>0.080913</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>46.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>48</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>20.039683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>48</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>48</td>\n",
       "      <td>0.076171</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>92.658730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>32</td>\n",
       "      <td>0.103653</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>48</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  dataset optimizer        lr  batch_size   dropout  n_layer_enc  \\\n",
       "0   model  dataset      Adam  0.000425          32  0.158746            4   \n",
       "1   model  dataset      Adam  0.000946          48  0.130351            3   \n",
       "2   model  dataset      Adam  0.000823          32  0.044103            5   \n",
       "3   model  dataset      Adam  0.000339          32  0.174644            3   \n",
       "4   model  dataset      Adam  0.000835          64  0.016269            2   \n",
       "5   model  dataset      Adam  0.000078          32  0.036563            2   \n",
       "6   model  dataset      Adam  0.000218          32  0.126969            5   \n",
       "7   model  dataset      Adam  0.000901          64  0.154917            2   \n",
       "8   model  dataset      Adam  0.000550          32  0.125399            2   \n",
       "9   model  dataset      Adam  0.000493          32  0.004410            3   \n",
       "10  model  dataset      Adam  0.000670          48  0.078869            4   \n",
       "11  model  dataset      Adam  0.000668          48  0.081688            4   \n",
       "12  model  dataset      Adam  0.000975          48  0.091360            4   \n",
       "13  model  dataset      Adam  0.000731          48  0.068706            3   \n",
       "14  model  dataset      Adam  0.000997          48  0.118253            4   \n",
       "15  model  dataset      Adam  0.000997          64  0.131878            3   \n",
       "16  model  dataset      Adam  0.000942          48  0.198995            4   \n",
       "17  model  dataset      Adam  0.000791          48  0.111423            5   \n",
       "18  model  dataset      Adam  0.000778          64  0.107427            5   \n",
       "19  model  dataset      Adam  0.000666          48  0.145682            3   \n",
       "20  model  dataset      Adam  0.000890          48  0.188350            5   \n",
       "21  model  dataset      Adam  0.000871          48  0.194394            5   \n",
       "22  model  dataset      Adam  0.000981          48  0.109942            4   \n",
       "23  model  dataset      Adam  0.000999          48  0.103142            3   \n",
       "24  model  dataset      Adam  0.000749          48  0.177623            5   \n",
       "25  model  dataset      Adam  0.000908          64  0.144937            4   \n",
       "26  model  dataset      Adam  0.000588          48  0.064298            3   \n",
       "27  model  dataset      Adam  0.000771          48  0.106832            4   \n",
       "28  model  dataset      Adam  0.000948          64  0.138439            3   \n",
       "29  model  dataset      Adam  0.000391          48  0.119270            5   \n",
       "30  model  dataset      Adam  0.000798          48  0.166125            4   \n",
       "31  model  dataset      Adam  0.000868          48  0.092712            5   \n",
       "32  model  dataset      Adam  0.000910          48  0.186484            5   \n",
       "33  model  dataset      Adam  0.000839          48  0.160658            5   \n",
       "34  model  dataset      Adam  0.000993          48  0.054597            5   \n",
       "35  model  dataset      Adam  0.000837          48  0.121300            4   \n",
       "36  model  dataset      Adam  0.000720          32  0.089597            5   \n",
       "37  model  dataset      Adam  0.000296          32  0.115180            4   \n",
       "38  model  dataset      Adam  0.000059          64  0.135858            4   \n",
       "39  model  dataset      Adam  0.000936          32  0.152652            2   \n",
       "40  model  dataset      Adam  0.000137          48  0.109732            3   \n",
       "41  model  dataset      Adam  0.000869          48  0.127127            4   \n",
       "42  model  dataset      Adam  0.000961          48  0.096609            4   \n",
       "43  model  dataset      Adam  0.000942          48  0.096068            5   \n",
       "44  model  dataset      Adam  0.000814          48  0.080913            3   \n",
       "45  model  dataset      Adam  0.000995          48  0.114384            4   \n",
       "46  model  dataset      Adam  0.000882          48  0.033099            2   \n",
       "47  model  dataset      Adam  0.000944          48  0.076171            3   \n",
       "48  model  dataset      Adam  0.000993          32  0.103653            4   \n",
       "49  model  dataset      Adam  0.000593          48  0.087275            5   \n",
       "\n",
       "    n_layer_dec num_heads hidden_dim layer_norm pre_layer_norm  loss  \\\n",
       "0             4         4         64       True           True   inf   \n",
       "1             4         8         32       True          False   inf   \n",
       "2             2         8         16       True          False   inf   \n",
       "3             3         2         32      False           True   inf   \n",
       "4             1         2         16       True           True   inf   \n",
       "5             3         4         64       True          False   inf   \n",
       "6             5         8         16       True          False   inf   \n",
       "7             4         8         16      False          False   inf   \n",
       "8             1         2         64       True          False   inf   \n",
       "9             1         2         64      False          False   inf   \n",
       "10            5         8         32       True          False   inf   \n",
       "11            5         8         32       True          False   inf   \n",
       "12            4         8         32       True          False   inf   \n",
       "13            5         8         32       True          False   inf   \n",
       "14            4         8         32       True          False   inf   \n",
       "15            4         8         32       True          False   inf   \n",
       "16            3         4         32       True          False   inf   \n",
       "17            2         8         32      False           True   inf   \n",
       "18            2         8         32      False           True   inf   \n",
       "19            2         8         32      False           True   inf   \n",
       "20            2         4         32      False           True   inf   \n",
       "21            2         4         32      False           True   inf   \n",
       "22            4         8         32      False           True   inf   \n",
       "23            3         8         32      False           True   inf   \n",
       "24            2         4         32      False           True   inf   \n",
       "25            4         8         32      False           True   inf   \n",
       "26            3         8         32      False           True   inf   \n",
       "27            4         8         32      False           True   inf   \n",
       "28            3         8         32      False           True   inf   \n",
       "29            4         8         64       True          False   inf   \n",
       "30            5         8         32       True          False   inf   \n",
       "31            2         4         32      False           True   inf   \n",
       "32            2         4         32       True           True   inf   \n",
       "33            1         4         32      False           True   inf   \n",
       "34            3         4         16      False           True   inf   \n",
       "35            2         2         32       True          False   inf   \n",
       "36            3         4         32      False           True   inf   \n",
       "37            4         8         64       True          False   inf   \n",
       "38            4         8         16       True          False   inf   \n",
       "39            3         2         32      False           True   inf   \n",
       "40            4         8         16       True          False   inf   \n",
       "41            4         8         32      False           True   inf   \n",
       "42            1         8         32      False           True   inf   \n",
       "43            1         8         32      False           True   inf   \n",
       "44            1         8         32      False           True   inf   \n",
       "45            5         8         32       True          False   inf   \n",
       "46            1         2         64       True          False   inf   \n",
       "47            1         8         32      False           True   inf   \n",
       "48            4         8         32       True          False   inf   \n",
       "49            2         4         32      False           True   inf   \n",
       "\n",
       "     accuracy  \n",
       "0   94.921875  \n",
       "1   98.710317  \n",
       "2   97.070312  \n",
       "3   63.769531  \n",
       "4   96.191406  \n",
       "5   89.160156  \n",
       "6   94.628906  \n",
       "7   96.582031  \n",
       "8   96.875000  \n",
       "9   96.777344  \n",
       "10  98.511905  \n",
       "11  97.519841  \n",
       "12  98.412698  \n",
       "13  98.015873  \n",
       "14  98.611111  \n",
       "15  95.507812  \n",
       "16  97.519841  \n",
       "17  99.107143  \n",
       "18  95.312500  \n",
       "19  94.246032  \n",
       "20  98.611111  \n",
       "21  96.726190  \n",
       "22  98.611111  \n",
       "23  97.718254  \n",
       "24  98.412698  \n",
       "25  97.363281  \n",
       "26  97.916667  \n",
       "27  97.519841  \n",
       "28  96.484375  \n",
       "29  94.742063  \n",
       "30  96.031746  \n",
       "31  98.412698  \n",
       "32  98.115079  \n",
       "33  65.773810  \n",
       "34  96.329365  \n",
       "35  96.130952  \n",
       "36  95.703125  \n",
       "37  94.921875  \n",
       "38  65.527344  \n",
       "39  97.363281  \n",
       "40  48.809524  \n",
       "41  98.214286  \n",
       "42  98.611111  \n",
       "43  98.214286  \n",
       "44  46.626984  \n",
       "45  20.039683  \n",
       "46  98.412698  \n",
       "47  92.658730  \n",
       "48  96.484375  \n",
       "49  97.222222  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = search._results()\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38906bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy\n",
      "  Downloading sympy-1.9-py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[K     |████████████████████████████████| 532 kB 98.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy\n",
      "Successfully installed mpmath-1.2.1 sympy-1.9\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/jovyan/conda-envs/giottodeep/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d5b8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_optimizer as optim\n",
    "\n",
    "# model = ...\n",
    "optimizer = optim.Shampoo(\n",
    "    m.parameters(),\n",
    "    lr=1e-1,\n",
    "    momentum=0.0,\n",
    "    weight_decay=0.0,\n",
    "    epsilon=1e-4,\n",
    "    update_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753d5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('set_transformer_grid_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68c8355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "Number of pruned trials:  0\n",
      "Number of complete trials:  50\n",
      "Best trial:\n",
      "Metric Value for best trial:  99.10714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/giottodeep/lib/python3.8/site-packages/numpy/lib/function_base.py:2474: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in subtract\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Parameters: %{x}<br>Parameters: %{y}<br>Correlation: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "lr",
          "batch_size",
          "dropout",
          "n_layer_enc",
          "n_layer_dec",
          "loss",
          "accuracy"
         ],
         "xaxis": "x",
         "y": [
          "lr",
          "batch_size",
          "dropout",
          "n_layer_enc",
          "n_layer_dec",
          "loss",
          "accuracy"
         ],
         "yaxis": "y",
         "z": [
          [
           1,
           0.3321793461835531,
           0.0904440217666608,
           0.08792457464781951,
           -0.1781623815223595,
           null,
           0.24389148551474943
          ],
          [
           0.33217934618355316,
           0.9999999999999998,
           0.11206889636935947,
           -0.02436777204559112,
           0.02155217086890601,
           null,
           -0.019212603122426414
          ],
          [
           0.0904440217666608,
           0.11206889636935947,
           0.9999999999999999,
           0.26285826902480613,
           0.1766546131963994,
           null,
           -0.05580527297616502
          ],
          [
           0.0879245746478195,
           -0.02436777204559112,
           0.26285826902480613,
           1,
           0.02517799662955688,
           null,
           0.09026802690199691
          ],
          [
           -0.17816238152235953,
           0.02155217086890601,
           0.1766546131963994,
           0.025177996629556883,
           0.9999999999999998,
           null,
           -0.07963620883241891
          ],
          [
           null,
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           0.24389148551474943,
           -0.019212603122426414,
           -0.05580527297616503,
           0.09026802690199691,
           -0.07963620883241893,
           null,
           1
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Correlation"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "side": "top",
         "title": {
          "text": "Parameters"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Parameters"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"f13c47d3-e1a8-481a-8d34-3dcce4c1e3b8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f13c47d3-e1a8-481a-8d34-3dcce4c1e3b8\")) {                    Plotly.newPlot(                        \"f13c47d3-e1a8-481a-8d34-3dcce4c1e3b8\",                        [{\"coloraxis\": \"coloraxis\", \"hovertemplate\": \"Parameters: %{x}<br>Parameters: %{y}<br>Correlation: %{z}<extra></extra>\", \"name\": \"0\", \"type\": \"heatmap\", \"x\": [\"lr\", \"batch_size\", \"dropout\", \"n_layer_enc\", \"n_layer_dec\", \"loss\", \"accuracy\"], \"xaxis\": \"x\", \"y\": [\"lr\", \"batch_size\", \"dropout\", \"n_layer_enc\", \"n_layer_dec\", \"loss\", \"accuracy\"], \"yaxis\": \"y\", \"z\": [[1.0, 0.3321793461835531, 0.0904440217666608, 0.08792457464781951, -0.1781623815223595, null, 0.24389148551474943], [0.33217934618355316, 0.9999999999999998, 0.11206889636935947, -0.02436777204559112, 0.02155217086890601, null, -0.019212603122426414], [0.0904440217666608, 0.11206889636935947, 0.9999999999999999, 0.26285826902480613, 0.1766546131963994, null, -0.05580527297616502], [0.0879245746478195, -0.02436777204559112, 0.26285826902480613, 1.0, 0.02517799662955688, null, 0.09026802690199691], [-0.17816238152235953, 0.02155217086890601, 0.1766546131963994, 0.025177996629556883, 0.9999999999999998, null, -0.07963620883241891], [null, null, null, null, null, null, null], [0.24389148551474943, -0.019212603122426414, -0.05580527297616503, 0.09026802690199691, -0.07963620883241893, null, 1.0]]}],                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"Correlation\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"constrain\": \"domain\", \"domain\": [0.0, 1.0], \"scaleanchor\": \"y\", \"side\": \"top\", \"title\": {\"text\": \"Parameters\"}}, \"yaxis\": {\"anchor\": \"x\", \"autorange\": \"reversed\", \"constrain\": \"domain\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Parameters\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f13c47d3-e1a8-481a-8d34-3dcce4c1e3b8');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>n_layer_enc</th>\n",
       "      <th>n_layer_dec</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>layer_norm</th>\n",
       "      <th>pre_layer_norm</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>32</td>\n",
       "      <td>0.158746</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>48</td>\n",
       "      <td>0.130351</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.710317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>32</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>32</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>63.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>64</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>32</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>89.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>32</td>\n",
       "      <td>0.126969</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>64</td>\n",
       "      <td>0.154917</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.582031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>32</td>\n",
       "      <td>0.125399</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>32</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>48</td>\n",
       "      <td>0.078869</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.511905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>48</td>\n",
       "      <td>0.081688</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>48</td>\n",
       "      <td>0.091360</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>48</td>\n",
       "      <td>0.068706</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>48</td>\n",
       "      <td>0.118253</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>64</td>\n",
       "      <td>0.131878</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>95.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>48</td>\n",
       "      <td>0.198995</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>48</td>\n",
       "      <td>0.111423</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>99.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>64</td>\n",
       "      <td>0.107427</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>95.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>48</td>\n",
       "      <td>0.145682</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.246032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>48</td>\n",
       "      <td>0.188350</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>48</td>\n",
       "      <td>0.194394</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>48</td>\n",
       "      <td>0.109942</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>48</td>\n",
       "      <td>0.103142</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>48</td>\n",
       "      <td>0.177623</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>64</td>\n",
       "      <td>0.144937</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.363281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>48</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>48</td>\n",
       "      <td>0.106832</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>64</td>\n",
       "      <td>0.138439</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>48</td>\n",
       "      <td>0.119270</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>48</td>\n",
       "      <td>0.166125</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>48</td>\n",
       "      <td>0.092712</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>48</td>\n",
       "      <td>0.186484</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.115079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>48</td>\n",
       "      <td>0.160658</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>65.773810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>48</td>\n",
       "      <td>0.054597</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.329365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>48</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.130952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>32</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>95.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>32</td>\n",
       "      <td>0.115180</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>94.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>64</td>\n",
       "      <td>0.135858</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>65.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>32</td>\n",
       "      <td>0.152652</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.363281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>48</td>\n",
       "      <td>0.109732</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>48.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>48</td>\n",
       "      <td>0.127127</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>48</td>\n",
       "      <td>0.096609</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>48</td>\n",
       "      <td>0.096068</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>48</td>\n",
       "      <td>0.080913</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>46.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>48</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>20.039683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>48</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>98.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>48</td>\n",
       "      <td>0.076171</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>92.658730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>32</td>\n",
       "      <td>0.103653</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>96.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>model</td>\n",
       "      <td>dataset</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>48</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>inf</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  dataset optimizer        lr  batch_size   dropout  n_layer_enc  \\\n",
       "0   model  dataset      Adam  0.000425          32  0.158746            4   \n",
       "1   model  dataset      Adam  0.000946          48  0.130351            3   \n",
       "2   model  dataset      Adam  0.000823          32  0.044103            5   \n",
       "3   model  dataset      Adam  0.000339          32  0.174644            3   \n",
       "4   model  dataset      Adam  0.000835          64  0.016269            2   \n",
       "5   model  dataset      Adam  0.000078          32  0.036563            2   \n",
       "6   model  dataset      Adam  0.000218          32  0.126969            5   \n",
       "7   model  dataset      Adam  0.000901          64  0.154917            2   \n",
       "8   model  dataset      Adam  0.000550          32  0.125399            2   \n",
       "9   model  dataset      Adam  0.000493          32  0.004410            3   \n",
       "10  model  dataset      Adam  0.000670          48  0.078869            4   \n",
       "11  model  dataset      Adam  0.000668          48  0.081688            4   \n",
       "12  model  dataset      Adam  0.000975          48  0.091360            4   \n",
       "13  model  dataset      Adam  0.000731          48  0.068706            3   \n",
       "14  model  dataset      Adam  0.000997          48  0.118253            4   \n",
       "15  model  dataset      Adam  0.000997          64  0.131878            3   \n",
       "16  model  dataset      Adam  0.000942          48  0.198995            4   \n",
       "17  model  dataset      Adam  0.000791          48  0.111423            5   \n",
       "18  model  dataset      Adam  0.000778          64  0.107427            5   \n",
       "19  model  dataset      Adam  0.000666          48  0.145682            3   \n",
       "20  model  dataset      Adam  0.000890          48  0.188350            5   \n",
       "21  model  dataset      Adam  0.000871          48  0.194394            5   \n",
       "22  model  dataset      Adam  0.000981          48  0.109942            4   \n",
       "23  model  dataset      Adam  0.000999          48  0.103142            3   \n",
       "24  model  dataset      Adam  0.000749          48  0.177623            5   \n",
       "25  model  dataset      Adam  0.000908          64  0.144937            4   \n",
       "26  model  dataset      Adam  0.000588          48  0.064298            3   \n",
       "27  model  dataset      Adam  0.000771          48  0.106832            4   \n",
       "28  model  dataset      Adam  0.000948          64  0.138439            3   \n",
       "29  model  dataset      Adam  0.000391          48  0.119270            5   \n",
       "30  model  dataset      Adam  0.000798          48  0.166125            4   \n",
       "31  model  dataset      Adam  0.000868          48  0.092712            5   \n",
       "32  model  dataset      Adam  0.000910          48  0.186484            5   \n",
       "33  model  dataset      Adam  0.000839          48  0.160658            5   \n",
       "34  model  dataset      Adam  0.000993          48  0.054597            5   \n",
       "35  model  dataset      Adam  0.000837          48  0.121300            4   \n",
       "36  model  dataset      Adam  0.000720          32  0.089597            5   \n",
       "37  model  dataset      Adam  0.000296          32  0.115180            4   \n",
       "38  model  dataset      Adam  0.000059          64  0.135858            4   \n",
       "39  model  dataset      Adam  0.000936          32  0.152652            2   \n",
       "40  model  dataset      Adam  0.000137          48  0.109732            3   \n",
       "41  model  dataset      Adam  0.000869          48  0.127127            4   \n",
       "42  model  dataset      Adam  0.000961          48  0.096609            4   \n",
       "43  model  dataset      Adam  0.000942          48  0.096068            5   \n",
       "44  model  dataset      Adam  0.000814          48  0.080913            3   \n",
       "45  model  dataset      Adam  0.000995          48  0.114384            4   \n",
       "46  model  dataset      Adam  0.000882          48  0.033099            2   \n",
       "47  model  dataset      Adam  0.000944          48  0.076171            3   \n",
       "48  model  dataset      Adam  0.000993          32  0.103653            4   \n",
       "49  model  dataset      Adam  0.000593          48  0.087275            5   \n",
       "\n",
       "    n_layer_dec num_heads hidden_dim layer_norm pre_layer_norm  loss  \\\n",
       "0             4         4         64       True           True   inf   \n",
       "1             4         8         32       True          False   inf   \n",
       "2             2         8         16       True          False   inf   \n",
       "3             3         2         32      False           True   inf   \n",
       "4             1         2         16       True           True   inf   \n",
       "5             3         4         64       True          False   inf   \n",
       "6             5         8         16       True          False   inf   \n",
       "7             4         8         16      False          False   inf   \n",
       "8             1         2         64       True          False   inf   \n",
       "9             1         2         64      False          False   inf   \n",
       "10            5         8         32       True          False   inf   \n",
       "11            5         8         32       True          False   inf   \n",
       "12            4         8         32       True          False   inf   \n",
       "13            5         8         32       True          False   inf   \n",
       "14            4         8         32       True          False   inf   \n",
       "15            4         8         32       True          False   inf   \n",
       "16            3         4         32       True          False   inf   \n",
       "17            2         8         32      False           True   inf   \n",
       "18            2         8         32      False           True   inf   \n",
       "19            2         8         32      False           True   inf   \n",
       "20            2         4         32      False           True   inf   \n",
       "21            2         4         32      False           True   inf   \n",
       "22            4         8         32      False           True   inf   \n",
       "23            3         8         32      False           True   inf   \n",
       "24            2         4         32      False           True   inf   \n",
       "25            4         8         32      False           True   inf   \n",
       "26            3         8         32      False           True   inf   \n",
       "27            4         8         32      False           True   inf   \n",
       "28            3         8         32      False           True   inf   \n",
       "29            4         8         64       True          False   inf   \n",
       "30            5         8         32       True          False   inf   \n",
       "31            2         4         32      False           True   inf   \n",
       "32            2         4         32       True           True   inf   \n",
       "33            1         4         32      False           True   inf   \n",
       "34            3         4         16      False           True   inf   \n",
       "35            2         2         32       True          False   inf   \n",
       "36            3         4         32      False           True   inf   \n",
       "37            4         8         64       True          False   inf   \n",
       "38            4         8         16       True          False   inf   \n",
       "39            3         2         32      False           True   inf   \n",
       "40            4         8         16       True          False   inf   \n",
       "41            4         8         32      False           True   inf   \n",
       "42            1         8         32      False           True   inf   \n",
       "43            1         8         32      False           True   inf   \n",
       "44            1         8         32      False           True   inf   \n",
       "45            5         8         32       True          False   inf   \n",
       "46            1         2         64       True          False   inf   \n",
       "47            1         8         32      False           True   inf   \n",
       "48            4         8         32       True          False   inf   \n",
       "49            2         4         32      False           True   inf   \n",
       "\n",
       "     accuracy  \n",
       "0   94.921875  \n",
       "1   98.710317  \n",
       "2   97.070312  \n",
       "3   63.769531  \n",
       "4   96.191406  \n",
       "5   89.160156  \n",
       "6   94.628906  \n",
       "7   96.582031  \n",
       "8   96.875000  \n",
       "9   96.777344  \n",
       "10  98.511905  \n",
       "11  97.519841  \n",
       "12  98.412698  \n",
       "13  98.015873  \n",
       "14  98.611111  \n",
       "15  95.507812  \n",
       "16  97.519841  \n",
       "17  99.107143  \n",
       "18  95.312500  \n",
       "19  94.246032  \n",
       "20  98.611111  \n",
       "21  96.726190  \n",
       "22  98.611111  \n",
       "23  97.718254  \n",
       "24  98.412698  \n",
       "25  97.363281  \n",
       "26  97.916667  \n",
       "27  97.519841  \n",
       "28  96.484375  \n",
       "29  94.742063  \n",
       "30  96.031746  \n",
       "31  98.412698  \n",
       "32  98.115079  \n",
       "33  65.773810  \n",
       "34  96.329365  \n",
       "35  96.130952  \n",
       "36  95.703125  \n",
       "37  94.921875  \n",
       "38  65.527344  \n",
       "39  97.363281  \n",
       "40  48.809524  \n",
       "41  98.214286  \n",
       "42  98.611111  \n",
       "43  98.214286  \n",
       "44  46.626984  \n",
       "45  20.039683  \n",
       "46  98.412698  \n",
       "47  92.658730  \n",
       "48  96.484375  \n",
       "49  97.222222  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = search._results()\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9520dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotmap import DotMap\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import the PyTorch modules\n",
    "import torch  # type: ignore\n",
    "from torch import nn  # type: ignore\n",
    "from torch.optim import SGD, Adam, RMSprop  # type: ignore\n",
    "\n",
    "# Import Tensorflow writer\n",
    "from torch.utils.tensorboard import SummaryWriter  # type: ignore\n",
    "\n",
    "# Import modules from XTransformers\n",
    "from x_transformers.x_transformers import AttentionLayers, Encoder, ContinuousTransformerWrapper\n",
    "\n",
    "\n",
    "# Import the giotto-deep modules\n",
    "from gdeep.data import OrbitsGenerator, DataLoaderKwargs\n",
    "from gdeep.topology_layers import SetTransformer, PersFormer\n",
    "#from gdeep.topology_layers import AttentionPooling\n",
    "from gdeep.topology_layers import ISAB, PMA, SAB\n",
    "from gdeep.pipeline import Pipeline\n",
    "from gdeep.search import Gridsearch\n",
    "import json\n",
    "#from gdeep.search import Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5bb8a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d74f0cd04c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSetTransformerOld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-d74f0cd04c66>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim_input, num_outputs, dim_output, num_inds, dim_hidden, num_heads, layer_norm, dropout, num_layer_enc, num_layer_dec)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnum_layer_dec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     ):\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSetTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         self.enc = nn.Sequential(\n\u001b[1;32m     20\u001b[0m             \u001b[0mISAB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "class SetTransformerOld(nn.Module):\n",
    "    \"\"\" Vanilla SetTransformer from\n",
    "    https://github.com/juho-lee/set_transformer/blob/master/main_pointcloud.py\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_input=4,  # dimension of input data for each element in the set\n",
    "        num_outputs=1,\n",
    "        dim_output=5,  # number of classes\n",
    "        num_inds=32,  # number of induced points, see  Set Transformer paper\n",
    "        dim_hidden=128,\n",
    "        num_heads=\"4\",\n",
    "        layer_norm=\"False\",  # use layer norm\n",
    "        dropout=0.0,\n",
    "        num_layer_enc=2,\n",
    "        num_layer_dec=2,\n",
    "    ):\n",
    "        super(SetTransformer, self).init()\n",
    "        self.enc = nn.Sequential(\n",
    "            ISAB(dim_input, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm)),\n",
    "            *[ISAB(dim_hidden, dim_hidden, eval(num_heads), num_inds, ln=eval(layer_norm))\n",
    "              for _ in range(num_layer_enc-1)],\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            PMA(dim_hidden, eval(num_heads), num_outputs, ln=layer_norm),\n",
    "            nn.Dropout(dropout),\n",
    "            *[nn.Sequential(nn.Linear(dim_hidden, dim_hidden),\n",
    "            nn.Dropout(dropout)) for _ in range(num_layer_dec-1)],\n",
    "            nn.Linear(dim_hidden, dim_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.dec(self.enc(input)).squeeze(dim=1)\n",
    "\n",
    "\n",
    "model = SetTransformerOld(num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecad1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:giottodeep]",
   "language": "python",
   "name": "conda-env-giottodeep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
