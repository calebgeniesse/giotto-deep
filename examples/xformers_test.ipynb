{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9309e743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blub\n",
      "warmup steps: 25\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.7423405495900957  \tBatch training accuracy:  19.990079365079367  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.764437 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.722286131646898  \tBatch training accuracy:  19.990079365079367  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.720310 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6773373153474596  \tBatch training accuracy:  19.990079365079367  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.661255 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6362711758840651  \tBatch training accuracy:  19.990079365079367  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.622986 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6156432060968309  \tBatch training accuracy:  20.28769841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.140625%,                 Avg loss: 1.610299 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6110274034833152  \tBatch training accuracy:  20.28769841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.824219%,                 Avg loss: 1.609329 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104246056269085  \tBatch training accuracy:  19.32043650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.261719%,                 Avg loss: 1.609312 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6103171923803905  \tBatch training accuracy:  20.114087301587304  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.679688%,                 Avg loss: 1.609741 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104049739383517  \tBatch training accuracy:  20.238095238095237  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.312500%,                 Avg loss: 1.609830 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104412362689065  \tBatch training accuracy:  19.76686507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.042969%,                 Avg loss: 1.609923 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610603379824805  \tBatch training accuracy:  19.76686507936508  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.871094%,                 Avg loss: 1.609238 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6106664774909851  \tBatch training accuracy:  18.998015873015873  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.609391 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6107394676359872  \tBatch training accuracy:  19.270833333333336  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.042969%,                 Avg loss: 1.610177 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6106902058162387  \tBatch training accuracy:  19.642857142857142  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.996094%,                 Avg loss: 1.610315 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102159534181868  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.335938%,                 Avg loss: 1.609724 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6107069689130027  \tBatch training accuracy:  19.419642857142858  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.503906%,                 Avg loss: 1.609999 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6117734965823947  \tBatch training accuracy:  18.77480158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.261719%,                 Avg loss: 1.609689 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6106994152069092  \tBatch training accuracy:  19.221230158730158  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.066406%,                 Avg loss: 1.609593 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610723336537679  \tBatch training accuracy:  20.535714285714285  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.164062%,                 Avg loss: 1.609489 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6116612827967083  \tBatch training accuracy:  19.32043650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.847656%,                 Avg loss: 1.609865 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6120003518604098  \tBatch training accuracy:  19.46924603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.042969%,                 Avg loss: 1.611049 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6107854502541679  \tBatch training accuracy:  19.66765873015873  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.433594%,                 Avg loss: 1.610270 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610832689300416  \tBatch training accuracy:  19.370039682539684  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.117188%,                 Avg loss: 1.609983 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.611039261969309  \tBatch training accuracy:  19.221230158730158  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.312500%,                 Avg loss: 1.609946 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6112209331421625  \tBatch training accuracy:  20.85813492063492  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.611113 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6108667566662742  \tBatch training accuracy:  19.791666666666664  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.093750%,                 Avg loss: 1.612057 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6112244886065286  \tBatch training accuracy:  20.089285714285715  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.703125%,                 Avg loss: 1.609480 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.612111769025288  \tBatch training accuracy:  20.634920634920633  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.703125%,                 Avg loss: 1.610511 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.6108111975684998  \tBatch training accuracy:  18.874007936507937  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.214844%,                 Avg loss: 1.608810 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6116391287909613  \tBatch training accuracy:  18.328373015873016  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.628906%,                 Avg loss: 1.611108 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6113781872249784  \tBatch training accuracy:  19.518849206349206  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.611942 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6108449678572396  \tBatch training accuracy:  17.509920634920633  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.703125%,                 Avg loss: 1.610588 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6116738943826585  \tBatch training accuracy:  19.32043650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.042969%,                 Avg loss: 1.610567 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104636040944902  \tBatch training accuracy:  18.948412698412696  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.312500%,                 Avg loss: 1.611137 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610241000614469  \tBatch training accuracy:  19.345238095238095  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.614024 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6118249174148318  \tBatch training accuracy:  18.17956349206349  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.359375%,                 Avg loss: 1.609251 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6107236865967038  \tBatch training accuracy:  19.46924603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.410156%,                 Avg loss: 1.609349 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6113507728728036  \tBatch training accuracy:  19.32043650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.410156%,                 Avg loss: 1.609584 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6109955859562708  \tBatch training accuracy:  18.328373015873016  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.824219%,                 Avg loss: 1.609625 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102393695286341  \tBatch training accuracy:  19.32043650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.851562%,                 Avg loss: 1.609626 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6106465922461615  \tBatch training accuracy:  19.717261904761905  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.433594%,                 Avg loss: 1.609834 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6108450132703025  \tBatch training accuracy:  20.535714285714285  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.406250%,                 Avg loss: 1.611431 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6114231196660844  \tBatch training accuracy:  18.601190476190478  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.261719%,                 Avg loss: 1.610911 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6117363808647034  \tBatch training accuracy:  19.618055555555554  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.611103 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.61049723435962  \tBatch training accuracy:  19.047619047619047  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.433594%,                 Avg loss: 1.612322 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.61087737764631  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.335938%,                 Avg loss: 1.611448 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610510131669423  \tBatch training accuracy:  19.543650793650794  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.703125%,                 Avg loss: 1.610784 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6111013227038913  \tBatch training accuracy:  19.221230158730158  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.261719%,                 Avg loss: 1.611448 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6112361673324826  \tBatch training accuracy:  19.717261904761905  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.140625%,                 Avg loss: 1.609894 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6105325846444993  \tBatch training accuracy:  20.386904761904763  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.609856 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6114482860716561  \tBatch training accuracy:  19.1468253968254  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.144531%,                 Avg loss: 1.609242 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104342596871513  \tBatch training accuracy:  19.072420634920633  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.777344%,                 Avg loss: 1.609922 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102818345266676  \tBatch training accuracy:  18.377976190476193  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.042969%,                 Avg loss: 1.609420 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6101735149111067  \tBatch training accuracy:  19.02281746031746  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.612006 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6106235829610673  \tBatch training accuracy:  19.940476190476193  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.214844%,                 Avg loss: 1.609734 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104576606599112  \tBatch training accuracy:  20.03968253968254  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.730469%,                 Avg loss: 1.613325 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.6111948736130246  \tBatch training accuracy:  20.13888888888889  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.214844%,                 Avg loss: 1.610505 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6108206491621713  \tBatch training accuracy:  19.444444444444446  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.335938%,                 Avg loss: 1.610511 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6101361286072504  \tBatch training accuracy:  19.866071428571427  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.558594%,                 Avg loss: 1.609941 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6106871972008356  \tBatch training accuracy:  18.278769841269842  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.144531%,                 Avg loss: 1.609566 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6103669556360396  \tBatch training accuracy:  19.59325396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.921875%,                 Avg loss: 1.609292 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6111221313476562  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.312500%,                 Avg loss: 1.610163 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.611830883555942  \tBatch training accuracy:  18.229166666666664  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 15.332031%,                 Avg loss: 1.609452 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104280570196727  \tBatch training accuracy:  18.998015873015873  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.824219%,                 Avg loss: 1.610204 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104724331507607  \tBatch training accuracy:  19.56845238095238  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.726562%,                 Avg loss: 1.610570 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610522158562191  \tBatch training accuracy:  19.841269841269842  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.093750%,                 Avg loss: 1.609116 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6110916932423909  \tBatch training accuracy:  18.278769841269842  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.652344%,                 Avg loss: 1.610499 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6107231889452254  \tBatch training accuracy:  19.39484126984127  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.610529 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.61019690263839  \tBatch training accuracy:  20.238095238095237  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.605469%,                 Avg loss: 1.609223 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6111648158421592  \tBatch training accuracy:  18.650793650793652  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.433594%,                 Avg loss: 1.610828 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610545105404324  \tBatch training accuracy:  19.370039682539684  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.312500%,                 Avg loss: 1.609251 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6101822039437672  \tBatch training accuracy:  19.9156746031746  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.610522 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102540322712489  \tBatch training accuracy:  19.717261904761905  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.750000%,                 Avg loss: 1.608886 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.61039652332427  \tBatch training accuracy:  20.238095238095237  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.140625%,                 Avg loss: 1.609925 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6099536021550496  \tBatch training accuracy:  19.76686507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.335938%,                 Avg loss: 1.610066 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102927412305559  \tBatch training accuracy:  19.618055555555554  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.433594%,                 Avg loss: 1.610558 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6105045420782906  \tBatch training accuracy:  19.692460317460316  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 14.062500%,                 Avg loss: 1.609574 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6108633204111977  \tBatch training accuracy:  18.57638888888889  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.726562%,                 Avg loss: 1.610097 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6094853802332802  \tBatch training accuracy:  20.33730158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.554688%,                 Avg loss: 1.609637 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6112960558088998  \tBatch training accuracy:  18.427579365079367  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.359375%,                 Avg loss: 1.609384 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6110570109079754  \tBatch training accuracy:  19.59325396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.261719%,                 Avg loss: 1.610271 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6105455103374662  \tBatch training accuracy:  18.898809523809522  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.507812%,                 Avg loss: 1.608676 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102388075419836  \tBatch training accuracy:  18.77480158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.628906%,                 Avg loss: 1.609746 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6111781426838465  \tBatch training accuracy:  18.824404761904763  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.601562%,                 Avg loss: 1.609592 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.6112266778945923  \tBatch training accuracy:  19.196428571428573  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.613167 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6103358249815682  \tBatch training accuracy:  21.205357142857142  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.610063 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610704919648549  \tBatch training accuracy:  18.452380952380953  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.308594%,                 Avg loss: 1.609281 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6103872268918962  \tBatch training accuracy:  19.791666666666664  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.608945 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098184755870275  \tBatch training accuracy:  19.76686507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.605469%,                 Avg loss: 1.610317 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6105102243877591  \tBatch training accuracy:  18.303571428571427  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.609662 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6102548799817524  \tBatch training accuracy:  19.890873015873016  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.480469%,                 Avg loss: 1.609765 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6108417643441095  \tBatch training accuracy:  19.59325396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.605469%,                 Avg loss: 1.609813 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6109379227199252  \tBatch training accuracy:  19.543650793650794  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.285156%,                 Avg loss: 1.609021 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104558857660445  \tBatch training accuracy:  20.65972222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.214844%,                 Avg loss: 1.609570 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6097860222771054  \tBatch training accuracy:  19.32043650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.871094%,                 Avg loss: 1.610146 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6101845086566986  \tBatch training accuracy:  19.543650793650794  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.921875%,                 Avg loss: 1.611529 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610587165469215  \tBatch training accuracy:  20.03968253968254  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.628906%,                 Avg loss: 1.610006 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.61038791565668  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.140625%,                 Avg loss: 1.610990 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610098819884043  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 13.671875%,                 Avg loss: 1.609161 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610680273600987  \tBatch training accuracy:  19.56845238095238  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.289062%,                 Avg loss: 1.609200 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6101954759113373  \tBatch training accuracy:  19.072420634920633  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.117188%,                 Avg loss: 1.609883 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6096420042098514  \tBatch training accuracy:  20.436507936507937  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.609522 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6099305474568928  \tBatch training accuracy:  18.40277777777778  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.410156%,                 Avg loss: 1.609646 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6105689813220312  \tBatch training accuracy:  18.501984126984127  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.042969%,                 Avg loss: 1.609374 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098766818879142  \tBatch training accuracy:  17.857142857142858  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.558594%,                 Avg loss: 1.609398 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6099692658772544  \tBatch training accuracy:  20.03968253968254  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 15.039062%,                 Avg loss: 1.609834 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104237389942957  \tBatch training accuracy:  19.370039682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.824219%,                 Avg loss: 1.609910 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6100403959788974  \tBatch training accuracy:  20.758928571428573  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.582031%,                 Avg loss: 1.610229 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.61001583886525  \tBatch training accuracy:  20.13888888888889  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.610431 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6105963445845104  \tBatch training accuracy:  19.39484126984127  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.558594%,                 Avg loss: 1.610223 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610369082481142  \tBatch training accuracy:  20.213293650793652  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.628906%,                 Avg loss: 1.609563 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6097220617627341  \tBatch training accuracy:  18.948412698412696  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.117188%,                 Avg loss: 1.609728 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.6108635001712375  \tBatch training accuracy:  19.09722222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.457031%,                 Avg loss: 1.609668 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098086587966434  \tBatch training accuracy:  18.998015873015873  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.824219%,                 Avg loss: 1.609684 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6100333796607122  \tBatch training accuracy:  19.46924603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.679688%,                 Avg loss: 1.609461 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610615329136924  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.824219%,                 Avg loss: 1.609754 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6096680637389895  \tBatch training accuracy:  19.618055555555554  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.484375%,                 Avg loss: 1.611417 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098710109317114  \tBatch training accuracy:  18.77480158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 12.011719%,                 Avg loss: 1.609350 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.609273564247858  \tBatch training accuracy:  19.46924603174603  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.410156%,                 Avg loss: 1.610706 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104981274831862  \tBatch training accuracy:  20.48611111111111  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.507812%,                 Avg loss: 1.608604 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098994073413668  \tBatch training accuracy:  19.618055555555554  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.554688%,                 Avg loss: 1.609837 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6099113036715795  \tBatch training accuracy:  19.39484126984127  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.605469%,                 Avg loss: 1.608688 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6092117570695423  \tBatch training accuracy:  19.890873015873016  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.945312%,                 Avg loss: 1.609297 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098727423047263  \tBatch training accuracy:  18.253968253968253  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 14.941406%,                 Avg loss: 1.609238 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6101501574591985  \tBatch training accuracy:  17.93154761904762  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 14.062500%,                 Avg loss: 1.609665 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6098076975534832  \tBatch training accuracy:  20.362103174603174  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.117188%,                 Avg loss: 1.609587 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6094266630354381  \tBatch training accuracy:  20.014880952380953  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 24.023438%,                 Avg loss: 1.609452 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.60938574965038  \tBatch training accuracy:  21.428571428571427  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.406250%,                 Avg loss: 1.609065 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6104210444859095  \tBatch training accuracy:  18.77480158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.703125%,                 Avg loss: 1.610625 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.610254302857414  \tBatch training accuracy:  18.229166666666664  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 14.453125%,                 Avg loss: 1.608822 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6092505379328652  \tBatch training accuracy:  15.873015873015872  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.238281%,                 Avg loss: 1.609606 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6095976337553963  \tBatch training accuracy:  20.560515873015873  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.628906%,                 Avg loss: 1.609525 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6095646827939958  \tBatch training accuracy:  20.03968253968254  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.214844%,                 Avg loss: 1.610226 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6100446193937272  \tBatch training accuracy:  19.59325396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 9.472656%,                 Avg loss: 1.608968 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6093583542203147  \tBatch training accuracy:  19.1468253968254  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.679688%,                 Avg loss: 1.609276 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.60952709780799  \tBatch training accuracy:  19.791666666666664  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.117188%,                 Avg loss: 1.609884 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6091100469468131  \tBatch training accuracy:  20.684523809523807  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.847656%,                 Avg loss: 1.608652 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.608930436391679  \tBatch training accuracy:  18.650793650793652  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 18.652344%,                 Avg loss: 1.609830 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6092157572034806  \tBatch training accuracy:  19.518849206349206  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.265625%,                 Avg loss: 1.608881 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6086542852341184  \tBatch training accuracy:  20.560515873015873  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.503906%,                 Avg loss: 1.612992 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.609273081734067  \tBatch training accuracy:  19.270833333333336  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.289062%,                 Avg loss: 1.608959 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6087882102481903  \tBatch training accuracy:  17.708333333333336  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.117188%,                 Avg loss: 1.609786 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6086567678148784  \tBatch training accuracy:  20.411706349206348  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.507812%,                 Avg loss: 1.609352 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6081218038286482  \tBatch training accuracy:  20.7093253968254  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.460938%,                 Avg loss: 1.608878 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6080057564235868  \tBatch training accuracy:  18.501984126984127  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.019531%,                 Avg loss: 1.609014 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.607578334354219  \tBatch training accuracy:  21.106150793650794  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.582031%,                 Avg loss: 1.608769 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6075761318206787  \tBatch training accuracy:  21.502976190476193  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.480469%,                 Avg loss: 1.607380 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.607081617627825  \tBatch training accuracy:  18.40277777777778  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 24.804688%,                 Avg loss: 1.609995 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6071759235291254  \tBatch training accuracy:  20.734126984126984  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.437500%,                 Avg loss: 1.606803 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6070069623371912  \tBatch training accuracy:  20.65972222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 12.109375%,                 Avg loss: 1.606453 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6065115342064509  \tBatch training accuracy:  20.33730158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.777344%,                 Avg loss: 1.606011 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6057323671522594  \tBatch training accuracy:  18.973214285714285  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.992188%,                 Avg loss: 1.606412 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6055481642011613  \tBatch training accuracy:  20.014880952380953  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 16.503906%,                 Avg loss: 1.604529 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.60470269785987  \tBatch training accuracy:  18.849206349206348  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 10.253906%,                 Avg loss: 1.604048 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6035635811941964  \tBatch training accuracy:  16.319444444444446  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.480469%,                 Avg loss: 1.604315 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.6033000813590155  \tBatch training accuracy:  23.09027777777778  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.410156%,                 Avg loss: 1.604129 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.601960645781623  \tBatch training accuracy:  19.717261904761905  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 17.968750%,                 Avg loss: 1.601278 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.601037682048858  \tBatch training accuracy:  20.95734126984127  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.242188%,                 Avg loss: 1.602532 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5990561133339292  \tBatch training accuracy:  22.668650793650794  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 8.105469%,                 Avg loss: 1.599185 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.599136093306163  \tBatch training accuracy:  19.717261904761905  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 15.917969%,                 Avg loss: 1.597753 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5975264064849368  \tBatch training accuracy:  19.816468253968253  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 19.335938%,                 Avg loss: 1.599279 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5966939434172616  \tBatch training accuracy:  21.081349206349206  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.363281%,                 Avg loss: 1.596358 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5958527080596439  \tBatch training accuracy:  21.52777777777778  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.289062%,                 Avg loss: 1.595815 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5955598524638586  \tBatch training accuracy:  21.651785714285715  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 25.488281%,                 Avg loss: 1.594641 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.593125337646121  \tBatch training accuracy:  20.163690476190478  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.386719%,                 Avg loss: 1.593282 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.592502438832843  \tBatch training accuracy:  20.88293650793651  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.410156%,                 Avg loss: 1.595219 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5911181465027824  \tBatch training accuracy:  22.2718253968254  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.996094%,                 Avg loss: 1.593174 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.590574998704214  \tBatch training accuracy:  23.239087301587304  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 20.507812%,                 Avg loss: 1.590701 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.58872385819753  \tBatch training accuracy:  21.949404761904763  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.289062%,                 Avg loss: 1.588373 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5875504338552082  \tBatch training accuracy:  24.00793650793651  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 24.511719%,                 Avg loss: 1.582751 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.585250108961075  \tBatch training accuracy:  23.487103174603174  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 25.292969%,                 Avg loss: 1.580344 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5834987163543701  \tBatch training accuracy:  26.53769841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 25.976562%,                 Avg loss: 1.577865 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5812914598555792  \tBatch training accuracy:  25.818452380952383  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.777344%,                 Avg loss: 1.574726 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.579586907038613  \tBatch training accuracy:  23.933531746031747  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.144531%,                 Avg loss: 1.578560 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5770903674383012  \tBatch training accuracy:  27.232142857142854  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 26.269531%,                 Avg loss: 1.571749 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5737477181449768  \tBatch training accuracy:  27.628968253968257  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 31.835938%,                 Avg loss: 1.563197 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5748231505590773  \tBatch training accuracy:  26.016865079365083  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 23.046875%,                 Avg loss: 1.565249 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5698534231337289  \tBatch training accuracy:  27.752976190476193  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 22.167969%,                 Avg loss: 1.576883 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5673640152764698  \tBatch training accuracy:  28.670634920634917  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 27.636719%,                 Avg loss: 1.559521 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5623414194773113  \tBatch training accuracy:  29.66269841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 21.484375%,                 Avg loss: 1.565005 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5612248428284177  \tBatch training accuracy:  28.819444444444443  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 26.757812%,                 Avg loss: 1.558031 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5586849280766077  \tBatch training accuracy:  28.447420634920633  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.187500%,                 Avg loss: 1.542822 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5555520965939476  \tBatch training accuracy:  29.811507936507937  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 27.734375%,                 Avg loss: 1.541379 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5541050339502  \tBatch training accuracy:  31.671626984126984  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 25.000000%,                 Avg loss: 1.555022 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5545402121922327  \tBatch training accuracy:  29.265873015873016  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 27.832031%,                 Avg loss: 1.534072 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5470561621681092  \tBatch training accuracy:  30.481150793650798  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.312500%,                 Avg loss: 1.528074 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5434354903205993  \tBatch training accuracy:  32.63888888888889  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 25.488281%,                 Avg loss: 1.544200 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5423095585807922  \tBatch training accuracy:  31.498015873015873  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 24.902344%,                 Avg loss: 1.540881 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.536852204610431  \tBatch training accuracy:  37.32638888888889  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 24.218750%,                 Avg loss: 1.530943 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5383540694675748  \tBatch training accuracy:  32.31646825396825  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.253906%,                 Avg loss: 1.530927 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5317582857041132  \tBatch training accuracy:  32.73809523809524  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.230469%,                 Avg loss: 1.512032 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.529016065219092  \tBatch training accuracy:  36.97916666666667  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 28.125000%,                 Avg loss: 1.514924 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.525134315566411  \tBatch training accuracy:  38.88888888888889  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 26.855469%,                 Avg loss: 1.519926 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.521893336659386  \tBatch training accuracy:  37.05357142857143  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.203125%,                 Avg loss: 1.509624 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.519376862616766  \tBatch training accuracy:  36.830357142857146  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 30.468750%,                 Avg loss: 1.508216 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.515886280271742  \tBatch training accuracy:  37.10317460317461  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.675781%,                 Avg loss: 1.488761 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.5110884147977073  \tBatch training accuracy:  37.92162698412698  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.496094%,                 Avg loss: 1.500320 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5110740245334686  \tBatch training accuracy:  35.1438492063492  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 30.761719%,                 Avg loss: 1.493161 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5056540379448542  \tBatch training accuracy:  38.913690476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 27.246094%,                 Avg loss: 1.504759 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.5036460142286996  \tBatch training accuracy:  36.507936507936506  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 31.152344%,                 Avg loss: 1.489825 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4998724441679696  \tBatch training accuracy:  37.67361111111111  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.765625%,                 Avg loss: 1.477497 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4990776871878004  \tBatch training accuracy:  37.94642857142857  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.332031%,                 Avg loss: 1.473890 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4924043568353804  \tBatch training accuracy:  38.24404761904761  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 30.371094%,                 Avg loss: 1.482033 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4877874491706726  \tBatch training accuracy:  39.8561507936508  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.398438%,                 Avg loss: 1.467318 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4843846597368755  \tBatch training accuracy:  37.89682539682539  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.917969%,                 Avg loss: 1.454270 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4791653913164895  \tBatch training accuracy:  42.757936507936506  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 30.566406%,                 Avg loss: 1.482270 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.472791210053459  \tBatch training accuracy:  39.955357142857146  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.644531%,                 Avg loss: 1.459779 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4696479524884904  \tBatch training accuracy:  42.485119047619044  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.179688%,                 Avg loss: 1.451675 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.465135581909664  \tBatch training accuracy:  40.87301587301587  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.402344%,                 Avg loss: 1.446910 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4599356140409196  \tBatch training accuracy:  42.21230158730159  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.300781%,                 Avg loss: 1.453722 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4521282154416282  \tBatch training accuracy:  41.86507936507937  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.570312%,                 Avg loss: 1.448291 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4483172042029244  \tBatch training accuracy:  37.47519841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.207031%,                 Avg loss: 1.416003 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4415536116039942  \tBatch training accuracy:  40.476190476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.769531%,                 Avg loss: 1.413802 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4388084373776875  \tBatch training accuracy:  42.43551587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 32.128906%,                 Avg loss: 1.455103 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4371744280769712  \tBatch training accuracy:  40.17857142857143  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.914062%,                 Avg loss: 1.430031 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4246202991122292  \tBatch training accuracy:  41.71626984126984  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.300781%,                 Avg loss: 1.462589 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4181835764930362  \tBatch training accuracy:  41.4186507936508  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.648438%,                 Avg loss: 1.377834 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.4128435831221322  \tBatch training accuracy:  41.93948412698413  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.574219%,                 Avg loss: 1.391210 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.405597452133421  \tBatch training accuracy:  40.57539682539682  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.789062%,                 Avg loss: 1.431676 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.395263013385591  \tBatch training accuracy:  41.4186507936508  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.300781%,                 Avg loss: 1.435897 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3917217065417578  \tBatch training accuracy:  42.807539682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 33.789062%,                 Avg loss: 1.434571 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3806994207321652  \tBatch training accuracy:  40.401785714285715  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 29.394531%,                 Avg loss: 1.523496 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3958723601840792  \tBatch training accuracy:  39.43452380952381  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.816406%,                 Avg loss: 1.390426 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3734153452373685  \tBatch training accuracy:  42.08829365079365  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 34.277344%,                 Avg loss: 1.429764 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.367854939566718  \tBatch training accuracy:  42.06349206349206  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.500000%,                 Avg loss: 1.385874 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3584657756109086  \tBatch training accuracy:  42.28670634920635  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.449219%,                 Avg loss: 1.391989 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3563131756252713  \tBatch training accuracy:  41.76587301587302  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.402344%,                 Avg loss: 1.391601 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.354501179286412  \tBatch training accuracy:  40.99702380952381  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.160156%,                 Avg loss: 1.344856 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3466594559805733  \tBatch training accuracy:  41.617063492063494  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.718750%,                 Avg loss: 1.430373 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3422294798351468  \tBatch training accuracy:  42.038690476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.207031%,                 Avg loss: 1.370718 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.340269612887549  \tBatch training accuracy:  41.12103174603175  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.574219%,                 Avg loss: 1.357232 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3476676713852656  \tBatch training accuracy:  40.25297619047619  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.742188%,                 Avg loss: 1.437204 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3319726179516505  \tBatch training accuracy:  42.31150793650794  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.425781%,                 Avg loss: 1.384067 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3305475560445634  \tBatch training accuracy:  41.964285714285715  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.355469%,                 Avg loss: 1.352489 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3254714655497717  \tBatch training accuracy:  42.55952380952381  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 35.253906%,                 Avg loss: 1.423520 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3266278599935866  \tBatch training accuracy:  42.65873015873016  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.378906%,                 Avg loss: 1.370716 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3181128766801622  \tBatch training accuracy:  42.43551587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.816406%,                 Avg loss: 1.416097 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3114585233113123  \tBatch training accuracy:  42.63392857142857  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.769531%,                 Avg loss: 1.409452 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.309439081994314  \tBatch training accuracy:  41.74107142857143  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.550781%,                 Avg loss: 1.347300 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.305582252759782  \tBatch training accuracy:  43.179563492063494  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.648438%,                 Avg loss: 1.355315 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3099967695417858  \tBatch training accuracy:  43.05555555555556  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.695312%,                 Avg loss: 1.410706 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3028211082730974  \tBatch training accuracy:  42.23710317460318  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.429688%,                 Avg loss: 1.312328 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.3012294220545935  \tBatch training accuracy:  42.757936507936506  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.964844%,                 Avg loss: 1.344032 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.296277057556879  \tBatch training accuracy:  42.782738095238095  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.476562%,                 Avg loss: 1.347623 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2925051658872575  \tBatch training accuracy:  42.26190476190476  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.160156%,                 Avg loss: 1.372112 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.295070419235835  \tBatch training accuracy:  42.385912698412696  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.671875%,                 Avg loss: 1.398032 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2857008453399417  \tBatch training accuracy:  42.9811507936508  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.062500%,                 Avg loss: 1.365012 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2825258459363664  \tBatch training accuracy:  43.30357142857143  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.160156%,                 Avg loss: 1.324411 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2893496978850592  \tBatch training accuracy:  43.03075396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.476562%,                 Avg loss: 1.399918 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2803955702554612  \tBatch training accuracy:  43.35317460317461  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.574219%,                 Avg loss: 1.362552 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2761578370654394  \tBatch training accuracy:  43.75  \t[ 63 / 63 ]                                  \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.332031%,                 Avg loss: 1.309027 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2799369664419264  \tBatch training accuracy:  43.22916666666667  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.425781%,                 Avg loss: 1.432393 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.2836703156668043  \tBatch training accuracy:  41.66666666666667  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 37.500000%,                 Avg loss: 1.382723 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.271795392036438  \tBatch training accuracy:  43.67559523809524  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.820312%,                 Avg loss: 1.349189 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2683561245600383  \tBatch training accuracy:  43.37797619047619  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.234375%,                 Avg loss: 1.277871 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2706073711788843  \tBatch training accuracy:  43.57638888888889  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 36.621094%,                 Avg loss: 1.433453 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2655405411644587  \tBatch training accuracy:  42.16269841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 39.941406%,                 Avg loss: 1.363612 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2623658653289553  \tBatch training accuracy:  44.24603174603175  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.699219%,                 Avg loss: 1.301184 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2583883206049602  \tBatch training accuracy:  44.14682539682539  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 38.183594%,                 Avg loss: 1.335553 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2584848668840196  \tBatch training accuracy:  43.42757936507937  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.015625%,                 Avg loss: 1.315056 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.25204723032694  \tBatch training accuracy:  42.68353174603175  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.773438%,                 Avg loss: 1.255439 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2625966828966897  \tBatch training accuracy:  43.79960317460318  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.527344%,                 Avg loss: 1.281772 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2466820194607688  \tBatch training accuracy:  44.5188492063492  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.820312%,                 Avg loss: 1.298492 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2535832306695363  \tBatch training accuracy:  43.62599206349206  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.894531%,                 Avg loss: 1.289727 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.243517970281934  \tBatch training accuracy:  44.419642857142854  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.750000%,                 Avg loss: 1.237545 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.246277890508137  \tBatch training accuracy:  44.642857142857146  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.917969%,                 Avg loss: 1.285143 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2373726576093644  \tBatch training accuracy:  44.24603174603175  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.113281%,                 Avg loss: 1.311899 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.242456419127328  \tBatch training accuracy:  44.19642857142857  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.722656%,                 Avg loss: 1.289253 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2334457616957406  \tBatch training accuracy:  44.667658730158735  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.601562%,                 Avg loss: 1.284560 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.234940006619408  \tBatch training accuracy:  44.14682539682539  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.675781%,                 Avg loss: 1.253031 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2315614601922413  \tBatch training accuracy:  44.07242063492063  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.285156%,                 Avg loss: 1.260453 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2299611757672022  \tBatch training accuracy:  44.46924603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.066406%,                 Avg loss: 1.269272 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2253141800562541  \tBatch training accuracy:  45.65972222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.089844%,                 Avg loss: 1.271748 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2263547787590632  \tBatch training accuracy:  44.76686507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.335938%,                 Avg loss: 1.234013 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2231434337676517  \tBatch training accuracy:  44.44444444444444  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.261719%,                 Avg loss: 1.257093 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2205235220137096  \tBatch training accuracy:  44.44444444444444  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.601562%,                 Avg loss: 1.280543 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2137476830255418  \tBatch training accuracy:  45.510912698412696  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.066406%,                 Avg loss: 1.278322 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2106990814208984  \tBatch training accuracy:  46.18055555555556  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.578125%,                 Avg loss: 1.247296 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2122814579615517  \tBatch training accuracy:  46.03174603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.554688%,                 Avg loss: 1.286712 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2142087031924536  \tBatch training accuracy:  45.63492063492063  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.652344%,                 Avg loss: 1.248826 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.2113306579135714  \tBatch training accuracy:  45.56051587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 40.820312%,                 Avg loss: 1.315258 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2096924819643535  \tBatch training accuracy:  45.03968253968254  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.773438%,                 Avg loss: 1.254268 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2007965511745877  \tBatch training accuracy:  46.47817460317461  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.433594%,                 Avg loss: 1.237540 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.2024350033866034  \tBatch training accuracy:  46.1061507936508  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.335938%,                 Avg loss: 1.216589 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1997842523786757  \tBatch training accuracy:  46.55257936507937  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.042969%,                 Avg loss: 1.244718 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1954300233295985  \tBatch training accuracy:  46.00694444444444  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.726562%,                 Avg loss: 1.202378 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1955261192624531  \tBatch training accuracy:  45.73412698412698  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.089844%,                 Avg loss: 1.187413 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.188915108877515  \tBatch training accuracy:  47.073412698412696  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.433594%,                 Avg loss: 1.207350 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1908814244800143  \tBatch training accuracy:  47.27182539682539  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.703125%,                 Avg loss: 1.197586 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1877199922289168  \tBatch training accuracy:  47.495039682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.480469%,                 Avg loss: 1.281500 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1862732758597723  \tBatch training accuracy:  47.19742063492063  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 42.675781%,                 Avg loss: 1.222019 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.182494575069064  \tBatch training accuracy:  47.445436507936506  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.433594%,                 Avg loss: 1.232947 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1850467333717951  \tBatch training accuracy:  46.577380952380956  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 41.210938%,                 Avg loss: 1.273617 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1749184528986614  \tBatch training accuracy:  46.55257936507937  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.898438%,                 Avg loss: 1.191074 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1749486204177615  \tBatch training accuracy:  47.56944444444444  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.605469%,                 Avg loss: 1.165012 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.180997852295164  \tBatch training accuracy:  46.726190476190474  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.703125%,                 Avg loss: 1.198647 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.171769656832256  \tBatch training accuracy:  48.09027777777778  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.726562%,                 Avg loss: 1.178784 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.172051471377176  \tBatch training accuracy:  46.254960317460316  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 46.386719%,                 Avg loss: 1.197434 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1704818161707076  \tBatch training accuracy:  46.47817460317461  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.214844%,                 Avg loss: 1.173849 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1670733955171373  \tBatch training accuracy:  46.577380952380956  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.996094%,                 Avg loss: 1.184135 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1637678685642423  \tBatch training accuracy:  47.12301587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 44.433594%,                 Avg loss: 1.204748 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.15902635880879  \tBatch training accuracy:  47.867063492063494  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 47.949219%,                 Avg loss: 1.137776 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.164309609503973  \tBatch training accuracy:  47.56944444444444  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 43.945312%,                 Avg loss: 1.225022 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1597775429014177  \tBatch training accuracy:  48.61111111111111  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.605469%,                 Avg loss: 1.196580 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.15583792754582  \tBatch training accuracy:  48.239087301587304  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 48.828125%,                 Avg loss: 1.158952 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1562391235714866  \tBatch training accuracy:  47.445436507936506  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 48.046875%,                 Avg loss: 1.166177 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1499153262092954  \tBatch training accuracy:  49.057539682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 45.898438%,                 Avg loss: 1.210490 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1513059110868544  \tBatch training accuracy:  47.867063492063494  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 47.363281%,                 Avg loss: 1.169318 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.146445667932904  \tBatch training accuracy:  48.61111111111111  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 48.339844%,                 Avg loss: 1.143879 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1493982284788102  \tBatch training accuracy:  48.214285714285715  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 46.679688%,                 Avg loss: 1.207866 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1431206899975974  \tBatch training accuracy:  48.660714285714285  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 48.144531%,                 Avg loss: 1.126849 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.143893976060171  \tBatch training accuracy:  48.735119047619044  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 46.093750%,                 Avg loss: 1.196277 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1379674975834195  \tBatch training accuracy:  50.297619047619044  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 47.070312%,                 Avg loss: 1.178666 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1332232006012448  \tBatch training accuracy:  49.057539682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.414062%,                 Avg loss: 1.137678 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1373388256345476  \tBatch training accuracy:  48.83432539682539  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.292969%,                 Avg loss: 1.137064 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1327857327839685  \tBatch training accuracy:  49.30555555555556  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.414062%,                 Avg loss: 1.129179 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1485426312401181  \tBatch training accuracy:  48.214285714285715  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.609375%,                 Avg loss: 1.119249 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1373493264591883  \tBatch training accuracy:  49.60317460317461  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 47.851562%,                 Avg loss: 1.131385 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1358284940795293  \tBatch training accuracy:  49.007936507936506  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 47.656250%,                 Avg loss: 1.167064 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1285103067519173  \tBatch training accuracy:  49.57837301587302  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.902344%,                 Avg loss: 1.120882 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1310385976518904  \tBatch training accuracy:  48.90873015873016  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.316406%,                 Avg loss: 1.145668 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1230785827788095  \tBatch training accuracy:  49.60317460317461  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.781250%,                 Avg loss: 1.120212 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.125565629156809  \tBatch training accuracy:  48.85912698412698  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.343750%,                 Avg loss: 1.108822 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.124802192998311  \tBatch training accuracy:  48.38789682539682  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.683594%,                 Avg loss: 1.107258 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1316758696995084  \tBatch training accuracy:  49.45436507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.414062%,                 Avg loss: 1.124109 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.12225850233956  \tBatch training accuracy:  50.148809523809526  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.660156%,                 Avg loss: 1.096818 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1148914798857674  \tBatch training accuracy:  49.62797619047619  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.585938%,                 Avg loss: 1.110780 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1169171560378301  \tBatch training accuracy:  49.13194444444444  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 49.414062%,                 Avg loss: 1.134948 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.114075503652058  \tBatch training accuracy:  49.379960317460316  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.292969%,                 Avg loss: 1.126590 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1148011637112452  \tBatch training accuracy:  49.97519841269841  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 48.535156%,                 Avg loss: 1.148311 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1115263530186243  \tBatch training accuracy:  50.32242063492064  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.195312%,                 Avg loss: 1.136524 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1071874187106179  \tBatch training accuracy:  49.330357142857146  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.097656%,                 Avg loss: 1.122413 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1056839615579634  \tBatch training accuracy:  50.148809523809526  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.660156%,                 Avg loss: 1.104997 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1081906566544184  \tBatch training accuracy:  50.37202380952381  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.757812%,                 Avg loss: 1.111870 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.10605392853419  \tBatch training accuracy:  50.49603174603175  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.097656%,                 Avg loss: 1.113509 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1000979750875444  \tBatch training accuracy:  50.074404761904766  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.855469%,                 Avg loss: 1.088216 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.102451209038023  \tBatch training accuracy:  50.86805555555556  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.027344%,                 Avg loss: 1.087565 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.1004516132294186  \tBatch training accuracy:  51.11607142857143  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.585938%,                 Avg loss: 1.119787 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.092538821318793  \tBatch training accuracy:  51.78571428571429  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.976562%,                 Avg loss: 1.100046 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0970324996917966  \tBatch training accuracy:  50.81845238095239  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.929688%,                 Avg loss: 1.068805 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0967836928746058  \tBatch training accuracy:  50.76884920634921  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.636719%,                 Avg loss: 1.096224 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0901746144370428  \tBatch training accuracy:  51.11607142857143  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.953125%,                 Avg loss: 1.083863 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0931124024920993  \tBatch training accuracy:  51.14087301587301  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.441406%,                 Avg loss: 1.076129 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0910471289876909  \tBatch training accuracy:  50.32242063492064  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.246094%,                 Avg loss: 1.073360 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0890133910708957  \tBatch training accuracy:  52.00892857142857  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.320312%,                 Avg loss: 1.065333 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0910894520699033  \tBatch training accuracy:  50.620039682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.464844%,                 Avg loss: 1.093984 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0852758714130946  \tBatch training accuracy:  51.01686507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 50.390625%,                 Avg loss: 1.114852 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0902579171316964  \tBatch training accuracy:  51.01686507936508  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.296875%,                 Avg loss: 1.062319 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0861018952869235  \tBatch training accuracy:  50.148809523809526  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.343750%,                 Avg loss: 1.078333 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0856640111832392  \tBatch training accuracy:  51.537698412698404  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.050781%,                 Avg loss: 1.069354 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0834344549784585  \tBatch training accuracy:  51.860119047619044  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.808594%,                 Avg loss: 1.076662 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0814973570051647  \tBatch training accuracy:  50.42162698412699  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.734375%,                 Avg loss: 1.071414 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.085279677595411  \tBatch training accuracy:  51.091269841269835  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.027344%,                 Avg loss: 1.065497 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0854696063768297  \tBatch training accuracy:  51.81051587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.417969%,                 Avg loss: 1.056340 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0796093363610526  \tBatch training accuracy:  51.711309523809526  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.320312%,                 Avg loss: 1.055381 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0835405692221627  \tBatch training accuracy:  51.413690476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.464844%,                 Avg loss: 1.093996 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0791756558039831  \tBatch training accuracy:  51.041666666666664  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.660156%,                 Avg loss: 1.081616 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0778193644114904  \tBatch training accuracy:  51.587301587301596  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.320312%,                 Avg loss: 1.066531 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0738966096015203  \tBatch training accuracy:  51.66170634920635  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.222656%,                 Avg loss: 1.060725 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0720609909012204  \tBatch training accuracy:  51.61210317460318  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.882812%,                 Avg loss: 1.039988 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.077873430554829  \tBatch training accuracy:  52.033730158730165  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.906250%,                 Avg loss: 1.056595 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.071591373473879  \tBatch training accuracy:  51.51289682539682  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.320312%,                 Avg loss: 1.056437 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.073859067190261  \tBatch training accuracy:  52.38095238095239  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.492188%,                 Avg loss: 1.041389 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0736756759976585  \tBatch training accuracy:  50.99206349206349  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.078125%,                 Avg loss: 1.041347 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.0729609065585666  \tBatch training accuracy:  52.05853174603175  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.882812%,                 Avg loss: 1.043704 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0709298101682512  \tBatch training accuracy:  51.587301587301596  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.710938%,                 Avg loss: 1.055636 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0698156479805234  \tBatch training accuracy:  52.182539682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.003906%,                 Avg loss: 1.054881 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0665564262677754  \tBatch training accuracy:  51.5625  \t[ 63 / 63 ]                                \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 51.562500%,                 Avg loss: 1.084833 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.06841360387348  \tBatch training accuracy:  51.33928571428571  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.027344%,                 Avg loss: 1.060828 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0695414864827717  \tBatch training accuracy:  51.587301587301596  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.125000%,                 Avg loss: 1.061194 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0610210110270788  \tBatch training accuracy:  52.33134920634921  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.906250%,                 Avg loss: 1.052283 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0642076986176627  \tBatch training accuracy:  51.537698412698404  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.785156%,                 Avg loss: 1.042808 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.065379035851312  \tBatch training accuracy:  52.45535714285714  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.980469%,                 Avg loss: 1.026045 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0670894024864075  \tBatch training accuracy:  52.28174603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.101562%,                 Avg loss: 1.053693 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0585453775193956  \tBatch training accuracy:  52.43055555555556  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.078125%,                 Avg loss: 1.032916 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0586500281379336  \tBatch training accuracy:  51.90972222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 52.929688%,                 Avg loss: 1.068966 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0605412664867582  \tBatch training accuracy:  51.93452380952381  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.785156%,                 Avg loss: 1.053687 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0567441289387052  \tBatch training accuracy:  51.388888888888886  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.394531%,                 Avg loss: 1.044884 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0564433922843328  \tBatch training accuracy:  51.81051587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.394531%,                 Avg loss: 1.044976 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0576464231052096  \tBatch training accuracy:  52.75297619047619  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.785156%,                 Avg loss: 1.034633 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.05903293689092  \tBatch training accuracy:  52.25694444444444  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.785156%,                 Avg loss: 1.051689 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.055518823010581  \tBatch training accuracy:  52.480158730158735  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.589844%,                 Avg loss: 1.032772 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0536159229657007  \tBatch training accuracy:  53.249007936507944  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.687500%,                 Avg loss: 1.030907 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0559330251481798  \tBatch training accuracy:  52.207341269841265  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.882812%,                 Avg loss: 1.030175 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.055201772659544  \tBatch training accuracy:  51.66170634920635  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 53.613281%,                 Avg loss: 1.062800 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0575533121351213  \tBatch training accuracy:  52.083333333333336  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.273438%,                 Avg loss: 1.028521 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.053317649969979  \tBatch training accuracy:  52.653769841269835  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.882812%,                 Avg loss: 1.030315 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0537412422043937  \tBatch training accuracy:  52.207341269841265  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.029780 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0515998743829273  \tBatch training accuracy:  51.21527777777778  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.492188%,                 Avg loss: 1.040331 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0506426218956235  \tBatch training accuracy:  52.30654761904761  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.785156%,                 Avg loss: 1.029568 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0542616446812947  \tBatch training accuracy:  52.504960317460316  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.664062%,                 Avg loss: 1.021682 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0435310876558697  \tBatch training accuracy:  52.33134920634921  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.492188%,                 Avg loss: 1.040471 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.0499258826649378  \tBatch training accuracy:  52.67857142857143  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.882812%,                 Avg loss: 1.031872 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0486069075644961  \tBatch training accuracy:  52.28174603174603  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.882812%,                 Avg loss: 1.033020 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0517801680262127  \tBatch training accuracy:  52.951388888888886  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.468750%,                 Avg loss: 1.030393 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0472052475762745  \tBatch training accuracy:  52.38095238095239  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.468750%,                 Avg loss: 1.023580 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0509577459759183  \tBatch training accuracy:  52.00892857142857  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.371094%,                 Avg loss: 1.027877 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0458553140125577  \tBatch training accuracy:  53.323412698412696  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.025975 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.042470517612639  \tBatch training accuracy:  53.37301587301587  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.041043 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0478716975166684  \tBatch training accuracy:  52.40575396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.957031%,                 Avg loss: 1.022292 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0422640896978832  \tBatch training accuracy:  52.70337301587301  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.017407 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.042347824762738  \tBatch training accuracy:  52.25694444444444  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.078125%,                 Avg loss: 1.024304 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0426954475660173  \tBatch training accuracy:  52.67857142857143  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.273438%,                 Avg loss: 1.018257 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0388867665850927  \tBatch training accuracy:  53.422619047619044  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.566406%,                 Avg loss: 1.021136 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0370793673727248  \tBatch training accuracy:  52.87698412698413  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.664062%,                 Avg loss: 1.011395 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0436077221991524  \tBatch training accuracy:  51.88492063492064  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 54.785156%,                 Avg loss: 1.035444 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0413142991444422  \tBatch training accuracy:  53.37301587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.761719%,                 Avg loss: 1.020139 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0446054206954107  \tBatch training accuracy:  52.55456349206349  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.027531 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0403027316880604  \tBatch training accuracy:  52.951388888888886  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.078125%,                 Avg loss: 1.025730 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0350013394204398  \tBatch training accuracy:  52.85218253968254  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.011602 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0447789090020316  \tBatch training accuracy:  53.07539682539682  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.032941 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.039116520730276  \tBatch training accuracy:  52.87698412698413  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.016447 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0321250728198461  \tBatch training accuracy:  53.02579365079365  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.054688%,                 Avg loss: 1.015509 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0410797170230321  \tBatch training accuracy:  53.39781746031746  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.013532 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0370793106063965  \tBatch training accuracy:  52.976190476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.152344%,                 Avg loss: 1.016462 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0360082406846305  \tBatch training accuracy:  52.62896825396825  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.004948 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0328730297467066  \tBatch training accuracy:  53.323412698412696  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.040934 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.037783600035168  \tBatch training accuracy:  53.273809523809526  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.008649 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0344768724744282  \tBatch training accuracy:  52.604166666666664  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.054688%,                 Avg loss: 1.011570 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0398128997711908  \tBatch training accuracy:  52.504960317460316  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.761719%,                 Avg loss: 1.019718 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.0398112611165122  \tBatch training accuracy:  53.199404761904766  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.761719%,                 Avg loss: 1.009084 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0421619074685233  \tBatch training accuracy:  53.000992063492056  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.957031%,                 Avg loss: 1.003658 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0364104443126254  \tBatch training accuracy:  53.050595238095234  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.664062%,                 Avg loss: 1.025253 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.031600832939148  \tBatch training accuracy:  53.050595238095234  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.175781%,                 Avg loss: 1.029168 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0373848667220464  \tBatch training accuracy:  52.653769841269835  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.566406%,                 Avg loss: 1.019133 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0347851051224604  \tBatch training accuracy:  53.199404761904766  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.152344%,                 Avg loss: 1.017831 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.032022914243123  \tBatch training accuracy:  53.422619047619044  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.007666 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0325632379168557  \tBatch training accuracy:  53.22420634920635  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.012456 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0336257058476646  \tBatch training accuracy:  53.37301587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.761719%,                 Avg loss: 1.007562 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.041341989759415  \tBatch training accuracy:  52.87698412698413  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.468750%,                 Avg loss: 1.020888 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0280070749540178  \tBatch training accuracy:  53.050595238095234  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.054688%,                 Avg loss: 1.011532 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0286619549705869  \tBatch training accuracy:  53.49702380952381  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.542969%,                 Avg loss: 1.010255 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0321790500292702  \tBatch training accuracy:  53.37301587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.009482 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0316990424716284  \tBatch training accuracy:  53.125  \t[ 63 / 63 ]                                 \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.054688%,                 Avg loss: 1.011715 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0284088698644487  \tBatch training accuracy:  53.273809523809526  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.859375%,                 Avg loss: 1.016963 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0310523841116164  \tBatch training accuracy:  53.745039682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.957031%,                 Avg loss: 1.009651 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0361697569726005  \tBatch training accuracy:  53.22420634920635  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.542969%,                 Avg loss: 1.012076 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0302372574806213  \tBatch training accuracy:  53.62103174603175  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.007339 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0290995561887348  \tBatch training accuracy:  53.249007936507944  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.761719%,                 Avg loss: 1.006679 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.025105150919112  \tBatch training accuracy:  53.769841269841265  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.957031%,                 Avg loss: 1.012234 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0261190334955852  \tBatch training accuracy:  53.47222222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.003196 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0298812379912725  \tBatch training accuracy:  53.22420634920635  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.010752 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0280006584667025  \tBatch training accuracy:  53.47222222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.933594%,                 Avg loss: 1.010349 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0252394420760018  \tBatch training accuracy:  53.720238095238095  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.273438%,                 Avg loss: 1.014714 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0363389887507  \tBatch training accuracy:  52.926587301587304  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.664062%,                 Avg loss: 1.008002 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.025498917178502  \tBatch training accuracy:  53.67063492063492  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.006997 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.033717359815325  \tBatch training accuracy:  53.100198412698404  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.004435 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0276341078773377  \tBatch training accuracy:  53.62103174603175  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.004108 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.0317579214535062  \tBatch training accuracy:  52.653769841269835  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.006285 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0313678658197796  \tBatch training accuracy:  53.050595238095234  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.152344%,                 Avg loss: 1.012680 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0289982746517847  \tBatch training accuracy:  52.75297619047619  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.016863 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.026213530510191  \tBatch training accuracy:  53.125  \t[ 63 / 63 ]                                  \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.009290 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0271500888324918  \tBatch training accuracy:  53.323412698412696  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.011697 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0293725766832866  \tBatch training accuracy:  53.37301587301587  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.015563 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0280016698534526  \tBatch training accuracy:  53.02579365079365  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.005949 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0288625208158342  \tBatch training accuracy:  53.47222222222222  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.957031%,                 Avg loss: 1.010873 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0290540504077124  \tBatch training accuracy:  53.44742063492064  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.542969%,                 Avg loss: 1.006210 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0263185747086057  \tBatch training accuracy:  52.62896825396825  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.640625%,                 Avg loss: 1.006203 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0260793528859578  \tBatch training accuracy:  53.645833333333336  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.640625%,                 Avg loss: 1.014489 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0305157474109106  \tBatch training accuracy:  52.976190476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.542969%,                 Avg loss: 0.999668 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0278740998298403  \tBatch training accuracy:  53.273809523809526  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 55.761719%,                 Avg loss: 1.008745 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0284677829061235  \tBatch training accuracy:  53.49702380952381  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.004632 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0237063614148942  \tBatch training accuracy:  53.34821428571429  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 0.997819 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0266202328697083  \tBatch training accuracy:  53.199404761904766  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.003260 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.025534454792265  \tBatch training accuracy:  53.769841269841265  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.009572 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0299363864792719  \tBatch training accuracy:  53.39781746031746  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.004268 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0239278702508836  \tBatch training accuracy:  54.19146825396825  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.835938%,                 Avg loss: 1.005084 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0239367485046387  \tBatch training accuracy:  53.000992063492056  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.347656%,                 Avg loss: 1.011981 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0232532998872181  \tBatch training accuracy:  53.645833333333336  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.835938%,                 Avg loss: 1.008636 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0263849780673073  \tBatch training accuracy:  53.54662698412699  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.003187 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0254719427653722  \tBatch training accuracy:  53.02579365079365  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.152344%,                 Avg loss: 1.011034 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.028853882872869  \tBatch training accuracy:  53.422619047619044  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.250000%,                 Avg loss: 1.009340 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0205163463713631  \tBatch training accuracy:  54.166666666666664  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.152344%,                 Avg loss: 1.004906 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0226090209824699  \tBatch training accuracy:  54.01785714285714  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.001737 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0269224776162043  \tBatch training accuracy:  52.480158730158735  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.640625%,                 Avg loss: 1.009894 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.028436094995529  \tBatch training accuracy:  54.14186507936508  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.542969%,                 Avg loss: 1.010327 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "No TPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss:  1.02640938569629  \tBatch training accuracy:  53.57142857142857  \t[ 63 / 63 ]                        \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.001639 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0199011365572612  \tBatch training accuracy:  53.79464285714286  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.004231 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0237681761620536  \tBatch training accuracy:  53.596230158730165  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.835938%,                 Avg loss: 1.008986 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0249117830443004  \tBatch training accuracy:  52.90178571428571  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.835938%,                 Avg loss: 1.009981 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0298285749223497  \tBatch training accuracy:  52.976190476190474  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.445312%,                 Avg loss: 1.003780 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0320982384303259  \tBatch training accuracy:  53.34821428571429  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.640625%,                 Avg loss: 1.002231 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0203665986893669  \tBatch training accuracy:  53.67063492063492  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.933594%,                 Avg loss: 0.998608 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.026586750197032  \tBatch training accuracy:  53.81944444444444  \t[ 63 / 63 ]                       \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.640625%,                 Avg loss: 1.003019 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0253478014279926  \tBatch training accuracy:  53.125  \t[ 63 / 63 ]                                 \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.010885 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0237871711216275  \tBatch training accuracy:  54.46428571428571  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.003866 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0252015477135068  \tBatch training accuracy:  53.96825396825397  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.005683 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0210975313943529  \tBatch training accuracy:  53.769841269841265  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.933594%,                 Avg loss: 1.003683 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.022943121100229  \tBatch training accuracy:  54.216269841269835  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.000872 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0229515083252438  \tBatch training accuracy:  53.79464285714286  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.003282 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0280853907267253  \tBatch training accuracy:  53.596230158730165  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.004636 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0240304082159013  \tBatch training accuracy:  54.01785714285714  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.004449 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0252098280286033  \tBatch training accuracy:  53.745039682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.005033 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0239714213779993  \tBatch training accuracy:  53.745039682539684  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.003731 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0238049323596652  \tBatch training accuracy:  54.01785714285714  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.015039 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.024487693158407  \tBatch training accuracy:  53.645833333333336  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.009072 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0262383203657846  \tBatch training accuracy:  53.720238095238095  \t[ 63 / 63 ]                     \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.005139 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0249434558172075  \tBatch training accuracy:  53.17460317460318  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.007150 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0230188303523593  \tBatch training accuracy:  53.99305555555556  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.005554 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "No TPUs\n",
      "Batch training loss:  1.0232705322522966  \tBatch training accuracy:  53.67063492063492  \t[ 63 / 63 ]                      \n",
      "Time taken for this epoch: 6s\n",
      "No TPUs\n",
      "Validation results: \n",
      " Accuracy: 56.738281%,                 Avg loss: 1.002031 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0020307675004005, 56.73828125)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from enum import Enum\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from xformers.factory import xFormer, xFormerConfig\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # type: ignore\n",
    "\n",
    "from gdeep.data import OrbitsGenerator, DataLoaderKwargs\n",
    "from gdeep.pipeline import Pipeline\n",
    "\n",
    "# %%\n",
    "print(\"blub\")\n",
    "\n",
    "class Classifier(str, Enum):\n",
    "    GAP = \"gap\"\n",
    "    TOKEN = \"token\"\n",
    "\n",
    "class SetTransformer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        steps,\n",
    "        learning_rate=1e-2,\n",
    "        weight_decay=0.0001,\n",
    "        image_size=32,\n",
    "        num_classes=10,\n",
    "        patch_size=4,\n",
    "        dim=256,\n",
    "        n_layer=12,\n",
    "        n_head=8,\n",
    "        resid_pdrop=0.1,\n",
    "        attn_pdrop=0.1,\n",
    "        mlp_pdrop=0.1,\n",
    "        attention=\"scaled_dot_product\",\n",
    "        hidden_layer_multiplier=4,\n",
    "        linear_warmup_ratio=0.05,\n",
    "        seq_len=1_000,\n",
    "        classifier: Classifier = Classifier.GAP,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # all the inputs are saved under self.hparams (hyperparams)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # A list of the encoder or decoder blocks which constitute the Transformer.\n",
    "        xformer_config = [\n",
    "            {\n",
    "                \"block_config\": {\n",
    "                    \"block_type\": \"encoder\",\n",
    "                    \"num_layers\": n_layer,\n",
    "                    \"dim_model\": dim,\n",
    "                    \"seq_len\": seq_len,\n",
    "                    \"layer_norm_style\": \"pre\",\n",
    "                    \"multi_head_config\": {\n",
    "                        \"num_heads\": n_head,\n",
    "                        \"residual_dropout\": resid_pdrop,\n",
    "                        \"use_rotary_embeddings\": False,\n",
    "                        \"attention\": {\n",
    "                            \"name\": attention,\n",
    "                            \"dropout\": attn_pdrop,\n",
    "                            \"causal\": False,\n",
    "                        },\n",
    "                    },\n",
    "                    \"feedforward_config\": {\n",
    "                        \"name\": \"MLP\",\n",
    "                        \"dropout\": mlp_pdrop,\n",
    "                        \"activation\": \"gelu\",\n",
    "                        \"hidden_layer_multiplier\": hidden_layer_multiplier,\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        config = xFormerConfig(xformer_config)\n",
    "        self.transformer = xFormer.from_config(config)\n",
    "\n",
    "        self.patch_emb = nn.Linear(2, dim)\n",
    "\n",
    "        if classifier == Classifier.TOKEN:\n",
    "            self.clf_token = nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.head = nn.Linear(dim, num_classes)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_warmup_cosine_decay(warmup_steps, total_steps):\n",
    "        \"\"\"\n",
    "        Linear warmup for warmup_steps, with cosine annealing to 0 at total_steps\n",
    "        \"\"\"\n",
    "\n",
    "        def fn(step):\n",
    "            if step < warmup_steps:\n",
    "                return float(step) / float(max(1, warmup_steps))\n",
    "\n",
    "            progress = float(step - warmup_steps) / float(\n",
    "                max(1, total_steps - warmup_steps)\n",
    "            )\n",
    "            return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "\n",
    "        return fn\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            momentum=0.9,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "\n",
    "        warmup_steps = int(self.hparams.linear_warmup_ratio * self.hparams.steps)\n",
    "\n",
    "        scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.LambdaLR(\n",
    "                optimizer,\n",
    "                self.linear_warmup_cosine_decay(warmup_steps, self.hparams.steps),\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, *_ = x.shape  # BCHW\n",
    "\n",
    "        x = self.patch_emb(x)\n",
    "\n",
    "        # flatten patches into sequence\n",
    "        #x = x.flatten(2, 3).transpose(1, 2).contiguous()  # B HW C\n",
    "\n",
    "        if self.hparams.classifier == Classifier.TOKEN:\n",
    "            # prepend classification token\n",
    "            clf_token = (\n",
    "                torch.ones(1, batch, self.hparams.dim, device=x.device) * self.clf_token\n",
    "            )\n",
    "            x = torch.cat([clf_token, x[:-1, :, :]], axis=0)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = self.ln(x)\n",
    "\n",
    "        if self.hparams.classifier == Classifier.TOKEN:\n",
    "            x = x[:, 0]\n",
    "        elif self.hparams.classifier == Classifier.GAP:\n",
    "            x = x.mean(dim=1)  # mean over sequence len\n",
    "\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "# %%\n",
    "model = SetTransformer(steps=500,\n",
    "                       num_classes=5,\n",
    "                       dim=32,\n",
    "                       n_layer=2,\n",
    "                       n_head=4,\n",
    "                       learning_rate=1e-4,\n",
    "                       attention=\"scaled_dot_product\")\n",
    "\n",
    "# %%\n",
    "homology_dimensions = (0, 1)\n",
    "\n",
    "dataloaders_dicts = DataLoaderKwargs(train_kwargs = {\"batch_size\": 64},\n",
    "                                     val_kwargs = {\"batch_size\": 4},\n",
    "                                     test_kwargs = {\"batch_size\": 3})\n",
    "\n",
    "og = OrbitsGenerator(num_orbits_per_class=1_000,\n",
    "                     homology_dimensions = homology_dimensions,\n",
    "                     validation_percentage=0.0,\n",
    "                     test_percentage=0.0,\n",
    "                     n_jobs=2\n",
    "                     #dynamical_system = 'pp_convention'\n",
    "                     )\n",
    "\n",
    "dl_train, _, _ = og.get_dataloader_orbits(dataloaders_dicts)\n",
    "\n",
    "# %%\n",
    "\n",
    "loss_fn = model.criterion\n",
    "\n",
    "# Initialize the Tensorflow writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# initialise pipeline class\n",
    "pipe = Pipeline(model, [dl_train, None], loss_fn, writer)\n",
    "# %%\n",
    "optimizer_list, scheduler_list = model.configure_optimizers()\n",
    "\n",
    "# %%\n",
    "warmup_steps = int(model.hparams.linear_warmup_ratio * model.hparams.steps)\n",
    "\n",
    "print('warmup steps:', warmup_steps)\n",
    "\n",
    "# train the model\n",
    "pipe.train(torch.optim.Adam, model.hparams.steps, cross_validation=False,\n",
    "        optimizers_param={\"lr\": model.hparams.learning_rate,\n",
    "                          \"weight_decay\":model.hparams.weight_decay,},\n",
    "                          lr_scheduler=torch.optim.lr_scheduler.LambdaLR,\n",
    "                          scheduler_params={'lr_lambda': model.linear_warmup_cosine_decay(warmup_steps, model.hparams.steps)}\n",
    "                          )\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0196227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformer(\n",
       "  (transformer): xFormer(\n",
       "    (encoders): ModuleList(\n",
       "      (0): xFormerEncoderBlock(\n",
       "        (mha): MultiHeadDispatch(\n",
       "          (attention): ScaledDotProduct(\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (in_proj_container): InProjContainer()\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (feedforward): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (wrap_att): Residual(\n",
       "          (layer): PreNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (sublayer): MultiHeadDispatch(\n",
       "              (attention): ScaledDotProduct(\n",
       "                (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (in_proj_container): InProjContainer()\n",
       "              (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "              (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (wrap_ff): Residual(\n",
       "          (layer): PreNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (sublayer): MLP(\n",
       "              (mlp): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.1, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "                (4): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): xFormerEncoderBlock(\n",
       "        (mha): MultiHeadDispatch(\n",
       "          (attention): ScaledDotProduct(\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (in_proj_container): InProjContainer()\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (feedforward): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (wrap_att): Residual(\n",
       "          (layer): PreNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (sublayer): MultiHeadDispatch(\n",
       "              (attention): ScaledDotProduct(\n",
       "                (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (in_proj_container): InProjContainer()\n",
       "              (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "              (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (wrap_ff): Residual(\n",
       "          (layer): PreNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (sublayer): MLP(\n",
       "              (mlp): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.1, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "                (4): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoders): ModuleList()\n",
       "  )\n",
       "  (patch_emb): Linear(in_features=2, out_features=32, bias=True)\n",
       "  (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=32, out_features=5, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af8686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:giottodeep]",
   "language": "python",
   "name": "conda-env-giottodeep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
