{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e191750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.topactivation import TopactivationFC as TFC\n",
    "from gdeep.pipeline import Pipeline\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from torch import nn\n",
    "import torch\n",
    "from gdeep.data import TorchDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "da25024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xitorch in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.8.0)\n",
      "Requirement already satisfied: torch>=1.8 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from torch>=1.8->xitorch) (4.1.1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing GPU!\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xitorch\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.topactivation.spectral_analysisTorch import LaplacianOperator\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using GPU!\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a10527a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32)\n",
    "\n",
    "arch = [28*28, 50, 50, 10]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "#cpu = torch.ones(1).device\n",
    "\n",
    "me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "weights = list(me.get_layers_param().values())\n",
    "#weights = [layer.to(cpu) for layer in weights]\n",
    "lapOp = LaplacianOperator(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "799b5f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u,v=lapOp.diagonalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaac97",
   "metadata": {},
   "source": [
    "# Spectrum with no training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "56421007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u = u.to('cpu')\n",
    "plt.hist(u.numpy(),bins=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961cdfc4",
   "metadata": {},
   "source": [
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f9339be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch training loss:  0.9478217343456434  \tBatch training accuracy:  73.00174760853568  \t[ 1359 / 1500 ]                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [214]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_accumulated_grads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/giotto-deep/gdeep/pipeline/pipeline.py:660\u001b[0m, in \u001b[0;36mPipeline.train\u001b[0;34m(self, optimizer, n_epochs, cross_validation, optimizers_param, dataloaders_param, lr_scheduler, scheduler_params, optuna_params, profiling, parallel_tpu, keep_training, store_grad_layer_hist, n_accumulated_grads, writer_tag)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_optimizer_and_scheduler(keep_training, cross_validation,\n\u001b[1;32m    656\u001b[0m                                    optimizer, optimizers_param,\n\u001b[1;32m    657\u001b[0m                                    lr_scheduler, scheduler_params)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel_tpu \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 660\u001b[0m     valloss, valacc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training_loops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mprof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_optuna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter_tag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     valloss, valacc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_tpu_training_loops(n_epochs, dl_tr,\n\u001b[1;32m    666\u001b[0m                                        dl_val, optimizers_param, lr_scheduler,\n\u001b[1;32m    667\u001b[0m                                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler,\n\u001b[1;32m    668\u001b[0m                                        prof, check_optuna, search_metric,\n\u001b[1;32m    669\u001b[0m                                        trial, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/giotto-deep/gdeep/pipeline/pipeline.py:731\u001b[0m, in \u001b[0;36mPipeline._training_loops\u001b[0;34m(self, n_epochs, dl_tr, dl_val, lr_scheduler, scheduler, prof, check_optuna, search_metric, trial, cross_validation, writer_tag)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_epoch \u001b[38;5;241m=\u001b[39m t\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m--> 731\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter_tag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m me \u001b[38;5;241m=\u001b[39m ModelExtractor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_grad_layer_hist:\n",
      "File \u001b[0;32m~/Documents/giotto-deep/gdeep/pipeline/pipeline.py:260\u001b[0m, in \u001b[0;36mPipeline._train_loop\u001b[0;34m(self, dl_tr, writer_tag)\u001b[0m\n\u001b[1;32m    257\u001b[0m tik \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_accumulated_grads \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m steps, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    259\u001b[0m                                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m accumulated gradients shall be diminished!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 260\u001b[0m correct, t_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mwriter_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mt_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEpoch training accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(correct\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mljust(\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/giotto-deep/gdeep/pipeline/pipeline.py:231\u001b[0m, in \u001b[0;36mPipeline._inner_train_loop\u001b[0;34m(self, dl_tr, writer_tag, size, steps, loss, t_loss, correct)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     t_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimisation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mt_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# accuracy:\u001b[39;00m\n\u001b[1;32m    234\u001b[0m correct \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m size\n",
      "File \u001b[0;32m~/Documents/giotto-deep/gdeep/pipeline/pipeline.py:176\u001b[0m, in \u001b[0;36mPipeline._optimisation_step\u001b[0;34m(self, dl_tr, steps, loss, t_loss, correct, batch, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (MissingClosureError, ):\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py:42\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m norms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(norms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mstack(norms))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mnorm(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach(), norm_type)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]), norm_type)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/site-packages/torch/nn/utils/clip_grad.py:42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m norms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(norms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mstack(norms))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, norm_type)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]), norm_type)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD\n",
    "pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd5107",
   "metadata": {},
   "source": [
    "# Spectrum after training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "weights = list(me.get_layers_param().values())\n",
    "#weights = [layer.to(cpu) for layer in weights]\n",
    "lapOp = LaplacianOperator(weights)\n",
    "uTrained,vTrained = lapOp.diagonalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uTrained = uTrained.to('cpu')\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.hist(u.numpy(),bins=300,range=(-3,3))\n",
    "plt.subplot(212)\n",
    "plt.hist(uTrained.numpy(),bins=300,range=(-3,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b318ec",
   "metadata": {},
   "source": [
    "# Spectrum evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [28*28, 50, 50, 10]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=True))\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "epochs=epochs+1\n",
    "for i in range(epochs):\n",
    "    #Display spectrum : \n",
    "    me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "    weights = list(me.get_layers_param().values())\n",
    "    weights = [weight for weight in weights if len(weight.shape)==2]\n",
    "    #weights = [layer.to(cpu) for layer in weights]\n",
    "    lapOp = LaplacianOperator(weights)\n",
    "    u,v = lapOp.diagonalize()\n",
    "    plt.subplot(100*epochs + 11+i)\n",
    "    plt.hist(u.to('cpu').numpy(),bins=300,range=(-2,2))\n",
    "    #Train : \n",
    "    pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe980d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting eigenvectors \n",
    "idx = 6\n",
    "\n",
    "img =-v.T[idx][:28*28].to('cpu')\n",
    "pixels = img.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "\n",
    "\n",
    "print(u[285])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9aa30",
   "metadata": {},
   "source": [
    "# With absolute value : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebeaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [28*28, 50, 50, 10]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(2):\n",
    "    #Display spectrum : \n",
    "    me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "    weights = list(me.get_layers_param().values())\n",
    "    #weights = [layer.to(cpu) for layer in weights]\n",
    "    lapOp = LaplacianOperator(weights,positivation='abs')\n",
    "    uabs,vabs = lapOp.diagonalize()\n",
    "    plt.subplot(epochs*100+11+i)\n",
    "    plt.hist(uabs.to('cpu').numpy(),bins=300,range=(-3,3),color='orange')\n",
    "    #Train : \n",
    "    pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting eigenvectors \n",
    "idx = -8\n",
    "print(uabs[idx])\n",
    "\n",
    "img = vabs.T[idx][:28*28].to('cpu')\n",
    "pixels = img.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13628a",
   "metadata": {},
   "source": [
    "# With ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57119c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [28*28, 50, 50, 10]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(2):\n",
    "    #Display spectrum : \n",
    "    me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "    weights = list(me.get_layers_param().values())\n",
    "    weights = [weight for weight in weights if len(weight.shape)==2]\n",
    "    #weights = [layer.to(cpu) for layer in weights]\n",
    "    lapOp = LaplacianOperator(weights,positivation='relu')\n",
    "    urelu,vrelu = lapOp.diagonalize()\n",
    "    plt.subplot(epochs*100+11+i)\n",
    "    plt.hist(urelu.to('cpu').numpy(),bins=300,range=(-3,3),color='green')\n",
    "    #Train : \n",
    "    pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting eigenvectors \n",
    "idx = 789\n",
    "print(urelu[idx])\n",
    "\n",
    "img = vrelu.T[idx][:28*28].to('cpu')\n",
    "pixels = img.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "\n",
    "print(vrelu.shape)\n",
    "print(-vrelu.T[idx][-10:])\n",
    "(-vrelu.T[idx][-10:]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be246d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(torch.abs(vrelu.T[-5][:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf77575",
   "metadata": {},
   "source": [
    "# High spectrum tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9235b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(uabs.to('cpu')[28*28:].numpy(),bins=300,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "#Plotting eigenvectors \n",
    "idx = 888\n",
    "print(uabs[idx])\n",
    "\n",
    "\n",
    "def saveEigenImages():\n",
    "    i=28*28\n",
    "    while i <893:\n",
    "        idx = i \n",
    "        if vabs.T[idx][:28*28].mean()<(vabs.T[idx][:28*28].max()+vabs.T[idx][:28*28].min())/2:\n",
    "            vabs.T[idx]=-vabs.T[idx]\n",
    "        img = vabs.T[idx][:28*28].to('cpu')\n",
    "        pixels = img.reshape((28, 28))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.savefig('lapInputLayer' + \"/eigenVec%02d.png\" % idx)\n",
    "        plt.show()\n",
    "\n",
    "        i +=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dbf252",
   "metadata": {},
   "source": [
    "# Binary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651a7f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from gdeep.data import DataLoaderFromArray\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32)\n",
    "\n",
    "\n",
    "dataset = datasets.MNIST(root='./data',transform=ToTensor())\n",
    "idx  = torch.logical_or(dataset.targets==4,dataset.targets==6)\n",
    "dataset.targets = ((dataset.targets[idx]-4)/2).int()\n",
    "dataset.data = dataset.data[idx]\n",
    "\n",
    "\n",
    "my_dl = DataLoader(dataset)\n",
    "\n",
    "\n",
    "train_len = int(len(dataset)*5/6)\n",
    "train_set, test_set = random_split(dataset, [train_len, int(len(dataset)) - train_len])\n",
    "\n",
    "dl_tr2 = DataLoader(train_set, batch_size=32, shuffle=True) # Train dataloader\n",
    "dl_ts2 = DataLoader(test_set, batch_size=32, shuffle=False) # Test set \n",
    "\n",
    "\n",
    "\"\"\" Crappy stuff \n",
    "j = int(len(data)*5/6) \n",
    "print(data.type())\n",
    "\n",
    "\n",
    "dl2 = DataLoaderFromArray(data[:j].unsqueeze(1),targets[:j],X_val=data[j:].unsqueeze(1),y_val=targets[j:])\n",
    "dl_tr2, dl_ts2,_ = dl2.build_dataloaders(batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "#dl_tr2.dataset = [(x[0],int(x[1].item())) for x in dl_tr2.dataset]\n",
    "    \n",
    "#dl_ts2.dataset = [(x[0],int(x[1].item())) for x in dl_ts2.dataset]\n",
    "\n",
    "print(len(dl_tr),len(dl_ts))\n",
    "print(len(dl_tr2),len(dl_ts2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dl_ts2.dataset:\n",
    "    print(x[0].type())\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "arch = [28*28, 50, 50, 50, 2]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "pipe = Pipeline(model, (dl_tr2, dl_ts2), loss_fn, writer)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "overfit = True\n",
    "\n",
    "\n",
    "if overfit:\n",
    "    for epoch in range(150):\n",
    "         pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(epochs):\n",
    "    #Display spectrum : \n",
    "    me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "    weights = list(me.get_layers_param().values())\n",
    "    #weights = [layer.to(cpu) for layer in weights]\n",
    "    lapOp = LaplacianOperator(weights,positivation='relu')\n",
    "    ubin,vbin = lapOp.diagonalize()\n",
    "    plt.subplot(epochs*100+11+i)\n",
    "    plt.hist(ubin.to('cpu').numpy(),bins=300,color='black')\n",
    "    #Train : \n",
    "    pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def19872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveEigenImages2():\n",
    "    i=28*28-5\n",
    "    while i <len(vbin.T):\n",
    "        idx = i \n",
    "        if vbin.T[idx][:28*28].mean()<(vbin.T[idx][:28*28].max()+vbin.T[idx][:28*28].min())/2:\n",
    "            vbin.T[idx]=-vbin.T[idx]\n",
    "        img = vbin.T[idx][:28*28].to('cpu')\n",
    "        pixels = img.reshape((28, 28))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.savefig('lapInputLayerBin' + \"/eigenVec%02d.png\" % idx)\n",
    "        plt.show()\n",
    "\n",
    "        i +=1 \n",
    "\n",
    "saveEigenImages2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57176229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting eigenvectors \n",
    "idx = 815\n",
    "print(ubin[idx])\n",
    "img = vbin.T[idx][:28*28].to('cpu')\n",
    "pixels = img.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "print(-vbin.T[idx][-10:])\n",
    "(-vbin.T[idx][-10:]).argmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a57a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vbin.T[28*28+25][872]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d0339",
   "metadata": {},
   "source": [
    "# Getting to know the eigenvectors : metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee1ff1",
   "metadata": {},
   "source": [
    "- sign \n",
    "- Total entropy \n",
    "- Argmax \n",
    "- value at argmax \n",
    "- spatial correlations on input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positivise(v):\n",
    "    \"\"\"Transforme le signe de chaque colonne de la matrice v de sorte à ce que l'argmax soit de signe positif \"\"\"\n",
    "    res = torch.zeros(v.shape)\n",
    "    for idx in range(len(v.T)):\n",
    "        res[:,idx]=torch.sign(v.T[idx][torch.abs(v.T[idx]).argmax()])*v.T[idx]\n",
    "    return res \n",
    "        \n",
    "def sign(vec):\n",
    "    \"\"\"Détermine la fraction de signes - pour un vecteur propre vec\"\"\"\n",
    "    return (torch.relu(-torch.sign(vec)).sum())/len(vec)\n",
    "\n",
    "def maxValue(vec):\n",
    "    return vec.max()\n",
    "\n",
    "def argMax(vec):\n",
    "    return vec.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = res.T[0]\n",
    "print(torch.sign(v.T[torch.abs(v.T).argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbe7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vbin = positivise(vbin)\n",
    "vbin=vbin.to('cpu')\n",
    "ubin = ubin.to('cpu')\n",
    "plt.scatter(ubin[28*28:],[argMax(vec) for vec in vbin.T[28*28:]])\n",
    "plt.title('argmax of eigenvector as a function of eigenvalue')\n",
    "plt.ylim(780,940)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ubin,[maxValue(vec) for vec in vbin.T])\n",
    "plt.title('maximum value of eigenvector as a function of eigenvalue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f44b00",
   "metadata": {},
   "source": [
    "# Attaques adversariales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f9d906d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.958780 \tEpoch training accuracy: 72.43%                                                               \n",
      "Time taken for this epoch: 7.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 87.33%,                 Avg loss: 0.413775 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.339787 \tEpoch training accuracy: 90.29%                                      00 ]                      \n",
      "Time taken for this epoch: 6.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 91.62%,                 Avg loss: 0.294548 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.270056 \tEpoch training accuracy: 92.42%                                                                \n",
      "Time taken for this epoch: 6.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 93.00%,                 Avg loss: 0.240412 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.228947 \tEpoch training accuracy: 93.49%                                                                \n",
      "Time taken for this epoch: 7.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 93.95%,                 Avg loss: 0.210191 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch = [28*28, 50, 50, 10]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    #Train : \n",
    "    pipe.train(optimizer, 1, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "    \n",
    "    \n",
    "me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "weights = list(me.get_layers_param().values())\n",
    "#weights = [layer.to(cpu) for layer in weights]\n",
    "lapOp = LaplacianOperator(weights,positivation='abs')\n",
    "u,v = lapOp.diagonalize()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0f27a9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(u.to('cpu').numpy(),bins=300,color='orange')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3d72d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "topactiv = TFC(pipe,arch)\n",
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32)\n",
    "\n",
    "\n",
    "for data, target in dl_tr: \n",
    "    data_noised = data+(0.2*torch.rand(data.shape)-0.1)\n",
    "    data=data.to(DEVICE) ##SUBOPTIMAL !!!\n",
    "    target = target.to(DEVICE)\n",
    "    data_perturbed = topactiv.fgsm_attack(data, target,epsilon)\n",
    "    normal_activation = torch.cat(me.get_activations(data)[:-2],dim=1)\n",
    "    perturbed_activation = torch.cat(me.get_activations(data_perturbed)[:-2],dim=1)\n",
    "    noised_activation= torch.cat(me.get_activations(data_noised)[:-2],dim=1)\n",
    "    break \n",
    "    \n",
    "# Weird last layers to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in perturbed_activation:\n",
    "    if (x.shape)[1]==10:\n",
    "        print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aca1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6e4e3684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7370c77a00>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "normal_activation = normal_activation.to('cpu')\n",
    "perturbed_activation = perturbed_activation.to('cpu')\n",
    "noised_activation =  noised_activation.to('cpu')\n",
    "\n",
    "v=v.to('cpu')\n",
    "plt.scatter(v.T@normal_activation[idx]/normal_activation[idx].max(),v.T@perturbed_activation[idx]/perturbed_activation[idx].max())\n",
    "plt.scatter(v.T@normal_activation[idx]/normal_activation[idx].max(),v.T@noised_activation[idx]/noised_activation[idx].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(data.to('cpu')[2]-data_noised[2]).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
