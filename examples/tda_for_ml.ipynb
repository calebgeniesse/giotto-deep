{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toplogy of Deep Neural Networks\n",
    "\n",
    "This notebook will show you how easy it is to use gdeep to reproduce the experiments of the paper [Topology of Deep Neural Networks](https://arxiv.org/pdf/2004.06093.pdf), by Naizat et. al. In this work, the authors studied the evolution of the topology of a dataset as embedded in the successive layers of a Neural Network, trained for classification on this dataset.\n",
    "\n",
    "Their main findings can be summarized as follows:\n",
    "\n",
    "- Neural networks tend to simplify the topology of the dataset accross layers.\n",
    "\n",
    "- This decrease in topological complexity is more efficient when the activation functions are non-homeomorphic, as it is the case for ReLu or leakyReLu.\n",
    "\n",
    "Here is an illustration from the paper:\n",
    "\n",
    "![illustration](/notebook_images/tda_dl/intro.png)\n",
    "\n",
    "The main steps of this tutorial will be as follows:\n",
    "\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import autograd  \n",
    "\n",
    "#gdeep\n",
    "from gdeep.data.datasets import DatasetBuilder, DataLoaderBuilder\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.visualisation import persistence_diagrams_of_activations\n",
    "from gdeep.data.preprocessors import ToTensorImage\n",
    "from gdeep.trainer import Trainer\n",
    "from gdeep.search import Benchmark\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# TDA\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.plotting import plot_diagram\n",
    "\n",
    "#Tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DatasetBuilder(name=\"EntangledTori\")\n",
    "ds_tr, ds_val, ds_ts = db.build()\n",
    "dl_tr, dl_val, dl_ts = DataLoaderBuilder((ds_tr, ds_val, ds_ts)).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Entangled Tori dataset and prepare the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DatasetBuilder(name=\"EntangledTori\")\n",
    "ds_tr, ds_val, ds_ts = db.build()\n",
    "dl_tr, dl_val, dl_ts = DataLoaderBuilder((ds_tr, ds_val, ds_ts)).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models with different activations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "architecture = [3,10,10,10,10,2]\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "activation_string = [\"relu\", \"leakyrelu\", \"tanh\", \"sigmoid\"]\n",
    "activation_functions = [F.relu, F.leaky_relu, F.tanh, F.sigmoid]\n",
    "models = []\n",
    "writers = []\n",
    "trainers = []\n",
    "for i in range(len(activation_functions)):\n",
    "    model_temp = FFNet(arch = architecture, activation = activation_functions[i])\n",
    "    writer_temp = SummaryWriter(log_dir='runs/' + model_temp.__class__.__name__ + activation_string[i])\n",
    "    trainer_temp = Trainer(model_temp, [dl_tr, dl_ts], loss_function, writer_temp)\n",
    "    models.append(model_temp)\n",
    "    writers.append(writer_temp)\n",
    "    trainers.append(trainer_temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.687144 \tEpoch training accuracy: 55.23%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.38%,                 Avg loss: 0.668257 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Batch training loss:  0.6569196581840515  \tBatch training accuracy:  56.25  \t[ 2 / 40 ]                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkouknicolas/giotto-deep/gdeep/trainer/trainer.py:455: UserWarning:\n",
      "\n",
      "Cannot store data in the PR curve\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch training loss: 0.670238 \tEpoch training accuracy: 57.58%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.19%,                 Avg loss: 0.653777 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.647436 \tEpoch training accuracy: 58.52%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.44%,                 Avg loss: 0.626329 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.687558 \tEpoch training accuracy: 53.28%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.94%,                 Avg loss: 0.666075 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.660901 \tEpoch training accuracy: 57.58%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.00%,                 Avg loss: 0.630536 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.637047 \tEpoch training accuracy: 57.58%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.19%,                 Avg loss: 0.634423 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch training loss:  0.7072979509830475  \tBatch training accuracy:  65.625  \t[ 8 / 40 ]                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkouknicolas/.local/lib/python3.9/site-packages/torch/nn/functional.py:1933: UserWarning:\n",
      "\n",
      "nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch training loss: 0.684465 \tEpoch training accuracy: 58.28%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.25%,                 Avg loss: 0.670698 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.654094 \tEpoch training accuracy: 59.84%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.25%,                 Avg loss: 0.636051 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602042 \tEpoch training accuracy: 65.31%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 65.94%,                 Avg loss: 0.588885 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch training loss:  0.7146308693018827  \tBatch training accuracy:  34.375  \t[ 11 / 40 ]                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkouknicolas/.local/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning:\n",
      "\n",
      "nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch training loss: 0.700545 \tEpoch training accuracy: 49.69%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 43.75%,                 Avg loss: 0.709261 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.692876 \tEpoch training accuracy: 52.50%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.25%,                 Avg loss: 0.683622 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.691344 \tEpoch training accuracy: 53.28%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.06%,                 Avg loss: 0.687904 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pipe in trainers:\n",
    "    pipe.train(\n",
    "    Adam,\n",
    "    3,\n",
    "    False,\n",
    "    {\"lr\": 0.01},\n",
    "    {\"batch_size\": 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(trainers[0]) \n",
    "vs.plot_3d_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkouknicolas/.local/lib/python3.9/site-packages/torch/nn/functional.py:1933: UserWarning:\n",
      "\n",
      "nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "\n",
      "/home/berkouknicolas/.local/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning:\n",
      "\n",
      "nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_batch_dataset, _, _ = DataLoaderBuilder((ds_tr, ds_val, ds_ts)).build([{\"batch_size\":1600}, {\"batch_size\":1600}, {\"batch_size\":1600}]) \n",
    "\n",
    "\n",
    "for pipe in trainers:\n",
    "    vs = Visualiser(pipe)\n",
    "    vs.plot_persistence_diagrams(next(iter(one_batch_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.684559 \tEpoch training accuracy: 53.67%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 51.43%,                 Avg loss: 0.684506 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.667289 \tEpoch training accuracy: 55.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.14%,                 Avg loss: 0.668249 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.651055 \tEpoch training accuracy: 58.23%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.14%,                 Avg loss: 0.648084 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.623932 \tEpoch training accuracy: 60.95%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.71%,                 Avg loss: 0.627552 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.612219 \tEpoch training accuracy: 63.72%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.14%,                 Avg loss: 0.610575 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch training loss: 0.594819 \tEpoch training accuracy: 65.08%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.57%,                 Avg loss: 0.618354 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch training loss: 0.584752 \tEpoch training accuracy: 67.46%                                                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.29%,                 Avg loss: 0.587505 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch training loss: 0.569361 \tEpoch training accuracy: 68.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 65.86%,                 Avg loss: 0.615993 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch training loss: 0.566981 \tEpoch training accuracy: 68.87%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.29%,                 Avg loss: 0.572641 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch training loss: 0.554045 \tEpoch training accuracy: 71.23%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.86%,                 Avg loss: 0.552587 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch training loss: 0.548403 \tEpoch training accuracy: 70.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.71%,                 Avg loss: 0.602029 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch training loss: 0.540512 \tEpoch training accuracy: 70.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.86%,                 Avg loss: 0.556379 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch training loss: 0.538473 \tEpoch training accuracy: 72.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.43%,                 Avg loss: 0.557430 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch training loss: 0.537212 \tEpoch training accuracy: 71.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.43%,                 Avg loss: 0.538492 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch training loss: 0.525296 \tEpoch training accuracy: 71.92%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.511141 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch training loss: 0.532506 \tEpoch training accuracy: 71.21%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.519715 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch training loss: 0.516718 \tEpoch training accuracy: 72.46%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.43%,                 Avg loss: 0.583751 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch training loss: 0.542616 \tEpoch training accuracy: 71.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.71%,                 Avg loss: 0.538695 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch training loss: 0.527139 \tEpoch training accuracy: 70.69%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.57%,                 Avg loss: 0.499883 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Epoch training loss: 0.507425 \tEpoch training accuracy: 73.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.57%,                 Avg loss: 0.522961 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch training loss: 0.496723 \tEpoch training accuracy: 73.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.00%,                 Avg loss: 0.498142 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch training loss: 0.497284 \tEpoch training accuracy: 74.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.464530 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch training loss: 0.483892 \tEpoch training accuracy: 74.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.71%,                 Avg loss: 0.542219 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch training loss: 0.485702 \tEpoch training accuracy: 73.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.71%,                 Avg loss: 0.504891 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch training loss: 0.523426 \tEpoch training accuracy: 71.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.71%,                 Avg loss: 0.548441 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch training loss: 0.511646 \tEpoch training accuracy: 70.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.14%,                 Avg loss: 0.503227 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch training loss: 0.478163 \tEpoch training accuracy: 75.13%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.57%,                 Avg loss: 0.468903 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch training loss: 0.464274 \tEpoch training accuracy: 74.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.00%,                 Avg loss: 0.459006 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch training loss: 0.456801 \tEpoch training accuracy: 75.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.413728 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch training loss: 0.449214 \tEpoch training accuracy: 75.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.43%,                 Avg loss: 0.427257 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch training loss: 0.434910 \tEpoch training accuracy: 76.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.86%,                 Avg loss: 0.430797 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch training loss: 0.444040 \tEpoch training accuracy: 75.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.57%,                 Avg loss: 0.426755 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch training loss: 0.423162 \tEpoch training accuracy: 77.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.57%,                 Avg loss: 0.414818 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch training loss: 0.444088 \tEpoch training accuracy: 77.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.416521 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch training loss: 0.445434 \tEpoch training accuracy: 77.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.00%,                 Avg loss: 0.427824 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch training loss: 0.450858 \tEpoch training accuracy: 76.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.43%,                 Avg loss: 0.428757 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch training loss: 0.432279 \tEpoch training accuracy: 77.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.411964 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch training loss: 0.397963 \tEpoch training accuracy: 78.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.86%,                 Avg loss: 0.455382 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch training loss: 0.415170 \tEpoch training accuracy: 77.56%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.71%,                 Avg loss: 0.412318 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Epoch training loss: 0.428126 \tEpoch training accuracy: 76.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.14%,                 Avg loss: 0.450096 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch training loss: 0.431839 \tEpoch training accuracy: 77.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.00%,                 Avg loss: 0.389810 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch training loss: 0.406989 \tEpoch training accuracy: 77.72%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.57%,                 Avg loss: 0.449603 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405967 \tEpoch training accuracy: 77.13%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.57%,                 Avg loss: 0.388445 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch training loss: 0.398778 \tEpoch training accuracy: 78.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.86%,                 Avg loss: 0.403962 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405426 \tEpoch training accuracy: 77.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.29%,                 Avg loss: 0.438577 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch training loss: 0.385388 \tEpoch training accuracy: 78.49%                                       ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.14%,                 Avg loss: 0.425251 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch training loss: 0.403218 \tEpoch training accuracy: 78.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.86%,                 Avg loss: 0.377576 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch training loss: 0.385478 \tEpoch training accuracy: 79.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.29%,                 Avg loss: 0.423447 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch training loss: 0.402360 \tEpoch training accuracy: 78.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.14%,                 Avg loss: 0.407715 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch training loss: 0.409862 \tEpoch training accuracy: 79.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.43%,                 Avg loss: 0.469716 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch training loss: 0.422217 \tEpoch training accuracy: 78.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.14%,                 Avg loss: 0.381549 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch training loss: 0.381073 \tEpoch training accuracy: 79.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.439412 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch training loss: 0.387948 \tEpoch training accuracy: 79.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.57%,                 Avg loss: 0.405169 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405355 \tEpoch training accuracy: 80.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.43%,                 Avg loss: 0.400918 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch training loss: 0.415345 \tEpoch training accuracy: 77.41%                                                            \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.29%,                 Avg loss: 0.370348 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch training loss: 0.389641 \tEpoch training accuracy: 77.64%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.479906 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch training loss: 0.432575 \tEpoch training accuracy: 76.59%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.404460 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412414 \tEpoch training accuracy: 77.28%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.14%,                 Avg loss: 0.368483 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch training loss: 0.390205 \tEpoch training accuracy: 78.13%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.14%,                 Avg loss: 0.406570 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Epoch training loss: 0.403807 \tEpoch training accuracy: 79.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.57%,                 Avg loss: 0.417610 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch training loss: 0.396773 \tEpoch training accuracy: 78.21%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.57%,                 Avg loss: 0.433332 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch training loss: 0.382238 \tEpoch training accuracy: 80.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.356298 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch training loss: 0.389628 \tEpoch training accuracy: 78.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.391390 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch training loss: 0.375313 \tEpoch training accuracy: 79.56%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.57%,                 Avg loss: 0.369205 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch training loss: 0.398994 \tEpoch training accuracy: 80.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.00%,                 Avg loss: 0.413143 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch training loss: 0.387555 \tEpoch training accuracy: 78.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.14%,                 Avg loss: 0.429687 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch training loss: 0.395794 \tEpoch training accuracy: 78.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.57%,                 Avg loss: 0.375445 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch training loss: 0.372372 \tEpoch training accuracy: 79.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.86%,                 Avg loss: 0.381528 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch training loss: 0.384575 \tEpoch training accuracy: 80.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.385320 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch training loss: 0.360360 \tEpoch training accuracy: 82.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.374780 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch training loss: 0.358302 \tEpoch training accuracy: 81.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.14%,                 Avg loss: 0.370052 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch training loss: 0.366007 \tEpoch training accuracy: 80.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.43%,                 Avg loss: 0.381808 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch training loss: 0.389091 \tEpoch training accuracy: 80.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.29%,                 Avg loss: 0.387511 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch training loss: 0.407069 \tEpoch training accuracy: 78.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.86%,                 Avg loss: 0.380646 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch training loss: 0.359190 \tEpoch training accuracy: 81.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.57%,                 Avg loss: 0.437080 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch training loss: 0.363496 \tEpoch training accuracy: 82.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.14%,                 Avg loss: 0.398316 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch training loss: 0.353451 \tEpoch training accuracy: 82.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.43%,                 Avg loss: 0.353280 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch training loss: 0.357748 \tEpoch training accuracy: 80.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.350146 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch training loss: 0.371873 \tEpoch training accuracy: 78.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.57%,                 Avg loss: 0.384916 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Epoch training loss: 0.364890 \tEpoch training accuracy: 81.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.57%,                 Avg loss: 0.511851 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch training loss: 0.381444 \tEpoch training accuracy: 79.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.29%,                 Avg loss: 0.400019 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch training loss: 0.383638 \tEpoch training accuracy: 79.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.86%,                 Avg loss: 0.406681 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch training loss: 0.358222 \tEpoch training accuracy: 82.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.29%,                 Avg loss: 0.364038 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch training loss: 0.379699 \tEpoch training accuracy: 79.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.43%,                 Avg loss: 0.393406 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch training loss: 0.375284 \tEpoch training accuracy: 79.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.00%,                 Avg loss: 0.343076 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch training loss: 0.364421 \tEpoch training accuracy: 81.64%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.29%,                 Avg loss: 0.413478 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch training loss: 0.379590 \tEpoch training accuracy: 79.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.57%,                 Avg loss: 0.363756 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch training loss: 0.349969 \tEpoch training accuracy: 81.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.43%,                 Avg loss: 0.368403 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch training loss: 0.375919 \tEpoch training accuracy: 79.87%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.29%,                 Avg loss: 0.356991 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch training loss: 0.369876 \tEpoch training accuracy: 80.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.359917 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch training loss: 0.352582 \tEpoch training accuracy: 80.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.14%,                 Avg loss: 0.370723 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch training loss: 0.340486 \tEpoch training accuracy: 82.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.381947 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch training loss: 0.353654 \tEpoch training accuracy: 82.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.43%,                 Avg loss: 0.343167 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch training loss: 0.360031 \tEpoch training accuracy: 80.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.29%,                 Avg loss: 0.371701 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch training loss: 0.363905 \tEpoch training accuracy: 80.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.57%,                 Avg loss: 0.375319 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch training loss: 0.346709 \tEpoch training accuracy: 80.95%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.29%,                 Avg loss: 0.373227 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch training loss: 0.376569 \tEpoch training accuracy: 80.36%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.449519 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405227 \tEpoch training accuracy: 77.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.374917 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch training loss: 0.368891 \tEpoch training accuracy: 80.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.00%,                 Avg loss: 0.355404 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Epoch training loss: 0.356791 \tEpoch training accuracy: 82.21%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.86%,                 Avg loss: 0.394154 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.684206 \tEpoch training accuracy: 54.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.86%,                 Avg loss: 0.676360 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.683423 \tEpoch training accuracy: 55.85%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.00%,                 Avg loss: 0.658862 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.646347 \tEpoch training accuracy: 57.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.71%,                 Avg loss: 0.648951 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.615322 \tEpoch training accuracy: 58.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 51.57%,                 Avg loss: 0.656298 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.607964 \tEpoch training accuracy: 58.72%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.00%,                 Avg loss: 0.601245 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch training loss: 0.594787 \tEpoch training accuracy: 59.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.43%,                 Avg loss: 0.603887 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch training loss: 0.612111 \tEpoch training accuracy: 60.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.57%,                 Avg loss: 0.638430 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch training loss: 0.612674 \tEpoch training accuracy: 58.44%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.00%,                 Avg loss: 0.619413 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch training loss: 0.589699 \tEpoch training accuracy: 57.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.57%,                 Avg loss: 0.598000 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch training loss: 0.580399 \tEpoch training accuracy: 59.85%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.14%,                 Avg loss: 0.605395 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch training loss: 0.577978 \tEpoch training accuracy: 62.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.71%,                 Avg loss: 0.591898 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch training loss: 0.584155 \tEpoch training accuracy: 59.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.00%,                 Avg loss: 0.620556 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch training loss: 0.581712 \tEpoch training accuracy: 59.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.14%,                 Avg loss: 0.590702 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch training loss: 0.575660 \tEpoch training accuracy: 61.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.43%,                 Avg loss: 0.602960 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch training loss: 0.577381 \tEpoch training accuracy: 62.05%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.71%,                 Avg loss: 0.601618 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch training loss: 0.576676 \tEpoch training accuracy: 62.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.00%,                 Avg loss: 0.597539 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch training loss: 0.568078 \tEpoch training accuracy: 62.85%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.43%,                 Avg loss: 0.587661 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch training loss: 0.555609 \tEpoch training accuracy: 68.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 64.29%,                 Avg loss: 0.586183 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch training loss: 0.551529 \tEpoch training accuracy: 67.85%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.71%,                 Avg loss: 0.588796 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Epoch training loss: 0.544664 \tEpoch training accuracy: 69.92%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.43%,                 Avg loss: 0.601903 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch training loss: 0.571543 \tEpoch training accuracy: 63.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.86%,                 Avg loss: 0.596175 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch training loss: 0.572183 \tEpoch training accuracy: 64.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 65.00%,                 Avg loss: 0.587796 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch training loss: 0.555771 \tEpoch training accuracy: 67.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.00%,                 Avg loss: 0.561564 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch training loss: 0.548869 \tEpoch training accuracy: 69.79%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.43%,                 Avg loss: 0.584206 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch training loss: 0.545327 \tEpoch training accuracy: 69.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.43%,                 Avg loss: 0.569189 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch training loss: 0.530310 \tEpoch training accuracy: 70.97%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.29%,                 Avg loss: 0.596768 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch training loss: 0.526442 \tEpoch training accuracy: 68.77%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.14%,                 Avg loss: 0.532348 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch training loss: 0.506493 \tEpoch training accuracy: 71.00%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.43%,                 Avg loss: 0.537382 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch training loss: 0.518128 \tEpoch training accuracy: 70.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.00%,                 Avg loss: 0.546415 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch training loss: 0.512392 \tEpoch training accuracy: 69.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.00%,                 Avg loss: 0.542252 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch training loss: 0.523062 \tEpoch training accuracy: 71.08%                                               76.0  \t[ 15 / 26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.00%,                 Avg loss: 0.600226 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch training loss: 0.563591 \tEpoch training accuracy: 68.08%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.57%,                 Avg loss: 0.547044 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch training loss: 0.504627 \tEpoch training accuracy: 73.92%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.71%,                 Avg loss: 0.560132 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch training loss: 0.485245 \tEpoch training accuracy: 74.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.00%,                 Avg loss: 0.524789 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch training loss: 0.514656 \tEpoch training accuracy: 71.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.00%,                 Avg loss: 0.532439 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch training loss: 0.486034 \tEpoch training accuracy: 74.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.29%,                 Avg loss: 0.506004 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch training loss: 0.506276 \tEpoch training accuracy: 72.79%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.86%,                 Avg loss: 0.539031 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch training loss: 0.472500 \tEpoch training accuracy: 75.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.71%,                 Avg loss: 0.494391 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch training loss: 0.461637 \tEpoch training accuracy: 75.74%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.00%,                 Avg loss: 0.516754 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Epoch training loss: 0.471303 \tEpoch training accuracy: 74.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.86%,                 Avg loss: 0.502727 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch training loss: 0.471816 \tEpoch training accuracy: 75.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.00%,                 Avg loss: 0.496430 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch training loss: 0.448423 \tEpoch training accuracy: 74.49%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.86%,                 Avg loss: 0.537004 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch training loss: 0.487028 \tEpoch training accuracy: 74.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.14%,                 Avg loss: 0.566654 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch training loss: 0.459261 \tEpoch training accuracy: 74.92%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.57%,                 Avg loss: 0.480802 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch training loss: 0.458703 \tEpoch training accuracy: 74.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.14%,                 Avg loss: 0.506104 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch training loss: 0.472269 \tEpoch training accuracy: 75.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.14%,                 Avg loss: 0.485051 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch training loss: 0.451087 \tEpoch training accuracy: 74.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.86%,                 Avg loss: 0.503802 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch training loss: 0.465705 \tEpoch training accuracy: 73.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.43%,                 Avg loss: 0.491121 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch training loss: 0.444591 \tEpoch training accuracy: 76.26%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.460625 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch training loss: 0.435205 \tEpoch training accuracy: 75.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.00%,                 Avg loss: 0.474212 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch training loss: 0.436683 \tEpoch training accuracy: 75.31%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.29%,                 Avg loss: 0.473152 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch training loss: 0.481333 \tEpoch training accuracy: 74.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.29%,                 Avg loss: 0.521506 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch training loss: 0.456786 \tEpoch training accuracy: 75.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.86%,                 Avg loss: 0.465032 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch training loss: 0.446643 \tEpoch training accuracy: 75.33%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.00%,                 Avg loss: 0.457686 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch training loss: 0.431798 \tEpoch training accuracy: 76.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.29%,                 Avg loss: 0.483634 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch training loss: 0.430708 \tEpoch training accuracy: 76.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.00%,                 Avg loss: 0.448865 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch training loss: 0.431663 \tEpoch training accuracy: 76.26%                                                                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.00%,                 Avg loss: 0.470014 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch training loss: 0.425981 \tEpoch training accuracy: 76.67%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.29%,                 Avg loss: 0.470515 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch training loss: 0.431495 \tEpoch training accuracy: 77.44%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.43%,                 Avg loss: 0.482180 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Epoch training loss: 0.446583 \tEpoch training accuracy: 76.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.86%,                 Avg loss: 0.497403 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch training loss: 0.407170 \tEpoch training accuracy: 78.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.418640 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch training loss: 0.400359 \tEpoch training accuracy: 78.92%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.71%,                 Avg loss: 0.434151 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch training loss: 0.410020 \tEpoch training accuracy: 77.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.464705 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch training loss: 0.419367 \tEpoch training accuracy: 77.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.442781 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch training loss: 0.404755 \tEpoch training accuracy: 77.36%                                      ]                     6 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.29%,                 Avg loss: 0.477507 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch training loss: 0.413907 \tEpoch training accuracy: 77.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.86%,                 Avg loss: 0.473659 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch training loss: 0.432396 \tEpoch training accuracy: 78.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.71%,                 Avg loss: 0.464049 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch training loss: 0.425392 \tEpoch training accuracy: 78.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.427046 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch training loss: 0.386734 \tEpoch training accuracy: 80.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.00%,                 Avg loss: 0.416775 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch training loss: 0.404849 \tEpoch training accuracy: 79.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.00%,                 Avg loss: 0.429741 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch training loss: 0.406084 \tEpoch training accuracy: 79.05%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.415488 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch training loss: 0.383640 \tEpoch training accuracy: 77.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.57%,                 Avg loss: 0.410062 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch training loss: 0.403908 \tEpoch training accuracy: 78.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.43%,                 Avg loss: 0.392864 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch training loss: 0.398954 \tEpoch training accuracy: 78.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.452243 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405107 \tEpoch training accuracy: 78.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.14%,                 Avg loss: 0.439258 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405844 \tEpoch training accuracy: 77.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.405859 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch training loss: 0.383875 \tEpoch training accuracy: 79.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.57%,                 Avg loss: 0.410907 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch training loss: 0.383514 \tEpoch training accuracy: 78.74%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.57%,                 Avg loss: 0.422674 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch training loss: 0.400566 \tEpoch training accuracy: 78.90%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.43%,                 Avg loss: 0.430951 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Epoch training loss: 0.382363 \tEpoch training accuracy: 78.05%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.29%,                 Avg loss: 0.427468 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch training loss: 0.390420 \tEpoch training accuracy: 80.49%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.43%,                 Avg loss: 0.414452 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch training loss: 0.394915 \tEpoch training accuracy: 77.92%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.29%,                 Avg loss: 0.420501 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch training loss: 0.408658 \tEpoch training accuracy: 78.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.57%,                 Avg loss: 0.461539 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch training loss: 0.411107 \tEpoch training accuracy: 77.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.457553 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch training loss: 0.424758 \tEpoch training accuracy: 78.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.14%,                 Avg loss: 0.438748 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch training loss: 0.402564 \tEpoch training accuracy: 80.28%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.57%,                 Avg loss: 0.429114 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch training loss: 0.416908 \tEpoch training accuracy: 78.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.00%,                 Avg loss: 0.426889 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch training loss: 0.397852 \tEpoch training accuracy: 79.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.406895 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch training loss: 0.384940 \tEpoch training accuracy: 80.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.438955 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch training loss: 0.400184 \tEpoch training accuracy: 78.03%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.00%,                 Avg loss: 0.393849 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch training loss: 0.380817 \tEpoch training accuracy: 79.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.00%,                 Avg loss: 0.399423 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch training loss: 0.386320 \tEpoch training accuracy: 78.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.00%,                 Avg loss: 0.403458 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch training loss: 0.370431 \tEpoch training accuracy: 79.56%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.29%,                 Avg loss: 0.411215 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch training loss: 0.403856 \tEpoch training accuracy: 79.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.86%,                 Avg loss: 0.471105 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch training loss: 0.399611 \tEpoch training accuracy: 78.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.14%,                 Avg loss: 0.444062 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch training loss: 0.384853 \tEpoch training accuracy: 78.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.71%,                 Avg loss: 0.390206 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch training loss: 0.398718 \tEpoch training accuracy: 78.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.14%,                 Avg loss: 0.402839 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch training loss: 0.386376 \tEpoch training accuracy: 80.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.29%,                 Avg loss: 0.405757 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch training loss: 0.371120 \tEpoch training accuracy: 81.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.86%,                 Avg loss: 0.414286 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Epoch training loss: 0.381157 \tEpoch training accuracy: 81.33%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.43%,                 Avg loss: 0.393873 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.673739 \tEpoch training accuracy: 57.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.43%,                 Avg loss: 0.661427 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.635113 \tEpoch training accuracy: 60.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.14%,                 Avg loss: 0.646403 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.615140 \tEpoch training accuracy: 59.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.71%,                 Avg loss: 0.607430 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.593225 \tEpoch training accuracy: 61.69%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.29%,                 Avg loss: 0.644108 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.614845 \tEpoch training accuracy: 61.56%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.71%,                 Avg loss: 0.605894 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch training loss: 0.583121 \tEpoch training accuracy: 61.05%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.86%,                 Avg loss: 0.586456 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch training loss: 0.573703 \tEpoch training accuracy: 62.54%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.00%,                 Avg loss: 0.580986 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch training loss: 0.572164 \tEpoch training accuracy: 61.28%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.86%,                 Avg loss: 0.599531 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch training loss: 0.556116 \tEpoch training accuracy: 66.15%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.29%,                 Avg loss: 0.616311 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch training loss: 0.543681 \tEpoch training accuracy: 65.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.00%,                 Avg loss: 0.551874 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch training loss: 0.540652 \tEpoch training accuracy: 67.44%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.43%,                 Avg loss: 0.580596 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch training loss: 0.530866 \tEpoch training accuracy: 67.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.57%,                 Avg loss: 0.539278 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch training loss: 0.538314 \tEpoch training accuracy: 65.38%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.71%,                 Avg loss: 0.557148 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch training loss: 0.528460 \tEpoch training accuracy: 69.38%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.57%,                 Avg loss: 0.583177 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch training loss: 0.532289 \tEpoch training accuracy: 66.87%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.71%,                 Avg loss: 0.525200 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch training loss: 0.521916 \tEpoch training accuracy: 68.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.29%,                 Avg loss: 0.521198 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch training loss: 0.535416 \tEpoch training accuracy: 66.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 65.86%,                 Avg loss: 0.540967 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch training loss: 0.524618 \tEpoch training accuracy: 67.18%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 64.57%,                 Avg loss: 0.567716 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch training loss: 0.526551 \tEpoch training accuracy: 68.08%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.71%,                 Avg loss: 0.541763 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Epoch training loss: 0.508013 \tEpoch training accuracy: 70.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.14%,                 Avg loss: 0.500884 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch training loss: 0.502899 \tEpoch training accuracy: 71.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.29%,                 Avg loss: 0.516545 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch training loss: 0.499795 \tEpoch training accuracy: 70.18%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.86%,                 Avg loss: 0.528553 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch training loss: 0.496861 \tEpoch training accuracy: 67.82%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.00%,                 Avg loss: 0.505723 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch training loss: 0.488069 \tEpoch training accuracy: 69.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.57%,                 Avg loss: 0.498837 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch training loss: 0.481244 \tEpoch training accuracy: 71.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.14%,                 Avg loss: 0.492014 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch training loss: 0.487857 \tEpoch training accuracy: 71.59%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.29%,                 Avg loss: 0.509431 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch training loss: 0.483878 \tEpoch training accuracy: 69.23%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.57%,                 Avg loss: 0.488909 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch training loss: 0.478134 \tEpoch training accuracy: 69.92%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.86%,                 Avg loss: 0.498436 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch training loss: 0.478690 \tEpoch training accuracy: 70.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.57%,                 Avg loss: 0.506705 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch training loss: 0.472601 \tEpoch training accuracy: 70.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.57%,                 Avg loss: 0.506084 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch training loss: 0.481577 \tEpoch training accuracy: 72.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.71%,                 Avg loss: 0.492920 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch training loss: 0.475299 \tEpoch training accuracy: 70.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.57%,                 Avg loss: 0.495170 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch training loss: 0.479203 \tEpoch training accuracy: 70.92%                                                            \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.14%,                 Avg loss: 0.492474 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch training loss: 0.471771 \tEpoch training accuracy: 69.15%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.86%,                 Avg loss: 0.469419 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch training loss: 0.459477 \tEpoch training accuracy: 70.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.71%,                 Avg loss: 0.488274 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch training loss: 0.458634 \tEpoch training accuracy: 71.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.86%,                 Avg loss: 0.487462 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch training loss: 0.458680 \tEpoch training accuracy: 71.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.00%,                 Avg loss: 0.472250 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch training loss: 0.463986 \tEpoch training accuracy: 72.05%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.14%,                 Avg loss: 0.478545 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch training loss: 0.486173 \tEpoch training accuracy: 72.00%                                                            \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.00%,                 Avg loss: 0.504062 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Epoch training loss: 0.459755 \tEpoch training accuracy: 70.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.29%,                 Avg loss: 0.456307 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch training loss: 0.450403 \tEpoch training accuracy: 73.69%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.71%,                 Avg loss: 0.468144 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch training loss: 0.477544 \tEpoch training accuracy: 72.56%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.00%,                 Avg loss: 0.491658 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch training loss: 0.484304 \tEpoch training accuracy: 72.44%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.14%,                 Avg loss: 0.507061 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch training loss: 0.489173 \tEpoch training accuracy: 72.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.29%,                 Avg loss: 0.520878 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch training loss: 0.467714 \tEpoch training accuracy: 72.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.14%,                 Avg loss: 0.483494 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch training loss: 0.443445 \tEpoch training accuracy: 74.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.14%,                 Avg loss: 0.481320 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch training loss: 0.505616 \tEpoch training accuracy: 71.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.29%,                 Avg loss: 0.530506 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch training loss: 0.496759 \tEpoch training accuracy: 72.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.29%,                 Avg loss: 0.502450 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch training loss: 0.484086 \tEpoch training accuracy: 72.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.498491 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch training loss: 0.466630 \tEpoch training accuracy: 71.23%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.29%,                 Avg loss: 0.479556 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch training loss: 0.470568 \tEpoch training accuracy: 73.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.29%,                 Avg loss: 0.492198 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch training loss: 0.480561 \tEpoch training accuracy: 72.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.71%,                 Avg loss: 0.497820 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch training loss: 0.473043 \tEpoch training accuracy: 72.87%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.43%,                 Avg loss: 0.465663 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch training loss: 0.461237 \tEpoch training accuracy: 72.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.14%,                 Avg loss: 0.451885 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch training loss: 0.455444 \tEpoch training accuracy: 72.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.00%,                 Avg loss: 0.470631 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch training loss: 0.451984 \tEpoch training accuracy: 72.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.446015 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch training loss: 0.436955 \tEpoch training accuracy: 71.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.00%,                 Avg loss: 0.483800 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch training loss: 0.456575 \tEpoch training accuracy: 72.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.471383 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch training loss: 0.444813 \tEpoch training accuracy: 72.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.71%,                 Avg loss: 0.476995 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Epoch training loss: 0.443084 \tEpoch training accuracy: 74.56%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.57%,                 Avg loss: 0.464876 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch training loss: 0.454940 \tEpoch training accuracy: 71.26%                                                            \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.453204 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch training loss: 0.435855 \tEpoch training accuracy: 73.74%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.71%,                 Avg loss: 0.446012 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch training loss: 0.439367 \tEpoch training accuracy: 73.87%                                                            \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.71%,                 Avg loss: 0.452324 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch training loss: 0.454484 \tEpoch training accuracy: 72.90%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.14%,                 Avg loss: 0.476663 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch training loss: 0.453997 \tEpoch training accuracy: 71.56%                                       ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.57%,                 Avg loss: 0.429923 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch training loss: 0.443579 \tEpoch training accuracy: 72.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.86%,                 Avg loss: 0.427041 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch training loss: 0.427293 \tEpoch training accuracy: 74.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.434495 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch training loss: 0.436131 \tEpoch training accuracy: 74.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.00%,                 Avg loss: 0.450705 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch training loss: 0.435830 \tEpoch training accuracy: 74.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.00%,                 Avg loss: 0.457045 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch training loss: 0.442144 \tEpoch training accuracy: 73.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.14%,                 Avg loss: 0.549737 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch training loss: 0.446746 \tEpoch training accuracy: 71.87%                                       ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.29%,                 Avg loss: 0.478132 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch training loss: 0.445012 \tEpoch training accuracy: 73.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.00%,                 Avg loss: 0.442384 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch training loss: 0.430364 \tEpoch training accuracy: 73.90%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.433915 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412382 \tEpoch training accuracy: 77.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.57%,                 Avg loss: 0.446975 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch training loss: 0.436916 \tEpoch training accuracy: 72.92%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.71%,                 Avg loss: 0.454875 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch training loss: 0.421444 \tEpoch training accuracy: 75.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.00%,                 Avg loss: 0.432721 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch training loss: 0.411968 \tEpoch training accuracy: 75.79%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.86%,                 Avg loss: 0.428971 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch training loss: 0.422540 \tEpoch training accuracy: 74.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.86%,                 Avg loss: 0.448395 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch training loss: 0.420216 \tEpoch training accuracy: 75.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.71%,                 Avg loss: 0.490773 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Epoch training loss: 0.418564 \tEpoch training accuracy: 74.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.430755 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch training loss: 0.407936 \tEpoch training accuracy: 76.56%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.86%,                 Avg loss: 0.456029 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch training loss: 0.422668 \tEpoch training accuracy: 75.05%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.57%,                 Avg loss: 0.433635 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412474 \tEpoch training accuracy: 75.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.57%,                 Avg loss: 0.424265 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch training loss: 0.428752 \tEpoch training accuracy: 75.67%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.29%,                 Avg loss: 0.444040 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch training loss: 0.423903 \tEpoch training accuracy: 74.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.86%,                 Avg loss: 0.428229 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412765 \tEpoch training accuracy: 74.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.71%,                 Avg loss: 0.430923 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch training loss: 0.398807 \tEpoch training accuracy: 76.90%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.71%,                 Avg loss: 0.472934 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch training loss: 0.431184 \tEpoch training accuracy: 74.36%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.14%,                 Avg loss: 0.447093 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch training loss: 0.431690 \tEpoch training accuracy: 73.10%                                      ]                      26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.00%,                 Avg loss: 0.458856 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch training loss: 0.397405 \tEpoch training accuracy: 75.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.57%,                 Avg loss: 0.403016 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch training loss: 0.393613 \tEpoch training accuracy: 77.18%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.43%,                 Avg loss: 0.393163 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch training loss: 0.393296 \tEpoch training accuracy: 76.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.86%,                 Avg loss: 0.415995 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch training loss: 0.409229 \tEpoch training accuracy: 76.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.14%,                 Avg loss: 0.421830 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch training loss: 0.384122 \tEpoch training accuracy: 77.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.407210 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch training loss: 0.386056 \tEpoch training accuracy: 76.23%                                                \t[ 26 / 26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.71%,                 Avg loss: 0.411761 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch training loss: 0.403116 \tEpoch training accuracy: 76.31%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.71%,                 Avg loss: 0.463494 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch training loss: 0.399044 \tEpoch training accuracy: 74.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.86%,                 Avg loss: 0.395354 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch training loss: 0.386045 \tEpoch training accuracy: 78.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.86%,                 Avg loss: 0.404076 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch training loss: 0.395118 \tEpoch training accuracy: 76.56%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.71%,                 Avg loss: 0.412408 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412300 \tEpoch training accuracy: 76.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.14%,                 Avg loss: 0.402924 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.706551 \tEpoch training accuracy: 48.33%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.43%,                 Avg loss: 0.685988 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.694978 \tEpoch training accuracy: 50.33%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 41.86%,                 Avg loss: 0.699585 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.694537 \tEpoch training accuracy: 49.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 44.86%,                 Avg loss: 0.711295 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.692345 \tEpoch training accuracy: 52.13%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.689253 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.688052 \tEpoch training accuracy: 54.15%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 52.86%,                 Avg loss: 0.686277 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch training loss: 0.667934 \tEpoch training accuracy: 59.54%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.29%,                 Avg loss: 0.670806 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch training loss: 0.645754 \tEpoch training accuracy: 61.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.14%,                 Avg loss: 0.656701 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch training loss: 0.630827 \tEpoch training accuracy: 61.23%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.29%,                 Avg loss: 0.640296 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch training loss: 0.632101 \tEpoch training accuracy: 61.21%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.43%,                 Avg loss: 0.607819 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch training loss: 0.625554 \tEpoch training accuracy: 61.15%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.71%,                 Avg loss: 0.620729 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch training loss: 0.622871 \tEpoch training accuracy: 61.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.14%,                 Avg loss: 0.644339 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch training loss: 0.625719 \tEpoch training accuracy: 61.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.14%,                 Avg loss: 0.616774 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch training loss: 0.619074 \tEpoch training accuracy: 61.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.29%,                 Avg loss: 0.639188 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch training loss: 0.626479 \tEpoch training accuracy: 60.56%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.14%,                 Avg loss: 0.624600 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch training loss: 0.624005 \tEpoch training accuracy: 61.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.57%,                 Avg loss: 0.630500 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch training loss: 0.621366 \tEpoch training accuracy: 61.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.71%,                 Avg loss: 0.621340 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch training loss: 0.619174 \tEpoch training accuracy: 62.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.29%,                 Avg loss: 0.637315 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch training loss: 0.625393 \tEpoch training accuracy: 61.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.43%,                 Avg loss: 0.625653 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch training loss: 0.620808 \tEpoch training accuracy: 61.67%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.14%,                 Avg loss: 0.614700 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Epoch training loss: 0.624004 \tEpoch training accuracy: 61.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.29%,                 Avg loss: 0.621770 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch training loss: 0.619126 \tEpoch training accuracy: 62.00%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.00%,                 Avg loss: 0.609463 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch training loss: 0.623029 \tEpoch training accuracy: 61.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 56.29%,                 Avg loss: 0.616267 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch training loss: 0.616559 \tEpoch training accuracy: 62.08%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.29%,                 Avg loss: 0.610078 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch training loss: 0.620022 \tEpoch training accuracy: 61.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.71%,                 Avg loss: 0.615378 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch training loss: 0.613180 \tEpoch training accuracy: 61.97%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.605224 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch training loss: 0.614027 \tEpoch training accuracy: 62.18%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.14%,                 Avg loss: 0.616222 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch training loss: 0.611247 \tEpoch training accuracy: 62.38%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.00%,                 Avg loss: 0.597478 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch training loss: 0.611076 \tEpoch training accuracy: 62.90%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.71%,                 Avg loss: 0.613934 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch training loss: 0.612746 \tEpoch training accuracy: 63.36%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.29%,                 Avg loss: 0.622206 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch training loss: 0.604774 \tEpoch training accuracy: 64.95%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.14%,                 Avg loss: 0.606198 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch training loss: 0.610004 \tEpoch training accuracy: 63.23%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.71%,                 Avg loss: 0.599942 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch training loss: 0.615864 \tEpoch training accuracy: 63.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.00%,                 Avg loss: 0.614038 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch training loss: 0.609421 \tEpoch training accuracy: 62.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.57%,                 Avg loss: 0.612565 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605491 \tEpoch training accuracy: 62.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.29%,                 Avg loss: 0.619509 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605324 \tEpoch training accuracy: 65.31%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.57%,                 Avg loss: 0.602532 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch training loss: 0.604264 \tEpoch training accuracy: 65.03%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.29%,                 Avg loss: 0.622511 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch training loss: 0.606093 \tEpoch training accuracy: 64.74%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.71%,                 Avg loss: 0.620075 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605379 \tEpoch training accuracy: 65.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.43%,                 Avg loss: 0.612902 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch training loss: 0.604878 \tEpoch training accuracy: 65.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.14%,                 Avg loss: 0.619803 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601780 \tEpoch training accuracy: 65.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.605812 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605840 \tEpoch training accuracy: 64.03%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.00%,                 Avg loss: 0.607274 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch training loss: 0.607867 \tEpoch training accuracy: 64.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.00%,                 Avg loss: 0.650165 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch training loss: 0.606976 \tEpoch training accuracy: 64.15%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.71%,                 Avg loss: 0.625737 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch training loss: 0.606179 \tEpoch training accuracy: 64.92%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.57%,                 Avg loss: 0.619733 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch training loss: 0.606342 \tEpoch training accuracy: 64.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.57%,                 Avg loss: 0.611283 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603985 \tEpoch training accuracy: 64.85%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.71%,                 Avg loss: 0.610813 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605612 \tEpoch training accuracy: 65.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 57.86%,                 Avg loss: 0.603825 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch training loss: 0.606208 \tEpoch training accuracy: 65.31%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.14%,                 Avg loss: 0.623603 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603200 \tEpoch training accuracy: 64.03%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.71%,                 Avg loss: 0.617141 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch training loss: 0.604054 \tEpoch training accuracy: 65.85%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.71%,                 Avg loss: 0.612888 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603495 \tEpoch training accuracy: 65.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.608670 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch training loss: 0.608998 \tEpoch training accuracy: 64.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.29%,                 Avg loss: 0.618431 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603772 \tEpoch training accuracy: 65.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.14%,                 Avg loss: 0.600359 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602402 \tEpoch training accuracy: 65.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.00%,                 Avg loss: 0.618166 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch training loss: 0.604664 \tEpoch training accuracy: 65.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.71%,                 Avg loss: 0.618729 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602481 \tEpoch training accuracy: 64.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.57%,                 Avg loss: 0.592970 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605251 \tEpoch training accuracy: 63.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.71%,                 Avg loss: 0.594649 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602295 \tEpoch training accuracy: 65.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.71%,                 Avg loss: 0.602160 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601975 \tEpoch training accuracy: 65.72%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.43%,                 Avg loss: 0.610560 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603563 \tEpoch training accuracy: 64.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.86%,                 Avg loss: 0.603158 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch training loss: 0.600929 \tEpoch training accuracy: 65.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.57%,                 Avg loss: 0.601315 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601203 \tEpoch training accuracy: 65.87%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.00%,                 Avg loss: 0.611639 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603499 \tEpoch training accuracy: 65.69%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.86%,                 Avg loss: 0.614635 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601253 \tEpoch training accuracy: 65.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.43%,                 Avg loss: 0.603744 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch training loss: 0.600912 \tEpoch training accuracy: 65.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.57%,                 Avg loss: 0.601780 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602219 \tEpoch training accuracy: 64.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.57%,                 Avg loss: 0.615981 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch training loss: 0.600181 \tEpoch training accuracy: 65.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 54.71%,                 Avg loss: 0.626663 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601914 \tEpoch training accuracy: 64.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.43%,                 Avg loss: 0.612007 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch training loss: 0.600582 \tEpoch training accuracy: 64.49%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.57%,                 Avg loss: 0.597468 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601289 \tEpoch training accuracy: 65.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.29%,                 Avg loss: 0.611162 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601224 \tEpoch training accuracy: 65.56%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.43%,                 Avg loss: 0.602774 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601779 \tEpoch training accuracy: 65.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.86%,                 Avg loss: 0.618891 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599450 \tEpoch training accuracy: 64.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.00%,                 Avg loss: 0.625146 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599922 \tEpoch training accuracy: 65.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.71%,                 Avg loss: 0.609176 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch training loss: 0.598407 \tEpoch training accuracy: 66.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.43%,                 Avg loss: 0.609199 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602004 \tEpoch training accuracy: 65.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.86%,                 Avg loss: 0.619793 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch training loss: 0.598600 \tEpoch training accuracy: 66.23%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.43%,                 Avg loss: 0.619078 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599066 \tEpoch training accuracy: 65.49%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.00%,                 Avg loss: 0.605599 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch training loss: 0.600656 \tEpoch training accuracy: 63.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.601416 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602702 \tEpoch training accuracy: 63.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.29%,                 Avg loss: 0.617067 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599533 \tEpoch training accuracy: 66.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 55.86%,                 Avg loss: 0.625076 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599049 \tEpoch training accuracy: 64.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.00%,                 Avg loss: 0.620059 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602599 \tEpoch training accuracy: 65.56%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.57%,                 Avg loss: 0.609068 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch training loss: 0.598477 \tEpoch training accuracy: 65.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.71%,                 Avg loss: 0.605451 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch training loss: 0.598841 \tEpoch training accuracy: 65.15%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.611883 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch training loss: 0.600345 \tEpoch training accuracy: 63.69%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.00%,                 Avg loss: 0.625148 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch training loss: 0.603914 \tEpoch training accuracy: 65.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.57%,                 Avg loss: 0.607948 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch training loss: 0.597929 \tEpoch training accuracy: 66.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.00%,                 Avg loss: 0.615479 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599263 \tEpoch training accuracy: 65.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.43%,                 Avg loss: 0.622026 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch training loss: 0.597627 \tEpoch training accuracy: 66.15%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.00%,                 Avg loss: 0.610076 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601580 \tEpoch training accuracy: 65.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.14%,                 Avg loss: 0.616854 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch training loss: 0.601149 \tEpoch training accuracy: 65.31%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.57%,                 Avg loss: 0.611904 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch training loss: 0.596600 \tEpoch training accuracy: 66.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.57%,                 Avg loss: 0.611788 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch training loss: 0.599034 \tEpoch training accuracy: 65.87%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.57%,                 Avg loss: 0.608705 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch training loss: 0.598565 \tEpoch training accuracy: 65.46%                                                          60.0  \t[ 26 / 26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.43%,                 Avg loss: 0.607358 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch training loss: 0.597942 \tEpoch training accuracy: 66.03%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.00%,                 Avg loss: 0.604981 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch training loss: 0.597970 \tEpoch training accuracy: 66.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.86%,                 Avg loss: 0.617408 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch training loss: 0.595219 \tEpoch training accuracy: 66.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 61.86%,                 Avg loss: 0.605300 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch training loss: 0.597079 \tEpoch training accuracy: 66.00%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 60.57%,                 Avg loss: 0.609341 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Epoch training loss: 0.596422 \tEpoch training accuracy: 66.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.71%,                 Avg loss: 0.609985 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialise the benchmarking class. When we do not specify it, it will use KFold with 5 splits\n",
    "bench = Benchmark(models_dicts, dataloaders_dicts, loss_fn, writer)\n",
    "\n",
    "# start the benchmarking\n",
    "bench.start(SGD, 2, False, {\"lr\": 0.01}, {\"batch_size\": 32}, n_accumulated_grads=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNet(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (4): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.674135 \tEpoch training accuracy: 54.95%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 59.86%,                 Avg loss: 0.646908 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.643848 \tEpoch training accuracy: 57.15%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 62.86%,                 Avg loss: 0.607025 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.602208 \tEpoch training accuracy: 60.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.43%,                 Avg loss: 0.566409 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.575144 \tEpoch training accuracy: 63.69%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.00%,                 Avg loss: 0.519996 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.550739 \tEpoch training accuracy: 66.56%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 65.29%,                 Avg loss: 0.509049 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch training loss: 0.550600 \tEpoch training accuracy: 64.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.86%,                 Avg loss: 0.507524 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch training loss: 0.527803 \tEpoch training accuracy: 68.62%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 63.29%,                 Avg loss: 0.501394 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch training loss: 0.507035 \tEpoch training accuracy: 68.54%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.86%,                 Avg loss: 0.511708 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch training loss: 0.490313 \tEpoch training accuracy: 71.92%                                                         \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.57%,                 Avg loss: 0.462196 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch training loss: 0.503157 \tEpoch training accuracy: 69.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.00%,                 Avg loss: 0.449597 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch training loss: 0.473748 \tEpoch training accuracy: 72.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.86%,                 Avg loss: 0.441772 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch training loss: 0.460426 \tEpoch training accuracy: 74.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.14%,                 Avg loss: 0.454806 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch training loss: 0.476365 \tEpoch training accuracy: 72.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.14%,                 Avg loss: 0.448931 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch training loss: 0.472947 \tEpoch training accuracy: 72.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.440738 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch training loss: 0.429871 \tEpoch training accuracy: 77.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.403257 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch training loss: 0.441364 \tEpoch training accuracy: 77.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.00%,                 Avg loss: 0.423887 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405863 \tEpoch training accuracy: 77.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.29%,                 Avg loss: 0.395945 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch training loss: 0.426897 \tEpoch training accuracy: 77.92%                                               78.0  \t[ 8 / 26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.29%,                 Avg loss: 0.430447 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch training loss: 0.418932 \tEpoch training accuracy: 77.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.86%,                 Avg loss: 0.378035 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Epoch training loss: 0.401906 \tEpoch training accuracy: 78.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.378924 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch training loss: 0.392556 \tEpoch training accuracy: 79.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.43%,                 Avg loss: 0.422089 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch training loss: 0.405209 \tEpoch training accuracy: 78.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.489437 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch training loss: 0.404089 \tEpoch training accuracy: 78.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.57%,                 Avg loss: 0.412841 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch training loss: 0.391518 \tEpoch training accuracy: 80.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.29%,                 Avg loss: 0.404222 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch training loss: 0.392458 \tEpoch training accuracy: 79.46%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.409198 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch training loss: 0.383965 \tEpoch training accuracy: 79.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.29%,                 Avg loss: 0.430988 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch training loss: 0.409204 \tEpoch training accuracy: 79.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.409387 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch training loss: 0.395328 \tEpoch training accuracy: 79.51%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.86%,                 Avg loss: 0.388396 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch training loss: 0.393951 \tEpoch training accuracy: 79.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.43%,                 Avg loss: 0.452332 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch training loss: 0.408876 \tEpoch training accuracy: 78.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.57%,                 Avg loss: 0.423477 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412361 \tEpoch training accuracy: 79.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.86%,                 Avg loss: 0.388417 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch training loss: 0.370999 \tEpoch training accuracy: 81.21%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.00%,                 Avg loss: 0.407501 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch training loss: 0.380971 \tEpoch training accuracy: 81.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.57%,                 Avg loss: 0.372545 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch training loss: 0.369645 \tEpoch training accuracy: 82.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.43%,                 Avg loss: 0.416298 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch training loss: 0.391321 \tEpoch training accuracy: 79.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.29%,                 Avg loss: 0.408897 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch training loss: 0.380190 \tEpoch training accuracy: 79.64%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.00%,                 Avg loss: 0.401530 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch training loss: 0.385319 \tEpoch training accuracy: 80.41%                                                            26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.437507 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch training loss: 0.389924 \tEpoch training accuracy: 79.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.388632 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch training loss: 0.376255 \tEpoch training accuracy: 81.67%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.71%,                 Avg loss: 0.434298 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Epoch training loss: 0.351882 \tEpoch training accuracy: 82.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.86%,                 Avg loss: 0.372799 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch training loss: 0.347922 \tEpoch training accuracy: 82.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.00%,                 Avg loss: 0.419828 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch training loss: 0.392484 \tEpoch training accuracy: 80.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.00%,                 Avg loss: 0.442525 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch training loss: 0.368636 \tEpoch training accuracy: 81.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.00%,                 Avg loss: 0.400297 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch training loss: 0.348859 \tEpoch training accuracy: 83.08%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.71%,                 Avg loss: 0.384856 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch training loss: 0.349202 \tEpoch training accuracy: 83.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.361176 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch training loss: 0.371681 \tEpoch training accuracy: 81.87%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.381860 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch training loss: 0.344617 \tEpoch training accuracy: 83.31%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.86%,                 Avg loss: 0.399426 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch training loss: 0.370233 \tEpoch training accuracy: 83.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.86%,                 Avg loss: 0.372347 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch training loss: 0.329834 \tEpoch training accuracy: 84.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 86.00%,                 Avg loss: 0.336008 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch training loss: 0.336725 \tEpoch training accuracy: 84.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.57%,                 Avg loss: 0.403365 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch training loss: 0.333148 \tEpoch training accuracy: 83.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.00%,                 Avg loss: 0.351451 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch training loss: 0.369997 \tEpoch training accuracy: 82.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.86%,                 Avg loss: 0.356772 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch training loss: 0.348204 \tEpoch training accuracy: 83.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.29%,                 Avg loss: 0.344419 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch training loss: 0.349374 \tEpoch training accuracy: 84.08%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.57%,                 Avg loss: 0.386892 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch training loss: 0.325924 \tEpoch training accuracy: 85.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.00%,                 Avg loss: 0.301459 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch training loss: 0.322469 \tEpoch training accuracy: 85.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.43%,                 Avg loss: 0.349328 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch training loss: 0.307681 \tEpoch training accuracy: 85.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.29%,                 Avg loss: 0.347607 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch training loss: 0.331281 \tEpoch training accuracy: 84.64%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.57%,                 Avg loss: 0.371840 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch training loss: 0.317142 \tEpoch training accuracy: 85.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 86.00%,                 Avg loss: 0.328026 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Epoch training loss: 0.314502 \tEpoch training accuracy: 85.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.57%,                 Avg loss: 0.355006 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch training loss: 0.318248 \tEpoch training accuracy: 85.18%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.71%,                 Avg loss: 0.327045 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch training loss: 0.315583 \tEpoch training accuracy: 85.72%                                                         \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 87.57%,                 Avg loss: 0.341947 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch training loss: 0.322150 \tEpoch training accuracy: 86.49%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.29%,                 Avg loss: 0.388372 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch training loss: 0.385593 \tEpoch training accuracy: 81.08%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.43%,                 Avg loss: 0.403374 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch training loss: 0.341900 \tEpoch training accuracy: 83.36%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.71%,                 Avg loss: 0.311117 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch training loss: 0.282349 \tEpoch training accuracy: 87.49%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 86.00%,                 Avg loss: 0.304612 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch training loss: 0.293298 \tEpoch training accuracy: 86.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 89.00%,                 Avg loss: 0.306404 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch training loss: 0.280885 \tEpoch training accuracy: 87.92%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.00%,                 Avg loss: 0.348688 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch training loss: 0.324876 \tEpoch training accuracy: 85.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.71%,                 Avg loss: 0.339987 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch training loss: 0.280973 \tEpoch training accuracy: 87.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.43%,                 Avg loss: 0.295394 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch training loss: 0.312539 \tEpoch training accuracy: 86.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.29%,                 Avg loss: 0.477928 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch training loss: 0.362330 \tEpoch training accuracy: 83.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.86%,                 Avg loss: 0.300548 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch training loss: 0.308108 \tEpoch training accuracy: 85.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.00%,                 Avg loss: 0.363721 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch training loss: 0.326445 \tEpoch training accuracy: 84.62%                                               80.0  \t[ 19 / 26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 89.71%,                 Avg loss: 0.300372 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch training loss: 0.294706 \tEpoch training accuracy: 87.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.29%,                 Avg loss: 0.371186 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch training loss: 0.276688 \tEpoch training accuracy: 88.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 89.43%,                 Avg loss: 0.303136 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch training loss: 0.272358 \tEpoch training accuracy: 88.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.360116 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch training loss: 0.291021 \tEpoch training accuracy: 86.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 87.29%,                 Avg loss: 0.304473 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch training loss: 0.296540 \tEpoch training accuracy: 86.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 89.00%,                 Avg loss: 0.302070 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Epoch training loss: 0.269197 \tEpoch training accuracy: 88.87%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.29%,                 Avg loss: 0.293989 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch training loss: 0.280711 \tEpoch training accuracy: 88.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.86%,                 Avg loss: 0.352057 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch training loss: 0.284784 \tEpoch training accuracy: 87.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.57%,                 Avg loss: 0.353898 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch training loss: 0.270851 \tEpoch training accuracy: 86.90%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.43%,                 Avg loss: 0.338396 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch training loss: 0.337262 \tEpoch training accuracy: 85.05%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.14%,                 Avg loss: 0.385902 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch training loss: 0.311507 \tEpoch training accuracy: 84.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 87.57%,                 Avg loss: 0.285670 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch training loss: 0.277195 \tEpoch training accuracy: 85.87%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.43%,                 Avg loss: 0.408915 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch training loss: 0.292232 \tEpoch training accuracy: 87.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 90.86%,                 Avg loss: 0.279201 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch training loss: 0.292951 \tEpoch training accuracy: 86.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.71%,                 Avg loss: 0.324766 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch training loss: 0.279553 \tEpoch training accuracy: 88.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 87.29%,                 Avg loss: 0.382660 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch training loss: 0.253358 \tEpoch training accuracy: 89.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.29%,                 Avg loss: 0.304772 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch training loss: 0.262583 \tEpoch training accuracy: 88.92%                                                \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 90.86%,                 Avg loss: 0.276906 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch training loss: 0.266465 \tEpoch training accuracy: 88.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.71%,                 Avg loss: 0.330478 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch training loss: 0.287864 \tEpoch training accuracy: 86.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.14%,                 Avg loss: 0.379972 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch training loss: 0.272893 \tEpoch training accuracy: 88.64%                                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.57%,                 Avg loss: 0.323036 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch training loss: 0.276951 \tEpoch training accuracy: 87.72%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.00%,                 Avg loss: 0.305980 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch training loss: 0.296257 \tEpoch training accuracy: 85.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.57%,                 Avg loss: 0.378501 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch training loss: 0.310228 \tEpoch training accuracy: 86.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 87.00%,                 Avg loss: 0.288034 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch training loss: 0.296440 \tEpoch training accuracy: 87.59%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 86.71%,                 Avg loss: 0.322689 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch training loss: 0.316061 \tEpoch training accuracy: 84.97%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 88.43%,                 Avg loss: 0.302722 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Epoch training loss: 0.268035 \tEpoch training accuracy: 87.64%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 90.86%,                 Avg loss: 0.251322 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2513222247362137, 90.85714285714286)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model = FFNet(arch=[3,10,10,10,10,2])\n",
    "print(model)\n",
    "pipe = Trainer(model, (dl_tr, dl_ts), nn.CrossEntropyLoss(), writer)\n",
    "pipe.train(Adam, 100, False, {\"lr\":0.01}, {\"batch_size\":50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "one_batch_dataset, _, _ = DataLoaderBuilder((ds_tr, ds_val, ds_ts)).build([{\"batch_size\":1600}, {\"batch_size\":1600}, {\"batch_size\":1600}]) \n",
    "\n",
    "\n",
    "\n",
    "# the diagrams can be seen on tensorboard!\n",
    "vs.plot_persistence_diagrams(next(iter(one_batch_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.plot_3d_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
