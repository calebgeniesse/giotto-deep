{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toplogy of Deep Neural Networks\n",
    "\n",
    "This notebook will show you how easy it is to use gdeep to reproduce the experiments of the paper *Topology of Deep Neural Networks*, by Naizat et. al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPUs...\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import autograd  \n",
    "\n",
    "#gdeep\n",
    "from gdeep.data.datasets import DatasetBuilder, DataLoaderBuilder\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.visualisation import persistence_diagrams_of_activations\n",
    "from gdeep.data.preprocessors import ToTensorImage\n",
    "from gdeep.trainer import Trainer\n",
    "\n",
    "\n",
    "# plot\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# TDA\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.plotting import plot_diagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the reuslts of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/example` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DatasetBuilder(name=\"EntangledTori\")\n",
    "ds_tr, ds_val, ds_ts = db.build()\n",
    "dl_tr, dl_val, dl_ts = DataLoaderBuilder((ds_tr, ds_val, ds_ts)).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot dataset to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1600, 3]), torch.Size([1600]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.cat([batch for batch, _ in dl_tr])\n",
    "label_tensor = torch.cat([batch for _ ,batch in dl_tr])\n",
    "data_tensor.shape, label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNet(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (4): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 0.682101 \tEpoch training accuracy: 54.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.29%,                 Avg loss: 0.664563 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Batch training loss:  0.6711804866790771  \tBatch training accuracy:  52.0  \t[ 8 / 26 ]                                  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berkouknicolas/Desktop/giotto-deep/gdeep/trainer/trainer.py:455: UserWarning: Cannot store data in the PR curve\n",
      "  warnings.warn(\"Cannot store data in the PR curve\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch training loss: 0.647352 \tEpoch training accuracy: 56.77%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 64.00%,                 Avg loss: 0.608776 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch training loss: 0.605375 \tEpoch training accuracy: 61.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 58.00%,                 Avg loss: 0.588700 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch training loss: 0.577258 \tEpoch training accuracy: 61.92%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.14%,                 Avg loss: 0.538880 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch training loss: 0.551721 \tEpoch training accuracy: 63.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.00%,                 Avg loss: 0.565839 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch training loss: 0.541176 \tEpoch training accuracy: 65.54%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.43%,                 Avg loss: 0.525677 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch training loss: 0.539933 \tEpoch training accuracy: 62.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 67.00%,                 Avg loss: 0.561806 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch training loss: 0.549772 \tEpoch training accuracy: 63.56%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.71%,                 Avg loss: 0.546091 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch training loss: 0.537802 \tEpoch training accuracy: 65.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 66.71%,                 Avg loss: 0.520011 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch training loss: 0.527022 \tEpoch training accuracy: 66.69%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.00%,                 Avg loss: 0.504377 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch training loss: 0.515890 \tEpoch training accuracy: 69.97%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.00%,                 Avg loss: 0.519984 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch training loss: 0.508553 \tEpoch training accuracy: 70.46%                                              \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.71%,                 Avg loss: 0.508292 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch training loss: 0.517534 \tEpoch training accuracy: 69.23%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.43%,                 Avg loss: 0.503625 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch training loss: 0.498924 \tEpoch training accuracy: 71.18%                                                         \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 69.43%,                 Avg loss: 0.512278 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch training loss: 0.497247 \tEpoch training accuracy: 72.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 72.86%,                 Avg loss: 0.489160 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch training loss: 0.487135 \tEpoch training accuracy: 74.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.71%,                 Avg loss: 0.479865 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch training loss: 0.498537 \tEpoch training accuracy: 72.21%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 68.00%,                 Avg loss: 0.517374 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch training loss: 0.503832 \tEpoch training accuracy: 70.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.57%,                 Avg loss: 0.504203 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch training loss: 0.475315 \tEpoch training accuracy: 73.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.29%,                 Avg loss: 0.488025 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Epoch training loss: 0.475767 \tEpoch training accuracy: 77.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.00%,                 Avg loss: 0.507860 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch training loss: 0.454980 \tEpoch training accuracy: 77.59%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 71.86%,                 Avg loss: 0.464917 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch training loss: 0.456450 \tEpoch training accuracy: 74.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 74.71%,                 Avg loss: 0.461014 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch training loss: 0.435302 \tEpoch training accuracy: 77.44%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.29%,                 Avg loss: 0.448985 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch training loss: 0.488749 \tEpoch training accuracy: 72.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 70.29%,                 Avg loss: 0.496193 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch training loss: 0.447638 \tEpoch training accuracy: 75.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.29%,                 Avg loss: 0.446438 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch training loss: 0.408692 \tEpoch training accuracy: 77.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.401374 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch training loss: 0.416892 \tEpoch training accuracy: 79.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.418564 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch training loss: 0.439695 \tEpoch training accuracy: 75.64%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.29%,                 Avg loss: 0.408780 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412899 \tEpoch training accuracy: 77.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 73.14%,                 Avg loss: 0.433287 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch training loss: 0.425652 \tEpoch training accuracy: 77.21%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 75.43%,                 Avg loss: 0.439785 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch training loss: 0.385417 \tEpoch training accuracy: 81.21%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.14%,                 Avg loss: 0.372460 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch training loss: 0.368652 \tEpoch training accuracy: 80.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.57%,                 Avg loss: 0.375500 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch training loss: 0.351759 \tEpoch training accuracy: 82.72%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.29%,                 Avg loss: 0.423754 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch training loss: 0.375480 \tEpoch training accuracy: 80.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.57%,                 Avg loss: 0.388142 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch training loss: 0.353691 \tEpoch training accuracy: 83.69%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 76.14%,                 Avg loss: 0.433209 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch training loss: 0.353842 \tEpoch training accuracy: 81.95%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.14%,                 Avg loss: 0.351777 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch training loss: 0.354332 \tEpoch training accuracy: 82.79%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.71%,                 Avg loss: 0.414878 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch training loss: 0.358017 \tEpoch training accuracy: 82.00%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.14%,                 Avg loss: 0.350438 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch training loss: 0.345774 \tEpoch training accuracy: 82.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.86%,                 Avg loss: 0.384420 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Epoch training loss: 0.344233 \tEpoch training accuracy: 82.10%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 79.86%,                 Avg loss: 0.367764 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch training loss: 0.347891 \tEpoch training accuracy: 81.38%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.29%,                 Avg loss: 0.377941 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch training loss: 0.366362 \tEpoch training accuracy: 80.87%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.43%,                 Avg loss: 0.404869 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch training loss: 0.379774 \tEpoch training accuracy: 79.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.00%,                 Avg loss: 0.410170 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch training loss: 0.337559 \tEpoch training accuracy: 82.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.71%,                 Avg loss: 0.357415 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch training loss: 0.354053 \tEpoch training accuracy: 81.41%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 77.57%,                 Avg loss: 0.394827 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch training loss: 0.354337 \tEpoch training accuracy: 82.62%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.374213 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch training loss: 0.323758 \tEpoch training accuracy: 84.92%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.14%,                 Avg loss: 0.361558 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch training loss: 0.310539 \tEpoch training accuracy: 84.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.86%,                 Avg loss: 0.340260 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch training loss: 0.313875 \tEpoch training accuracy: 84.51%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.14%,                 Avg loss: 0.324965 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch training loss: 0.333240 \tEpoch training accuracy: 83.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.396556 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch training loss: 0.336059 \tEpoch training accuracy: 82.44%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.71%,                 Avg loss: 0.330000 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch training loss: 0.323286 \tEpoch training accuracy: 84.33%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.71%,                 Avg loss: 0.363402 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch training loss: 0.311599 \tEpoch training accuracy: 85.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.71%,                 Avg loss: 0.339627 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch training loss: 0.307527 \tEpoch training accuracy: 85.33%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.57%,                 Avg loss: 0.371081 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch training loss: 0.336739 \tEpoch training accuracy: 83.28%                                                          \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 78.14%,                 Avg loss: 0.411250 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch training loss: 0.335566 \tEpoch training accuracy: 82.67%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.338618 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch training loss: 0.293968 \tEpoch training accuracy: 85.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.71%,                 Avg loss: 0.326821 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch training loss: 0.328424 \tEpoch training accuracy: 84.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.14%,                 Avg loss: 0.363421 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch training loss: 0.346275 \tEpoch training accuracy: 82.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 80.86%,                 Avg loss: 0.387974 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Epoch training loss: 0.328176 \tEpoch training accuracy: 83.79%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.14%,                 Avg loss: 0.334794 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch training loss: 0.310085 \tEpoch training accuracy: 85.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.14%,                 Avg loss: 0.375135 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch training loss: 0.332670 \tEpoch training accuracy: 83.26%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.330192 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch training loss: 0.324783 \tEpoch training accuracy: 82.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.57%,                 Avg loss: 0.321926 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch training loss: 0.313653 \tEpoch training accuracy: 84.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.86%,                 Avg loss: 0.368569 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch training loss: 0.302657 \tEpoch training accuracy: 85.36%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.330028 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch training loss: 0.289457 \tEpoch training accuracy: 85.59%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.71%,                 Avg loss: 0.318016 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch training loss: 0.296856 \tEpoch training accuracy: 84.95%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.57%,                 Avg loss: 0.297221 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch training loss: 0.295529 \tEpoch training accuracy: 85.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.29%,                 Avg loss: 0.337315 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch training loss: 0.306722 \tEpoch training accuracy: 85.36%                                      ]                     26 ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.57%,                 Avg loss: 0.319597 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch training loss: 0.308757 \tEpoch training accuracy: 85.49%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.86%,                 Avg loss: 0.296078 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch training loss: 0.302697 \tEpoch training accuracy: 85.26%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.57%,                 Avg loss: 0.297584 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch training loss: 0.303402 \tEpoch training accuracy: 85.13%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.43%,                 Avg loss: 0.356170 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch training loss: 0.324440 \tEpoch training accuracy: 83.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.321439 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch training loss: 0.294313 \tEpoch training accuracy: 85.82%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 87.57%,                 Avg loss: 0.299328 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch training loss: 0.297008 \tEpoch training accuracy: 84.77%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 86.14%,                 Avg loss: 0.301305 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch training loss: 0.284346 \tEpoch training accuracy: 86.15%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.71%,                 Avg loss: 0.329391 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch training loss: 0.312845 \tEpoch training accuracy: 83.74%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.57%,                 Avg loss: 0.301223 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch training loss: 0.292303 \tEpoch training accuracy: 84.90%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.308594 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch training loss: 0.309079 \tEpoch training accuracy: 84.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.322726 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Epoch training loss: 0.289140 \tEpoch training accuracy: 84.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 86.86%,                 Avg loss: 0.281146 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch training loss: 0.287767 \tEpoch training accuracy: 85.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.00%,                 Avg loss: 0.297151 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch training loss: 0.295535 \tEpoch training accuracy: 84.79%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.14%,                 Avg loss: 0.278868 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch training loss: 0.283328 \tEpoch training accuracy: 85.59%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.29%,                 Avg loss: 0.331457 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch training loss: 0.288224 \tEpoch training accuracy: 86.05%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.29%,                 Avg loss: 0.306445 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch training loss: 0.287504 \tEpoch training accuracy: 85.79%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 82.00%,                 Avg loss: 0.385625 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch training loss: 0.313461 \tEpoch training accuracy: 84.64%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.29%,                 Avg loss: 0.311086 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch training loss: 0.283362 \tEpoch training accuracy: 86.41%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.86%,                 Avg loss: 0.325702 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch training loss: 0.300282 \tEpoch training accuracy: 85.28%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.57%,                 Avg loss: 0.295472 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch training loss: 0.310396 \tEpoch training accuracy: 84.23%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.71%,                 Avg loss: 0.334120 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch training loss: 0.280558 \tEpoch training accuracy: 86.13%                                                         \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.71%,                 Avg loss: 0.298441 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch training loss: 0.304933 \tEpoch training accuracy: 85.03%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.57%,                 Avg loss: 0.285273 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch training loss: 0.295509 \tEpoch training accuracy: 84.67%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.71%,                 Avg loss: 0.297660 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch training loss: 0.282622 \tEpoch training accuracy: 85.51%                                                           \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.14%,                 Avg loss: 0.385993 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch training loss: 0.320158 \tEpoch training accuracy: 84.85%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.57%,                 Avg loss: 0.338064 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch training loss: 0.320461 \tEpoch training accuracy: 82.97%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 84.86%,                 Avg loss: 0.320252 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch training loss: 0.303966 \tEpoch training accuracy: 85.10%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.43%,                 Avg loss: 0.314473 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch training loss: 0.278379 \tEpoch training accuracy: 86.46%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.71%,                 Avg loss: 0.284452 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch training loss: 0.289751 \tEpoch training accuracy: 85.54%                                               \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 85.00%,                 Avg loss: 0.295697 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch training loss: 0.292268 \tEpoch training accuracy: 85.44%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 83.71%,                 Avg loss: 0.335710 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Epoch training loss: 0.304726 \tEpoch training accuracy: 84.82%                                      ]                     \n",
      "Time taken for this epoch: 0.00s\n",
      "Learning rate value: 0.01000000\n",
      "Validation results: \n",
      " accuracy: 81.71%,                 Avg loss: 0.367792 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36779201882226126, 81.71428571428571)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train NN\n",
    "model = FFNet(arch=[3,10,10,10,10,2])\n",
    "print(model)\n",
    "pipe = Trainer(model, (dl_tr, dl_ts), nn.CrossEntropyLoss(), writer)\n",
    "pipe.train(Adam, 100, False, {\"lr\":0.01}, {\"batch_size\":50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bb44f6febb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# the diagrams can be seen on tensorboard!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_persistence_diagrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/giotto-deep/gdeep/visualisation/visualiser.py\u001b[0m in \u001b[0;36mplot_persistence_diagrams\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistence_diagrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualisation import Visualiser\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "data_tensor = torch.cat([batch for batch, _ in dl_tr])\n",
    "\n",
    "# the diagrams can be seen on tensorboard!\n",
    "vs.plot_persistence_diagrams(data_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d6fef448b7468aff623dc33ab00203e2652da5aee5d4c713f92321da872d47b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
