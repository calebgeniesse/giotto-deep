{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c7a584",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n",
      "Using GPU!\n",
      "Using GPU!\n",
      "No TPUs...\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xitorch in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.22.3)\n",
      "Requirement already satisfied: torch>=1.8 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.11.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from xitorch) (1.8.0)\n",
      "Requirement already satisfied: typing-extensions in /home/linuxbrew/.linuxbrew/lib/python3.9/site-packages (from torch>=1.8->xitorch) (4.1.1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing GPU!\n"
     ]
    }
   ],
   "source": [
    "from gdeep.topactivation import TopactivationFC as TFC\n",
    "from gdeep.pipeline import Pipeline\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from torch import nn\n",
    "import torch\n",
    "from gdeep.data import TorchDataLoader\n",
    "\n",
    "!pip3 install xitorch\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.topactivation.spectral_analysisTorch import LaplacianOperator\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using GPU!\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "writer = SummaryWriter()\n",
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32)\n",
    "\n",
    "arch = [28*28, 50, 50, 10]\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "#cpu = torch.ones(1).device\n",
    "\n",
    "me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "weights = list(me.get_layers_param().values())\n",
    "#weights = [layer.to(cpu) for layer in weights]\n",
    "lapOp = LaplacianOperator(weights)\n",
    "\n",
    "def print28x28tensor(tensor):\n",
    "    img=tensor.to('cpu')\n",
    "    pixels = img.reshape((28,28))\n",
    "    plt.imshow(pixels,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fe7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.topactivation.attack_carlini_wagner_l2 import AttackCarliniWagnerL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f31a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch training loss: 1.342672 \tEpoch training accuracy: 59.03%                                      500 ]                     \n",
      "Time taken for this epoch: 7.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 83.62%,                 Avg loss: 0.537760 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch training loss: 0.412013 \tEpoch training accuracy: 87.66%                                      500 ]                     \n",
      "Time taken for this epoch: 7.00s\n",
      "Learning rate value: 0.10000000\n",
      "Validation results: \n",
      " Accuracy: 90.22%,                 Avg loss: 0.333322 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Trainig the model \n",
    "\n",
    "arch = [28*28, 50,50,50, 10]\n",
    "optimizer = torch.optim.SGD\n",
    "model = nn.Sequential(nn.Flatten(), FFNet(arch,bias=False ))\n",
    "pipe = Pipeline(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "#for i in range(epochs):\n",
    "    #Train : \n",
    "pipe.train(optimizer, epochs, False, {\"lr\": 0.1}, n_accumulated_grads=5,keep_training=True)\n",
    "    \n",
    "   \n",
    "me = ModelExtractor(pipe.model, pipe.loss_fn)\n",
    "weights = list(me.get_layers_param().values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877f029b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torchattacks\n",
    "#help(torchattacks.PGD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "598e9aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#import torchattacks\n",
    "#atk = torchattacks.CW(pipe.model,kappa=0,c=1)\n",
    "#atk2 = torchattacks.FGSM(pipe.model, eps=8/255, steps=40, random_start=True)\n",
    "#atk3 = torchattacks.FGSM(pipe.model,eps=0.3)\n",
    "#atk=AttackCarliniWagnerL2()\n",
    "\n",
    "from foolbox import PyTorchModel\n",
    "from foolbox.attacks import L2CarliniWagnerAttack\n",
    "atk = L2CarliniWagnerAttack()\n",
    "epsilons = [2.0\n",
    "    ]\n",
    "\n",
    "for a in dl_ts:\n",
    "    perm = torch.randperm(len(a[1])).to(DEVICE)\n",
    "    print(a[0].shape)\n",
    "    print(a[1].shape)\n",
    "    fmodel = PyTorchModel(pipe.model, bounds=(0, 1), preprocessing=None)\n",
    "    #adv_images = atk.run(pipe.model,a[0].to(DEVICE),a[1][perm].to(DEVICE))\n",
    "    print('ok')\n",
    "    raw_advs, clipped_advs, success = atk(fmodel, a[0].to(DEVICE), a[1].to(DEVICE),epsilons=epsilons)\n",
    "    \n",
    "   \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f620d863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False,  True, False,  True,  True,  True,  True,\n",
       "         False,  True,  True, False, False,  True,  True, False,  True,  True,\n",
       "          True, False,  True, False,  True, False, False,  True, False,  True,\n",
       "         False,  True],\n",
       "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a8f2db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_advs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ccc954f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print28x28tensor(raw_advs[1][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fde988ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 5, 6, 7, 1, 4, 3, 4, 4, 6, 9, 4, 1, 9, 5, 3, 9, 1, 0, 0, 0, 7, 9,\n",
       "        7, 2, 6, 4, 5, 1, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e1f0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "idx= 8\n",
    "print(pipe.model(a[0][idx].to(DEVICE)).argmax())\n",
    "print(pipe.model(raw_advs[0][idx].to(DEVICE)).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bffd72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec5fb31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1846)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0][1]-raw_advs[0][1].to('cpu')).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print28x28tensor(a[0][1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.2\n",
    "n_batch = 1 #Number of batch used to generate the dataset \n",
    "\n",
    "\n",
    "activ = torch.zeros((3,n_batch*32,sum(arch)))\n",
    "#final tensor activ[alter][idx] contains an activation vector for data sample idx with a specific alteration :\n",
    "# 0 : no alteration, raw data \n",
    "# 1 : data + adversarial  noise\n",
    "# 2 : data + shuffle of adversarial noise (random perturbation with same statistics)\n",
    "label = torch.zeros(n_batch*32)\n",
    "predLabel = torch.zeros(5,n_batch*32)\n",
    "\n",
    "\n",
    "topactiv = TFC(pipe,arch)\n",
    "dl = TorchDataLoader(name=\"MNIST\")\n",
    "dl_tr, dl_ts = dl.build_dataloaders(batch_size=32)\n",
    "\n",
    "from foolbox import PyTorchModel\n",
    "from foolbox.attacks import L2CarliniWagnerAttack\n",
    "atk = L2CarliniWagnerAttack()\n",
    "epsilons = [2.0]\n",
    "fmodel = PyTorchModel(pipe.model, bounds=(0, 1), preprocessing=None)\n",
    "\n",
    "k_batch = 0 \n",
    "for data, target in dl_tr: \n",
    "    \n",
    "    \n",
    "    data=data.to(DEVICE) ##SUBOPTIMAL !!!\n",
    "    target = target.to(DEVICE)\n",
    "    data_perturbed = topactiv.fgsm_attack(data, target,epsilon)\n",
    "    \n",
    "    perm = torch.randperm(len(target)).to(DEVICE)\n",
    "    \n",
    "\n",
    "    raw_advs, clipped_advs, success = atk(fmodel, a[0].to(DEVICE), a[1].to(DEVICE),epsilons=epsilons)\n",
    "    data_carlini = raw_advs[0]\n",
    "    \n",
    "    #data_noised = data+epsilon*2*(torch.bernoulli(0.5*torch.ones(data.shape))-1)\n",
    "    #Shuffle\n",
    "    data_noised = torch.zeros(32,1,28,28).to(DEVICE)\n",
    "    data_noised2 = torch.zeros(32,1,28,28).to(DEVICE)\n",
    "    for i in range(32):\n",
    "        indices=torch.randperm(784).to(DEVICE)\n",
    "        data_noised[i]=(data_perturbed-data)[i].reshape(784)[indices].reshape(1,28,28)+data[i]\n",
    "        data_noised2[i]=(rdata_carlini-data)[i].reshape(784)[indices].reshape(1,28,28)+data[i]\n",
    "    \n",
    "    normal_activation = torch.cat(me.get_activations(data)[:-2],dim=1)\n",
    "    perturbed_activation = torch.cat(me.get_activations(data_perturbed)[:-2],dim=1)\n",
    "    noised_activation= torch.cat(me.get_activations(data_noised)[:-2],dim=1)\n",
    "    \n",
    "    \n",
    "    activ[0][k_batch*32:(k_batch+1)*32]=normal_activation\n",
    "    activ[1][k_batch*32:(k_batch+1)*32]=perturbed_activation\n",
    "    activ[2][k_batch*32:(k_batch+1)*32]=noised_activation\n",
    "    activ[3][k_batch*32:(k_batch+1)*32]=\n",
    "    activ[2][k_batch*32:(k_batch+1)*32]=\n",
    "    \n",
    "    label[k_batch*32:(k_batch+1)*32]=target\n",
    "    for alter in range(3):\n",
    "        predLabel[alter][k_batch*32:(k_batch+1)*32]=activ[alter][k_batch*32:(k_batch+1)*32,-10:].argmax(dim=1)\n",
    "    \n",
    "    k_batch+=1\n",
    "    if k_batch>=n_batch:\n",
    "        break \n",
    "print(activ.shape)\n",
    "\n",
    "def print28x28tensor(tensor):\n",
    "    img=tensor.to('cpu')\n",
    "    pixels = img.reshape((28,28))\n",
    "    plt.imshow(pixels,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
