{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5c76cb-5a8f-4558-843d-79834cc2e11c",
   "metadata": {},
   "source": [
    "# Tutorial: distributed computations on Kubernetes\n",
    "\n",
    "This short tutorials explains how to run the hyperparamerter optimisation over multiple servers. It requires to set-up a Kubernetes cluster: you can refer to the `kubernetes/readme.md` file, where it is explained how to set-up the cluster (with a few lines of code, as all the configuration files are ready)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6213f4-bb90-4f03-8bc0-51c96bac8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-reload in notebooks\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# constants: if you are running the K( setup proposed in giotto-deep, do not change these values!\n",
    "USER = \"root\"\n",
    "MYSQL_IP = \"mysql-service\"  # \"127.0.0.1\", if you run locally on your infrastructure\n",
    "PSW = \"password\"\n",
    "REDIS_IP = \"redis-service\"  # \"localhost\", if you run locally on your infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f58a8-1244-4174-b4a4-a01b9466b372",
   "metadata": {},
   "source": [
    "## General principles of distributions of computations\n",
    "\n",
    "In this notebook we will show it is possible to distribute the HyperParametersOptimisation computations to different pods (i.e. computing servers).\n",
    "\n",
    "There are two databases involved: one is **Redis** and is used to queue the computations, while the other is **MySQL** and it is used to keep track of the state of the HPO.\n",
    "\n",
    "On a local setting, in which neither `K8` or `minikube` are running, you would start MySQL with the following command:\n",
    "\n",
    "```\n",
    "docker run --name=user_mysql_1 --env=\"MYSQL_ROOT_PASSWORD=password\" -p 3306:3306 -d mysql:latest\n",
    "```\n",
    "\n",
    "Simlarly, to make sure that also Redis runs:\n",
    "\n",
    "```\n",
    "redis-server\n",
    "```\n",
    "\n",
    "Of course, both Redis and MySQL have to be installed (in the case of MySQL we use a docker image, while for redis we installed it via `brew install redis` on MacOS).\n",
    "\n",
    "Then, each worker will be able to run an HPO: hence, each HPO run will also ave to be connected to MySQL.\n",
    "\n",
    "\n",
    "**addendum**: \n",
    " - to stop MySQL\n",
    "\n",
    "```\n",
    "/usr/local/bin/mysql.server stop\n",
    "```\n",
    " - to make sure that the account to login to mysql is `root:password`, do\n",
    "\n",
    "```\n",
    "ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d59a5e-120c-4846-8c78-428ff8e1dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load RQ\n",
    "from redis import Redis\n",
    "from rq import Queue\n",
    "from rq import Retry\n",
    "\n",
    "# needed! make sure the file parallel_hpo.py exists in the cwd\n",
    "from parallel_hpo import connect_to_mysql, run_hpo_parallel, test_fnc\n",
    "\n",
    "# connect to mysql\n",
    "connect_to_mysql(USER, PSW, MYSQL_IP)\n",
    "print(\"MySQL connected\")\n",
    "\n",
    "# connect to redis\n",
    "redis = Redis(host=REDIS_IP, port=6379, db=0)\n",
    "print(\"Redis connected\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a3a3c-154c-4332-ae03-d52b0ed4deab",
   "metadata": {},
   "source": [
    "## Enqueuing principles\n",
    "\n",
    "In order to distribute comptuations, the technique we use here use queues. Basically, all the computations are stored in a queue (in Redis!) and whence a worker is available, it starts crunching the job (in a FIFO logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2f507-0deb-4336-a305-a2b3b200d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the job queue\n",
    "q = Queue(connection=redis)\n",
    "job = q.enqueue(test_fnc, \"hello!\", retry=Retry(max=3))\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee36233-e684-4c20-858d-fbdfc226c6b1",
   "metadata": {},
   "source": [
    "So far you have enqueued one job: now you have to start the workers so that the jobs can be crunched!\n",
    "\n",
    "In our setup of `minikube` or `K8` the workers are automatically set-up. If you are running your infrastructure from scratch on local, then you need to fire up some workers (each from a different terminal or moving the job to the background with `&`):\n",
    "\n",
    "```\n",
    "rq worker --url <redis-url> high default low\n",
    "```\n",
    "\n",
    "`<redis-url>` would most probably be `127.0.0.1` (or `localhost` or `0.0.0.0`). No need for this if you use the set-up we provide.\n",
    "\n",
    "To monitor the workers and the jobs, you can run the dashboard with:\n",
    "\n",
    "```\n",
    "rq-dashboard\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c46a02-9e63-4b5d-aeba-6ef57928d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to wait a bit before being able to see the result\n",
    "job.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b8c1c-c2ba-43df-be94-03781e09e7e7",
   "metadata": {},
   "source": [
    "## Enqueuing the jobs for HPO\n",
    "\n",
    "In the next section we enqueue the HPO and make sure that the workers are actively cruching the jobs! If more than one worker is active, the job gets distributed!\n",
    "\n",
    "But how does `optuna` knows how to distribute the computations? This is what MySQL database is about.\n",
    "\n",
    "You can set up multiple workers to have the HPO run in parallel and optuna will store in a MySQL database the data of each run every time a trial is finished. Every time a new trial starts, then the databse is read and -- depending on the HPO technique -- the new set of hyperparameters is used and recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becca4e-2218-4c51-86fe-38e2374640c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enqueue hpo jobs\n",
    "hpo_job = q.enqueue(run_hpo_parallel, args=(USER, PSW, MYSQL_IP), retry=Retry(max=3))\n",
    "hpo_job2 = q.enqueue(run_hpo_parallel, args=(USER, PSW, MYSQL_IP), retry=Retry(max=3))\n",
    "print(\"jobs enqueued\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bca45b-4d7a-4ac3-9190-fc4424e8513e",
   "metadata": {},
   "source": [
    "As before, make sure there are some active workers to cruch the jobs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6406585-d6c4-485d-ade9-2a7cf55985ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
